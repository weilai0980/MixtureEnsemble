--------------- FINISHED -------------------

statistic mixture 

gate logit central regularization

no dependency on hiddens
markov for statistic version

ELBO
  
validation metric
cut the data on one time step

Bayesian regression

server config 

smoothing or adaptive 

*speedup version 

regularization on the latent dependence
variance squared function 

lower_bound for pos_neg_diff_sq

version merge and cross check 

*constant terms 
  mean
  variance

*performance monitoring:
  py_mean_src
  py_var_src
  
loss: homoscedasticity-mse, heteroscedastic-lk_inv

Logging: 
  py_pikcle
  epoch_log
  
  
l2 hyper-para on latent smooth 
 
 yes
 
    same scale l2
    
       gate regu or not 
  
    lower scale l2
    
       gate regu or not 
 
 *no
    same scale l2
    
       gate regu or not 
  
    lower scale l2
    
       gate regu or not 

  
*testing output
   py_mean
   py_var
   py_mean_src
   py_var_src
   
bias term on gate function?


Predictive Uncertainty Estimation via Prior Networks

Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling

Uncertainty-Aware Attention for Reliable Interpretation and Prediction


dropout on bilinear transformation
performance optimizatin issue
  l2 on latent dependence faster?
  

--- constant variance MSE  

-- ml on single source
-- ml on multi source 
   

** learning rate decay

 / random search 


** l2, # epoches in random search 

** grid search


training-testing framework
average consistency

early stopping: epoch-wise,

Testing:
  ensemble

bias terms for different data sources 
  bias as a constant effect




--------------- POINT LEARNED -------------------


Model:

   bias term effect on generalization ability. It is related to the marginal mean of the target. 
   lk_inv is numerical stable

Training-validation:
   
  hyper-para search: grid random bayesian 

  early stopping using change-point detection for generalization ability

  set of optimal hyper-parameters
  snapshots under one certain hyper-parameter
  
  discrepency between validation and testing data

Testing:

  validation and testing data difference
  

design choice:
  lk -> lk_inv -> l2 on latent -> lr decay -> random or grid? -> constant, scalar, vec, pos_neg


--------------- TO DO -------------------


---- Tuning


https://karpathy.github.io/2019/04/25/recipe/?utm_source=Deep+Learning+Weekly&utm_campaign=6049a04f13-EMAIL_CAMPAIGN_2019_04_24_03_18_COPY_01&utm_medium=email&utm_term=0_384567b42d-6049a04f13-72960733


https://blog.nanonets.com/hyperparameter-optimization/?utm_campaign=Deep%20Learning%20Weekly&utm_medium=email&utm_source=Revue%20newsletter


https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21



----- DATA

data inspection

correlated variable elimination

*remove auto-regressive part



----- Survey



----- Statistic heteroskedasticity mixture


Data:
  
  data augments: spikes
  
  discrepency between validation and testing data
  
  ** DATA augmentation
     outlier
     lag effect 


Model:
  
  generic feature extractor on time series: pre-augment, end2end augment
  
  statistical boosting
  
  mean related bias
  
  ** boosting jump component
     burn-in phase 
  
  loss decomposition 
  
  imbalanced target values:
    data augmentation by sampling
    boosting
    weighted loss function
    

Training:

  training error 

  boosting
  data augments: spikes
  
  early stopping: batch-wise, change point detection, exponential moving average 
  
  Cyclical learning rates
  
  EM training
  inference 
  output wrapper positive
  
  train mode:  mse, mle, map, ELBO, EM, bayesian 
  
  
  ** bayeisan SG-MCMC:
  
     thinning
     ancestral sampling
     heteroskedasticity and MCMC inference
     math operation check
     
  
  Regularization:
  
    latent dependence
    l1
    fine-grained regularization hyper-para 
  
    imbalanced regularization on mean and variance
    
     
  Cross-check:
    ** lk > lk_inv > l2 on latent > lr decay > random or grid? > constant, scalar, vec, pos_neg?


Testing:

  discrepency between validation and testing data 


Monitoring and diagnostic:


Inference:
  
  remove outliers 
  
  ** truncated Gaussian on source contribution uncertainty




----- Neural heteroskedasticity mixture

hidden transition
  moving averaging for neural network version



----- bayesian


Bayesian:
  
  MCMC
    SG-MCMC: SG-LD, SG-HMC
    
  VI 
    MC-Dropout
    Posteriro-sharpening
    
  SGWA

Sampling methods:

  REINFORCE
  Importance sampling
  Re-parameteraization trick 
  Monte Carlo
  
  
Random forest 
   http://contrib.scikit-learn.org/forest-confidence-interval/installation_guide.html


----- baselines

  regression, constant terms
  
  lstm + att
  cnn + lstm
  dual rnn
  
  Gradient boosted tree
  LightGBM
  Random forest
   
  XGboosted
  
  sub-sample in gradient boosted tree 

  further check of ARCH series 
  
  
  
  
