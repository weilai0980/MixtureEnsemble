


--------------- TO DO LIST -------------------

---- TRAINING HYPER-PARA:

  loss: homoscedasticity-mse, heteroscedastic-lk_inv
  train mode: bayesian, map, EM 


---- baseline

subsample in gradient boosted tree 


---- survey

Predictive Uncertainty Estimation via Prior Networks

Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling

Uncertainty-Aware Attention for Reliable Interpretation and Prediction



---- MLE constant variance  

Gradient boosted tree
  LightGBM
  XGboosted 


---- heteroskedasticity


EM training

statistic mixture 

-- transition

  no dependency on hiddens
  markov for statistic version
  moving averaging for neural network version 

neural mixture


cnn + lstm
dual lk

lstm + att lk 

temporal mixture lk


---- bayesian

Bayesian linear mixture 


Bayesian regression
mc-dropout
   
Random forest 
   http://contrib.scikit-learn.org/forest-confidence-interval/installation_guide.html






