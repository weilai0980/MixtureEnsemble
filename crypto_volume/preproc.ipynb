{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline    \n",
    "import matplotlib as mplt\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.style.use('ggplot')\n",
    "\n",
    "from utils_libs import *\n",
    "from utils_data_prep import *\n",
    "\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import norm\n",
    "# from scipy.stats import chisqprob\n",
    "\n",
    "from numpy import prod\n",
    "import seaborn as sns\n",
    "\n",
    "# statiscal models\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "\n",
    "from statsmodels.stats import diagnostic\n",
    "import datetime\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import transaction data market 1 & 2\n",
    "\n",
    "trx_df_market1 = np.load(\"../../dataset/bitcoin/large/trx_df_tick_data_bitfinex_market.dat\")\n",
    "print(trx_df_market1.shape)\n",
    "print(trx_df_market1.head(3))\n",
    "\n",
    "trx_df_market2 = np.load(\"../../dataset/bitcoin/large/trx_df_tick_data_bitstamp_market.dat\")\n",
    "print(trx_df_market2.shape)\n",
    "print(trx_df_market2.head(3))\n",
    "\n",
    "print('TRX data LOADED...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract transaction features fast\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "trx_features_market1, trx_features_mins_market1 = extract_trx_features_matrix_fast(trx_df_market1)\n",
    "b = datetime.datetime.now()\n",
    "print('Finished extracting TRX features for market1')\n",
    "print(b-a)\n",
    "print(trx_features_market1.shape)\n",
    "print(trx_features_market1[1:5, 0:7])     \n",
    "print(trx_features_mins_market1[0:5])\n",
    "\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "trx_features_market2, trx_features_mins_market2 = extract_trx_features_matrix_fast(trx_df_market2)\n",
    "b = datetime.datetime.now()\n",
    "print('Finished extracting TRX features for market 2')\n",
    "print(b-a)\n",
    "print(trx_features_market2.shape)\n",
    "print(trx_features_market2[1:5, 0:7])   \n",
    "print(trx_features_mins_market2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import OB data for market 1\n",
    "\n",
    "all_dta_minu_ob_market1 = np.load(\"../../dataset/bitcoin/large/dta_minu_bitfinex_ob.dat\")\n",
    "all_loc_hour_ob_market1 = np.load(\"../../dataset/bitcoin/large/loc_hour_bitfinex_ob.dat\")\n",
    "all_loc_month_ob_market1 = np.load(\"../../dataset/bitcoin/large/loc_month_bitfinex_ob.dat\")\n",
    "all_dta_minu_ticks_ob_market1 = np.load(\"../../dataset/bitcoin/large/dta_minu_ticks_bitfinex_ob.dat\")\n",
    "print('OB data LOADED...\\n')\n",
    "\n",
    "print len(all_dta_minu_ob_market1), len(all_loc_hour_ob_market1), len(all_loc_month_ob_market1)\n",
    "\n",
    "# How data looks and is ogranised\n",
    "print( np.shape(all_dta_minu_ob_market1) )\n",
    "min_idx = 5; #minute offset \n",
    "bid_idx = 1; #bid or ask side\n",
    "print( 'price amount: \\n' )\n",
    "print( all_dta_minu_ob_market1[min_idx][bid_idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OB features for market 1\n",
    "\n",
    "ob_features_minu_market1 = np.load(\"../../dataset/bitcoin/large/feature_minu_bitfinex_ob.dat\")\n",
    "ob_features_minu_ticks_market1 = np.load(\"../../dataset/bitcoin/large/feature_minu_ticks_bitfinex_ob.dat\")\n",
    "\n",
    "print('OB features LOADED...\\n')\n",
    "\n",
    "print(ob_features_minu_market1.shape)\n",
    "print(ob_features_minu_market1[1:5,0:7])  \n",
    "print(ob_features_minu_ticks_market1[1:5])\n",
    "print(ob_features_minu_ticks_market1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for learning (yi, ti) = yi is target volume, ti is the key in the feature_dict\n",
    "# sources = 1..M., feature_dist[key=(ti, source_id)]=matrix of features\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def get_source_feature_matrix(target_idx, features_tuple, feature_dict, source_id, delta1, delta2):\n",
    "    # y_i target volume extracted from index at target_idx\n",
    "    # features_tuple - (trx_features_timestamp_market1_sort, trx_features_market1_sort) \n",
    "    # feature_dict , #key = (target_id, source_id), value = matrix of features from source_id; - call by reference\n",
    "    # history [t_i-delta2,t_i-delta1], where t_i is time of target volume y_i\n",
    "    \n",
    "    trx_features_timestamp_market_sort = features_tuple[0]\n",
    "    trx_features_market_sort = features_tuple[1]\n",
    "\n",
    "    delta = delta2 - delta1;\n",
    "    ti = trx_features_timestamp_market_sort[target_idx]\n",
    "    tj = trx_features_timestamp_market_sort[target_idx - delta2]\n",
    "\n",
    "    yi = trx_features_market_sort[target_idx, 0]\n",
    "    #(yi,ti) target_var, feature_dict[(ti,source_id)] = features\n",
    "\n",
    "    if (ti - tj == (delta*60)):\n",
    "        \n",
    "        tmp_features_matrix = trx_features_market_sort[target_idx-delta2+1:target_idx-delta1+1,:]\n",
    "        key_tmp = (ti, source_id)\n",
    "        feature_dict[key_tmp]=tmp_features_matrix\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_features_matrix = np.zeros([delta, trx_features_market_sort.shape[1]])\n",
    "        offset_idx = 1\n",
    "        while( (target_idx>=offset_idx) & ((ti-trx_features_timestamp_market_sort[target_idx-offset_idx]) <= (delta*60)) ):\n",
    "            tmp_feature_offset_idx = delta-((ti-trx_features_timestamp_market_sort[target_idx-offset_idx])//60)\n",
    "            tmp_features_matrix[tmp_feature_offset_idx,:] = trx_features_market_sort[target_idx-offset_idx,:]    \n",
    "            offset_idx += 1\n",
    "\n",
    "        key_tmp = (ti, source_id)\n",
    "        feature_dict[key_tmp]=tmp_features_matrix\n",
    "        \n",
    "    return (yi,ti)\n",
    "\n",
    "def fillEmptyFeat(tmp_key, my_dict, elem):\n",
    "    if tmp_key not in my_dict:\n",
    "        my_dict[tmp_key] = elem\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_target_feature_pairs(source_data, feature_dict, delta1, delta2):\n",
    "    \n",
    "    source_type = source_data[0]\n",
    "    source_id = source_data[1]\n",
    "    print(source_type)\n",
    "    print(\"source id = \" + str(source_id))\n",
    "    \n",
    "    \n",
    "    features_mins_market = source_data[2]\n",
    "    features_market = source_data[3]\n",
    "\n",
    "    features_timestamp_market=[int((datetime.strptime(str_var, '%Y-%m-%d %H-%M')-datetime(1970,1,1)).total_seconds())\n",
    "                                    for str_var in features_mins_market]\n",
    "    idx_sort_time = np.argsort(features_timestamp_market)\n",
    "\n",
    "    features_timestamp_market_sort = [features_timestamp_market[x] for x in idx_sort_time]\n",
    "    features_market_sort = features_market[idx_sort_time,:]\n",
    "\n",
    "    features_time_tuple_sort = (features_timestamp_market_sort, features_market_sort)\n",
    "\n",
    "    target_feature_key = [get_source_feature_matrix(idx, \n",
    "                                                    features_time_tuple_sort, \n",
    "                                                    feature_dict, \n",
    "                                                    source_id, \n",
    "                                                    delta1, \n",
    "                                                    delta2) \n",
    "                          for idx in range(len(features_timestamp_market_sort))]\n",
    "   \n",
    "    \n",
    "    print(\"Extracted!\")\n",
    "    return target_feature_key\n",
    "    \n",
    "    \n",
    "    \n",
    "feature_dict={}\n",
    "#key = (timestep, source_id), value = matrix \n",
    "\n",
    "delta2 = 11 # look-back time steps\n",
    "delta1 = 1 # k-step ahead \n",
    "delta = delta2 - delta1\n",
    "\n",
    "\n",
    "source1_trx = (\"trx-data\", 1, trx_features_mins_market1, trx_features_market1)\n",
    "# target \n",
    "target_feature_key = extract_target_feature_pairs(source1_trx, feature_dict, delta1, delta2)\n",
    "\n",
    "\n",
    "source2_trx = (\"trx-data\", 2, trx_features_mins_market2, trx_features_market2)\n",
    "#for second market we neglect target_feature_key, it only inserts features for key with source2\n",
    "_ = extract_target_feature_pairs(source2_trx, feature_dict, delta1, delta2)\n",
    "\n",
    "\n",
    "source3_ob = (\"ob-data\", 3, ob_features_minu_ticks_market1, ob_features_minu_market1)\n",
    "_ = extract_target_feature_pairs(source3_ob, feature_dict, delta1, delta2)\n",
    "\n",
    "source3_ob = (\"ob-data\", 3, ob_features_minu_ticks_market1, ob_features_minu_market1)\n",
    "_ = extract_target_feature_pairs(source3_ob, feature_dict, delta1, delta2)\n",
    "\n",
    "\n",
    "empty_elem = np.zeros([delta, trx_features_market2.shape[1] ])\n",
    "tmp_inserts = map( lambda x: fillEmptyFeat((x[1],2), feature_dict, empty_elem), target_feature_key)\n",
    "    \n",
    "empty_elem = np.zeros([delta, ob_features_minu_market1.shape[1] ])\n",
    "tmp_inserts = map( lambda x: fillEmptyFeat((x[1],3), feature_dict, empty_elem), target_feature_key)\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path_data = \"../../dataset/bitcoin/\"\n",
    "\n",
    "dta = pickle.load(open(path_data + 'target_market1_features_ob_trx_delta_5_data.pkl', \"rb\"), encoding = 'latin1')\n",
    "\n",
    "print(np.shape(dta[0][2][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- create target, time, feature tupple (yi, ti, xi)\n",
    "\n",
    "# target_feature_key [y_i, timestep]\n",
    "\n",
    "# feature_dict [(timestep, source_id), matrix]\n",
    "\n",
    "# source1 feature matrix, source2 feature matrix, source 3 feature matrix\n",
    "\n",
    "target_feature_data = [(x[0], x[1], [feature_dict[(x[1],1)], feature_dict[(x[1],2)], feature_dict[(x[1],3)]]) \n",
    "                       for x in target_feature_key]\n",
    "\n",
    "print(len(target_feature_data))\n",
    "# print(target_feature_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first column corresponds to the target variable\n",
    "# timestamp increasing order \n",
    "target_feature_data[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load organized data\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = '../../dataset/bitcoin/delta_15_data.pkl'\n",
    "\n",
    "# filename = '../../dataset/bitcoin/delta_15_data.pkl'\n",
    "\n",
    "infile = open(filename,'rb')\n",
    "target_feature_data_agg = pickle.load(infile)\n",
    "infile.close()\n",
    "print(\"loaded\")\n",
    "\n",
    "print(len(target_feature_data_agg))\n",
    "\n",
    "print(target_feature_data_agg[1])\n",
    "\n",
    "print([i[1] for i in target_feature_data_agg[0:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_feature_data = target_feature_data_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlated features\n",
    "\n",
    "target_feature_data = []\n",
    "\n",
    "for i in target_feature_data_agg:\n",
    "    \n",
    "    tmp_ob = i[2][2]\n",
    "    \n",
    "    ob_feature = tmp_ob[:, [0, 1, 3, 5, 6, 8, 9]]\n",
    "    \n",
    "    target_feature_data.append([i[0], i[1], [i[2][0], i[2][1], ob_feature]])\n",
    "    \n",
    "print(target_feature_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Load organized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path_data = \"../../dataset/bitcoin/\"\n",
    "\n",
    "dta = pickle.load(open(path_data + 'target_market1_features_ob_trx_delta_1_data.pkl', \"rb\"), encoding = 'latin1')\n",
    "\n",
    "print(np.shape(dta[0][2][2]))\n",
    "\n",
    "target_feature_data = dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- dataset split\n",
    "\n",
    "cnt = len(target_feature_data)\n",
    "\n",
    "train_split = int(cnt*0.7)\n",
    "val_split = int(cnt*0.8)\n",
    "\n",
    "train_data = target_feature_data[:train_split]\n",
    "val_data = target_feature_data[train_split:val_split]\n",
    "test_data = target_feature_data[val_split:]\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ----- normalization\n",
    "\n",
    "# training data: mean and standard deviation from the training data\n",
    "src_x = []\n",
    "src_num = len(train_data[0][2])\n",
    "\n",
    "src_m = []\n",
    "src_std = []\n",
    "\n",
    "for src_idx in range(src_num):\n",
    "    # [N T D]     \n",
    "    tmp_src = [tmp[2][src_idx] for tmp in train_data]\n",
    "    tmp_mean = np.mean(tmp_src, axis = 0)\n",
    "    tmp_std = np.std(tmp_src, axis = 0)\n",
    "    \n",
    "    src_m.append(tmp_mean)\n",
    "    src_std.append(tmp_std)\n",
    "    \n",
    "    print('test', np.shape(tmp_src))\n",
    "\n",
    "print((train_data[0][2][0]))\n",
    "print(val_data[0][2][0])\n",
    "print(test_data[0][2][0])\n",
    "\n",
    "# normalize training data\n",
    "for src_idx in range(src_num):\n",
    "    for tmp_idx, tmp in enumerate(train_data):\n",
    "        \n",
    "        tmpdata = list(tmp)\n",
    "        tmpdata[2] = list(tmpdata[2])\n",
    "        \n",
    "        tmpdata[2][src_idx] = (tmpdata[2][src_idx] - src_m[src_idx])/(src_std[src_idx] + 1e-5)\n",
    "        train_data[tmp_idx] = tmpdata\n",
    "    \n",
    "# normalize validattion data\n",
    "for src_idx in range(src_num):\n",
    "    for tmp_idx, tmp in enumerate(val_data):\n",
    "        \n",
    "        tmpdata = list(tmp)\n",
    "        tmpdata[2] = list(tmpdata[2])\n",
    "        \n",
    "        tmpdata[2][src_idx] = (tmpdata[2][src_idx] - src_m[src_idx])/(src_std[src_idx] + 1e-5)\n",
    "        val_data[tmp_idx] = tmpdata\n",
    "        \n",
    "# normalize testing data\n",
    "for src_idx in range(src_num):\n",
    "    for tmp_idx, tmp in enumerate(test_data):\n",
    "        \n",
    "        tmpdata = list(tmp)\n",
    "        tmpdata[2] = list(tmpdata[2])\n",
    "        \n",
    "        tmpdata[2][src_idx] = (tmpdata[2][src_idx] - src_m[src_idx])/(src_std[src_idx] + 1e-5)\n",
    "        test_data[tmp_idx] = tmpdata\n",
    "\n",
    "print(\"\\n\")\n",
    "print(train_data[0][2][0])\n",
    "print(val_data[0][2][0])\n",
    "print(test_data[0][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto market \n",
    "\n",
    "auto_tr_data = [ [i[0], i[1], [i[2][0], i[2][2]]] for i in train_data ]\n",
    "print(np.shape(auto_tr_data[0][2][0]))\n",
    "\n",
    "auto_val_data =  [ [i[0], i[1], [i[2][0], i[2][2]]] for i in val_data ]\n",
    "auto_test_data = [ [i[0], i[1], [i[2][0], i[2][2]]] for i in test_data ]\n",
    "\n",
    "train_data = auto_tr_data\n",
    "val_data = auto_val_data\n",
    "test_data = auto_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(train_data, open(\"../../datasets/bitcoin/market2_tar10_len10/train.p\", \"wb\" ))\n",
    "pickle.dump(val_data,   open(\"../../datasets/bitcoin/market2_tar10_len10/val.p\", \"wb\" ))\n",
    "pickle.dump(test_data,  open(\"../../datasets/bitcoin/market2_tar10_len10/test.p\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- load existing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# [y, timestamp, x]\n",
    "train_data = pickle.load(open(\"../../datasets/bitcoin/market2_tar1_len10/train.p\", \"rb\"), encoding = 'latin1')\n",
    "val_data = pickle.load(open(  \"../../datasets/bitcoin/market2_tar1_len10/val.p\", \"rb\"), encoding = 'latin1')\n",
    "test_data = pickle.load(open( \"../../datasets/bitcoin/market2_tar1_len10/test.p\", \"rb\"), encoding = 'latin1')\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "print([np.shape(i) for i in train_data[0][2]])\n",
    "print([np.shape(i) for i in val_data[0][2]])\n",
    "print([np.shape(i) for i in test_data[0][2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------helper functions for removing daily patterns\n",
    "\n",
    "from datetime import datetime\n",
    "def get_intra_day_index(tmp_t, agg_level=60):\n",
    "    tmp = datetime.utcfromtimestamp(tmp_t)\n",
    "    index = int((tmp.hour*60+tmp.minute)/agg_level)\n",
    "    return index\n",
    "\n",
    "def get_avg_train_volume(tr_dta, agg_level=60):\n",
    "    vol_train = [ x[0] for x in tr_dta ]\n",
    "    timestamp_train = [ x[1] for x in tr_dta ]\n",
    "    my_train_dict = {'volume': vol_train, 'timestamp': timestamp_train }\n",
    "    df_train_tmp = pd.DataFrame(data=my_train_dict)\n",
    "    df_train_tmp['intraday_idx'] = df_train_tmp['timestamp'].map( lambda x: get_intra_day_index(x) )\n",
    "    avg_vol_dict_train = dict(df_train_tmp.groupby(['intraday_idx'])['volume'].mean())\n",
    "    \n",
    "    #dictionary: key is intraday index, value is average volume\n",
    "    return avg_vol_dict_train\n",
    "\n",
    "# ------\n",
    "\n",
    "tr_hour_avg_vol = get_avg_train_volume(train_data)\n",
    "\n",
    "for tmp_ins in train_data:\n",
    "    tmp_y = tmp_ins[0]\n",
    "    tmp_time = tmp_ins[1]\n",
    "    \n",
    "    tmp_y_normlizer = tr_hour_avg_vol[get_intra_day_index(tmp_time)]\n",
    "    tmp_y_dese = tmp_y/tmp_y_normlizer\n",
    "    \n",
    "    tmp_ins[0] = [tmp_y, tmp_y_normlizer, tmp_y_dese]\n",
    "    \n",
    "for tmp_ins in val_data:\n",
    "    tmp_y = tmp_ins[0]\n",
    "    tmp_time = tmp_ins[1]\n",
    "    \n",
    "    tmp_y_normlizer = tr_hour_avg_vol[get_intra_day_index(tmp_time)]\n",
    "    tmp_y_dese = tmp_y/tmp_y_normlizer\n",
    "    \n",
    "    tmp_ins[0] = [tmp_y, tmp_y_normlizer, tmp_y_dese]\n",
    "    \n",
    "for tmp_ins in test_data:\n",
    "    tmp_y = tmp_ins[0]\n",
    "    tmp_time = tmp_ins[1]\n",
    "    \n",
    "    tmp_y_normlizer = tr_hour_avg_vol[get_intra_day_index(tmp_time)]\n",
    "    tmp_y_dese = tmp_y/tmp_y_normlizer\n",
    "    \n",
    "    tmp_ins[0] = [tmp_y, tmp_y_normlizer, tmp_y_dese]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(train_data, open(\"../../datasets/bitcoin/market2_tar1_len10/train_dese.p\", \"wb\" ))\n",
    "pickle.dump(val_data,   open(\"../../datasets/bitcoin/market2_tar1_len10/val_dese.p\", \"wb\" ))\n",
    "pickle.dump(test_data,  open(\"../../datasets/bitcoin/market2_tar1_len10/test_dese.p\", \"wb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# [y, timestamp, x]\n",
    "train_data = pickle.load(open(\"../../datasets/bitcoin/market2_tar10_len10/train_dese.p\", \"rb\"), encoding = 'latin1')\n",
    "val_data = pickle.load(open(  \"../../datasets/bitcoin/market2_tar10_len10/train_dese.p\", \"rb\"), encoding = 'latin1')\n",
    "test_data = pickle.load(open( \"../../datasets/bitcoin/market2_tar10_len10/train_dese.p\", \"rb\"), encoding = 'latin1')\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "print([np.shape(i) for i in train_data[0][2]])\n",
    "print([np.shape(i) for i in val_data[0][2]])\n",
    "print([np.shape(i) for i in test_data[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
