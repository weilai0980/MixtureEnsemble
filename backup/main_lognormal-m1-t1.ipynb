{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_rnn_units.py:15: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.kde module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_rnn_units.py:14: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np.random.seed(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_optimization.py:233: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "120208 17173 34346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:45: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tmpx.append(np.asarray([tmp[2][src_idx] for tmp in data]))\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:46: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  print(\"src \" + str(src_idx) + \" : \", np.shape(tmpx[-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src 0 :  (120208, 9, 7)\n",
      "src 1 :  (120208, 9, 7)\n",
      "src 2 :  (120208, 9, 13)\n",
      "src 3 :  (120208, 9, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:48: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tmpy = np.asarray([tmp[0] for tmp in data])\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:51: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  return tmpx, np.expand_dims(tmpy, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src 0 :  (17173, 9, 7)\n",
      "src 1 :  (17173, 9, 7)\n",
      "src 2 :  (17173, 9, 13)\n",
      "src 3 :  (17173, 9, 13)\n",
      "src 0 :  (34346, 9, 7)\n",
      "src 1 :  (34346, 9, 7)\n",
      "src 2 :  (34346, 9, 13)\n",
      "src 3 :  (34346, 9, 13)\n",
      "training:  120208 120208\n",
      "validation:  17173 17173\n",
      "testing:  34346 34346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:473: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:474: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:475: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:62: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  max_dim_t =  max([np.shape(x[i][0])[0] for i in range(num_src)])\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:63: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  max_dim_d =  max([np.shape(x[i][0])[1] for i in range(num_src)])\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:71: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  zero_mask = np.zeros(target_shape)\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:73: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tmp_t = np.shape(x[tmp_src][0])[0]\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:74: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tmp_d = np.shape(x[tmp_src][0])[1]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:495: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes after padding:  (4, 120208, 9, 13) (4, 17173, 9, 13) (4, 34346, 9, 13)\n",
      "src 0 shape:  (9, 13)\n",
      "src 1 shape:  (9, 13)\n",
      "src 2 shape:  (9, 13)\n",
      "src 3 shape:  (9, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:548: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:236: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np.random.seed(100)\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:272: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tmp_hpara = tmp_hpara + (i[0] + (i[1] - i[0])*np.random.random(), )\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:175: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  tr_dict[\"batch_per_epoch\"] = int(np.ceil(1.0*shape_x_dict[\"N\"]/int(hpara_dict[\"batch_size\"])))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:254: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:143: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_linear_units.py:270: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_linear_units.py:273: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:279: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:537: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:541: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:277: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  lk_src = tf.exp(-0.5*tf.square(self.y - mean_stack)*inv_var_stack)*tf.sqrt(0.5/np.pi*inv_var_stack)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:617: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:668: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:685: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:427: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np.random.seed(1)\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:434: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  self.num_batch = int(np.ceil(1.0*num_ins/int(batch_size)))\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:437: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np.random.shuffle(self.ids)\n",
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:443: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np.random.shuffle(self.ids)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\mixture_models.py:726: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "\n",
      " --- At epoch 0 : \n",
      "  [0, [50.64809, 47.235973, 5.4595222, 5.8775034], [37.119896, 25.035402, 97.30511, 4.4799376], 0] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.4799376, 0.091482796, 0.31370565, array([[0.18629618, 0.5148388 , 0.14804035, 0.15082462],\n",
      "       [0.19272016, 0.49544248, 0.16542992, 0.14640743],\n",
      "       [0.20327796, 0.48037302, 0.1601863 , 0.15616268],\n",
      "       [0.21348727, 0.46133763, 0.1548231 , 0.17035201],\n",
      "       [0.21934828, 0.47216144, 0.12523188, 0.18325837]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:360: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- At epoch 1 : \n",
      "  [1, [50.531322, 47.11455, 5.436903, 5.154782], [37.08829, 24.977781, 97.0253, 4.548921], 1] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.548921, 0.018606462, 0.24936628, array([[0.07571647, 0.8276628 , 0.04455418, 0.05206652],\n",
      "       [0.09619615, 0.77864903, 0.06153633, 0.06361843],\n",
      "       [0.10454322, 0.76330006, 0.06334534, 0.06881137],\n",
      "       [0.1192984 , 0.72930604, 0.0701636 , 0.081232  ],\n",
      "       [0.13158104, 0.70962715, 0.06696226, 0.09182959]], dtype=float32)]\n",
      "\n",
      " --- At epoch 2 : \n",
      "  [2, [50.288303, 46.85887, 5.3928223, 4.8288093], [36.981457, 24.7681, 95.96089, 4.613072], 2] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.613072, 0.00070380303, 0.1966023, array([[3.40537704e-03, 9.94329512e-01, 1.63388811e-03, 6.31340488e-04],\n",
      "       [7.58404750e-03, 9.87272918e-01, 3.91420955e-03, 1.22887362e-03],\n",
      "       [8.39125831e-03, 9.86134350e-01, 4.16130992e-03, 1.31303805e-03],\n",
      "       [1.20928995e-02, 9.80019689e-01, 5.97630581e-03, 1.91105297e-03],\n",
      "       [1.79412160e-02, 9.71015871e-01, 8.07605591e-03, 2.96686939e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 3 : \n",
      "  [3, [49.90006, 46.450684, 5.320889, 4.746288], [36.803005, 24.404257, 94.116936, 4.6188374], 3] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6188374, 1.8374678e-05, 0.13400875, array([[6.2699791e-04, 9.9896646e-01, 2.4580772e-04, 1.6072445e-04],\n",
      "       [1.5292309e-03, 9.9748540e-01, 6.5383659e-04, 3.3162360e-04],\n",
      "       [1.7881807e-03, 9.9711418e-01, 7.2934182e-04, 3.6831526e-04],\n",
      "       [3.0577963e-03, 9.9507755e-01, 1.2440253e-03, 6.2065606e-04],\n",
      "       [5.4110917e-03, 9.9142319e-01, 2.0580059e-03, 1.1076939e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 4 : \n",
      "  [4, [49.401863, 45.9244, 5.22289, 4.677881], [36.58766, 23.95054, 91.80636, 4.586453], 4] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.586453, 3.104964e-08, 0.07829213, array([[1.1343214e-03, 9.9833292e-01, 3.4967795e-04, 1.8316816e-04],\n",
      "       [1.9924408e-03, 9.9699080e-01, 7.2483625e-04, 2.9190310e-04],\n",
      "       [2.5300211e-03, 9.9629045e-01, 8.4069296e-04, 3.3895599e-04],\n",
      "       [4.5400141e-03, 9.9336243e-01, 1.5092281e-03, 5.8826152e-04],\n",
      "       [8.1128199e-03, 9.8824441e-01, 2.5550749e-03, 1.0876376e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 5 : \n",
      "  [5, [48.758717, 45.242504, 5.0969205, 4.6409316], [36.3351, 23.38848, 88.933174, 4.5781784], 5] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.5781784, 5.3736427e-15, 0.03932911, array([[1.0619599e-03, 9.9833006e-01, 3.2240286e-04, 2.8564481e-04],\n",
      "       [1.7164915e-03, 9.9729747e-01, 5.7375478e-04, 4.1234650e-04],\n",
      "       [2.3228917e-03, 9.9642628e-01, 7.2432600e-04, 5.2643951e-04],\n",
      "       [4.4111246e-03, 9.9317247e-01, 1.4095048e-03, 1.0068576e-03],\n",
      "       [9.2108902e-03, 9.8587960e-01, 2.7668837e-03, 2.1426044e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 6 : \n",
      "  [6, [47.97631, 44.40856, 4.9400864, 4.594252], [36.04832, 22.710793, 85.48309, 4.599827], 6] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.599827, 3.8342912e-32, 0.018590787, array([[5.3704819e-03, 9.9233389e-01, 9.8748319e-04, 1.3081654e-03],\n",
      "       [6.3855047e-03, 9.9081099e-01, 1.2989659e-03, 1.5046349e-03],\n",
      "       [8.9903669e-03, 9.8747689e-01, 1.5762334e-03, 1.9565723e-03],\n",
      "       [1.5682915e-02, 9.7755253e-01, 3.1960132e-03, 3.5685399e-03],\n",
      "       [3.3577882e-02, 9.5269555e-01, 6.0917665e-03, 7.6347413e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 7 : \n",
      "  [7, [47.072865, 43.4469, 4.7670684, 4.551932], [35.727947, 21.922443, 81.51162, 4.6031523], 7] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6031523, 0.0, 0.007960044, array([[0.01488092, 0.98023087, 0.00219115, 0.00269702],\n",
      "       [0.01550982, 0.9790122 , 0.00248157, 0.00299644],\n",
      "       [0.02307055, 0.96992975, 0.00298579, 0.00401389],\n",
      "       [0.03357526, 0.9528994 , 0.00684642, 0.00667899],\n",
      "       [0.07066096, 0.9050343 , 0.01109076, 0.01321399]], dtype=float32)]\n",
      "\n",
      " --- At epoch 8 : \n",
      "  [8, [46.024868, 42.32462, 4.56607, 4.5103874], [35.400723, 21.039057, 76.98759, 4.6424484], 8] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6424484, 0.0, 0.0036580672, array([[0.02198728, 0.9697673 , 0.00406126, 0.00418413],\n",
      "       [0.02328276, 0.96759284, 0.00432793, 0.00479656],\n",
      "       [0.03244127, 0.95663065, 0.00485691, 0.0060711 ],\n",
      "       [0.03817564, 0.9417224 , 0.01145313, 0.00864886],\n",
      "       [0.0704172 , 0.9006352 , 0.01479061, 0.01415705]], dtype=float32)]\n",
      "\n",
      " --- At epoch 9 : \n",
      "  [9, [44.940754, 41.15286, 4.353198, 4.453505], [35.108208, 20.135143, 72.15217, 4.6890936], 9] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6890936, 0.0, 0.0007083104, array([[0.01767264, 0.9723573 , 0.00485119, 0.00511889],\n",
      "       [0.0199038 , 0.96890265, 0.00504972, 0.00614384],\n",
      "       [0.02531385, 0.96212995, 0.00522216, 0.00733404],\n",
      "       [0.02674926, 0.95195043, 0.0121153 , 0.00918508],\n",
      "       [0.04156768, 0.9324436 , 0.0132315 , 0.01275716]], dtype=float32)]\n",
      "\n",
      " --- At epoch 10 : \n",
      "  [10, [43.992516, 40.139603, 4.17785, 4.404612], [34.84776, 19.323168, 67.6455, 4.765728], 10] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.765728, 0.0, 0.000366393, array([[0.01111992, 0.97821665, 0.00594265, 0.00472072],\n",
      "       [0.0128735 , 0.97540116, 0.00608478, 0.0056406 ],\n",
      "       [0.01574252, 0.97151023, 0.00613488, 0.00661239],\n",
      "       [0.01621289, 0.96137595, 0.0144715 , 0.00793957],\n",
      "       [0.02492216, 0.9480323 , 0.01613312, 0.01091239]], dtype=float32)]\n",
      "\n",
      " --- At epoch 11 : \n",
      "  [11, [43.12531, 39.208385, 4.0204325, 4.3524194], [34.633938, 18.578794, 63.387783, 4.8391113], 11] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.8391113, 1.4596501e-21, 0.00045227967, array([[0.00792716, 0.97713256, 0.00950778, 0.00543246],\n",
      "       [0.00919323, 0.9740296 , 0.01023011, 0.00654694],\n",
      "       [0.01092938, 0.9707493 , 0.01068738, 0.00763394],\n",
      "       [0.01118872, 0.957232  , 0.02260627, 0.00897307],\n",
      "       [0.01647677, 0.9461487 , 0.02552893, 0.01184563]], dtype=float32)]\n",
      "\n",
      " --- At epoch 12 : \n",
      "  [12, [42.339714, 38.35824, 3.8804848, 4.2973504], [34.46863, 17.915377, 59.473454, 4.9556017], 12] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.9556017, 1.5461835e-12, 0.00070384424, array([[0.00596861, 0.9737551 , 0.01353575, 0.00674052],\n",
      "       [0.00681   , 0.969204  , 0.0159956 , 0.0079903 ],\n",
      "       [0.00792308, 0.96494514, 0.01791603, 0.0092157 ],\n",
      "       [0.00809734, 0.9541129 , 0.02709311, 0.01069671],\n",
      "       [0.01141682, 0.94225365, 0.03280704, 0.0135225 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 13 : \n",
      "  [13, [41.6226, 37.610565, 3.7707832, 4.2391205], [34.257328, 17.217175, 55.25035, 5.1293154], 13] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.1293154, 6.200688e-11, 0.00034532032, array([[0.00339827, 0.9763566 , 0.01530149, 0.00494359],\n",
      "       [0.0039504 , 0.97261435, 0.01745027, 0.00598504],\n",
      "       [0.0045986 , 0.9694243 , 0.01903468, 0.0069423 ],\n",
      "       [0.00478064, 0.9539384 , 0.03321416, 0.00806683],\n",
      "       [0.00682242, 0.9439045 , 0.03900274, 0.01027031]], dtype=float32)]\n",
      "\n",
      " --- At epoch 14 : \n",
      "  [14, [40.923664, 36.84517, 3.6512437, 4.177572], [34.155495, 16.627243, 51.454037, 5.306645], 14] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.306645, 1.0165221e-09, 0.0004365722, array([[0.00233193, 0.9738401 , 0.01867208, 0.00515596],\n",
      "       [0.00267683, 0.9687942 , 0.02238587, 0.00614313],\n",
      "       [0.00310724, 0.9642904 , 0.02544552, 0.00715684],\n",
      "       [0.00328104, 0.95071876, 0.03766174, 0.00833841],\n",
      "       [0.0046711 , 0.9381188 , 0.04666753, 0.01054256]], dtype=float32)]\n",
      "\n",
      " --- At epoch 15 : \n",
      "  [15, [40.291367, 36.152885, 3.544616, 4.1137047], [34.04987, 16.082884, 47.832497, 5.571898], 15] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.571898, 1.2561105e-17, 0.00047224323, array([[0.00170899, 0.96955943, 0.02302392, 0.00570763],\n",
      "       [0.00193057, 0.96365213, 0.02772389, 0.00669337],\n",
      "       [0.00224224, 0.9580866 , 0.03192647, 0.00774463],\n",
      "       [0.00237544, 0.9424459 , 0.04618965, 0.00898893],\n",
      "       [0.00329535, 0.9284685 , 0.05707561, 0.01116054]], dtype=float32)]\n",
      "\n",
      " --- At epoch 16 : \n",
      "  [16, [39.615505, 35.400913, 3.4132223, 4.0487485], [33.99205, 15.507031, 43.892727, 5.847775], 16] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.847775, 1.158717e-16, 0.0007363606, array([[0.00123708, 0.9688334 , 0.02394888, 0.00598066],\n",
      "       [0.00139378, 0.9634623 , 0.02809856, 0.00704537],\n",
      "       [0.00161677, 0.9586113 , 0.03167546, 0.00809649],\n",
      "       [0.00175145, 0.9446133 , 0.0442365 , 0.00939871],\n",
      "       [0.00231149, 0.93377405, 0.05255967, 0.01135483]], dtype=float32)]\n",
      "\n",
      " --- At epoch 17 : \n",
      "  [17, [39.105663, 34.82787, 3.3220215, 3.9774258], [33.946423, 15.089602, 40.793808, 6.23192], 17] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.23192, 6.562204e-17, 0.00068289496, array([[0.00116533, 0.959583  , 0.03126569, 0.0079861 ],\n",
      "       [0.00130902, 0.95348006, 0.03594252, 0.00926832],\n",
      "       [0.00150125, 0.94830775, 0.03971729, 0.01047369],\n",
      "       [0.00163855, 0.93098295, 0.05534357, 0.01203494],\n",
      "       [0.002069  , 0.91884476, 0.06486733, 0.01421889]], dtype=float32)]\n",
      "\n",
      " --- At epoch 18 : \n",
      "  [18, [38.50462, 34.13583, 3.2198164, 3.903902], [33.978687, 14.633544, 37.017765, 6.5528708], 18] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5528708, 0.004125101, 0.00088283536, array([[0.00121525, 0.95516187, 0.03470086, 0.00892194],\n",
      "       [0.00138064, 0.945709  , 0.04256333, 0.01034702],\n",
      "       [0.0015855 , 0.93821114, 0.04861425, 0.01158904],\n",
      "       [0.00176838, 0.92588145, 0.05886253, 0.01348758],\n",
      "       [0.00216366, 0.90965843, 0.07224659, 0.01593128]], dtype=float32)]\n",
      "\n",
      " --- At epoch 19 : \n",
      "  [19, [38.066406, 33.631226, 3.153393, 3.815723], [33.98602, 14.215186, 33.354626, 6.656411], 19] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.656411, 0.01756228, 9.884024e-05, array([[0.00230219, 0.9421133 , 0.04345469, 0.01212983],\n",
      "       [0.00266192, 0.9311918 , 0.05233848, 0.01380779],\n",
      "       [0.00300338, 0.9223588 , 0.05945749, 0.01518029],\n",
      "       [0.00336776, 0.9084472 , 0.0707055 , 0.01747949],\n",
      "       [0.00391899, 0.89162105, 0.08430286, 0.02015713]], dtype=float32)]\n",
      "\n",
      " --- At epoch 20 : \n",
      "  [20, [37.616707, 33.100132, 3.074612, 3.7227068], [34.03095, 13.792347, 29.178415, 6.514968], 20] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.514968, 0.033052176, 0.0009812483, array([[0.00844258, 0.9279486 , 0.04890029, 0.0147086 ],\n",
      "       [0.00992302, 0.9155117 , 0.05800864, 0.01655664],\n",
      "       [0.01087396, 0.90551054, 0.06544668, 0.01816884],\n",
      "       [0.01225119, 0.8906511 , 0.07629044, 0.02080726],\n",
      "       [0.01428085, 0.8717484 , 0.09010179, 0.02386899]], dtype=float32)]\n",
      "\n",
      " --- At epoch 21 : \n",
      "  [21, [37.384106, 32.81055, 3.0128558, 3.662144], [34.102608, 13.715613, 28.30359, 6.34114], 21] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.34114, 0.022962686, 0.0008128272, array([[0.02421825, 0.9098665 , 0.05020197, 0.01571319],\n",
      "       [0.02946741, 0.89420503, 0.05865006, 0.01767754],\n",
      "       [0.03097265, 0.8840795 , 0.0656039 , 0.0193439 ],\n",
      "       [0.03458903, 0.8630572 , 0.08064214, 0.02171158],\n",
      "       [0.03980605, 0.8423105 , 0.09317198, 0.02471147]], dtype=float32)]\n",
      "\n",
      " --- At epoch 22 : \n",
      "  [22, [37.182602, 32.556717, 2.9532087, 3.609357], [34.127365, 13.573478, 26.661877, 6.209797], 22] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.209797, 0.014935874, 0.001307995, array([[0.04680455, 0.895519  , 0.04279913, 0.01487725],\n",
      "       [0.05991382, 0.8742028 , 0.04896718, 0.01691624],\n",
      "       [0.05985849, 0.8675776 , 0.05408086, 0.01848303],\n",
      "       [0.06624746, 0.8410928 , 0.07197984, 0.02067988],\n",
      "       [0.07763442, 0.81679046, 0.08192635, 0.02364874]], dtype=float32)]\n",
      "\n",
      " --- At epoch 23 : \n",
      "  [23, [37.188316, 32.540745, 2.9602044, 3.5698705], [34.19268, 13.620534, 26.670748, 6.0655947], 23] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0655947, 0.0090248175, 0.0010353496, array([[0.07849018, 0.86694837, 0.03907057, 0.01549088],\n",
      "       [0.09967478, 0.83685935, 0.04608425, 0.01738154],\n",
      "       [0.09818599, 0.8296909 , 0.05301755, 0.01910557],\n",
      "       [0.106576  , 0.8080837 , 0.06399199, 0.0213483 ],\n",
      "       [0.12892693, 0.77104455, 0.07559538, 0.02443311]], dtype=float32)]\n",
      "\n",
      " --- At epoch 24 : \n",
      "  [24, [37.27561, 32.65315, 2.9757764, 3.548234], [34.086136, 13.636754, 27.00579, 5.9990425], 24] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9990425, 0.0035091178, 0.00034080032, array([[0.10753198, 0.8383199 , 0.03987188, 0.01427623],\n",
      "       [0.1333557 , 0.805507  , 0.04488843, 0.01624883],\n",
      "       [0.1331158 , 0.7995674 , 0.04956874, 0.01774804],\n",
      "       [0.1401587 , 0.7700267 , 0.07018226, 0.01963232],\n",
      "       [0.17205113, 0.7270554 , 0.07876918, 0.02212428]], dtype=float32)]\n",
      "\n",
      " --- At epoch 25 : \n",
      "  [25, [37.298557, 32.666836, 2.9701288, 3.5354352], [34.120014, 13.6840725, 27.306452, 5.997523], 25] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.997523, 0.00074354926, 0.00030599124, array([[0.12522063, 0.8230253 , 0.03830026, 0.01345374],\n",
      "       [0.15399055, 0.7860951 , 0.04460782, 0.01530652],\n",
      "       [0.15466212, 0.7788258 , 0.04987114, 0.01664092],\n",
      "       [0.16194732, 0.7516361 , 0.06786957, 0.01854696],\n",
      "       [0.20106743, 0.6999304 , 0.07820767, 0.02079448]], dtype=float32)]\n",
      "\n",
      " --- At epoch 26 : \n",
      "  [26, [37.2805, 32.642292, 2.9613328, 3.523859], [34.121124, 13.619704, 26.562332, 6.1778355], 26] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1778355, 9.527837e-06, 0.001109377, array([[0.130495  , 0.81914544, 0.03647972, 0.01387977],\n",
      "       [0.16285534, 0.7791582 , 0.04189315, 0.01609339],\n",
      "       [0.1617437 , 0.7751782 , 0.04569006, 0.01738801],\n",
      "       [0.16890797, 0.7472671 , 0.06433778, 0.0194871 ],\n",
      "       [0.21188165, 0.6928349 , 0.07336476, 0.02191875]], dtype=float32)]\n",
      "\n",
      " --- At epoch 27 : \n",
      "  [27, [37.31453, 32.6838, 2.9710033, 3.5118296], [34.116135, 13.67176, 27.05152, 6.225528], 27] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.225528, 2.199412e-10, 0.000750788, array([[0.14304048, 0.8047025 , 0.03860381, 0.01365316],\n",
      "       [0.17396669, 0.7652196 , 0.04507201, 0.01574163],\n",
      "       [0.17463349, 0.7585649 , 0.04976973, 0.01703184],\n",
      "       [0.18276593, 0.73262286, 0.06541689, 0.01919434],\n",
      "       [0.22834754, 0.6745041 , 0.07551775, 0.0216306 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 28 : \n",
      "  [28, [37.24583, 32.62136, 2.9796093, 3.502952], [34.070656, 13.582661, 26.156895, 6.271143], 28] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.271143, 1.053388e-10, 0.0009771023, array([[0.14193994, 0.80869216, 0.0358933 , 0.01347458],\n",
      "       [0.17312546, 0.7679697 , 0.04310005, 0.0158048 ],\n",
      "       [0.1777325 , 0.75709724, 0.04795355, 0.01721672],\n",
      "       [0.18564029, 0.7346829 , 0.06011388, 0.01956291],\n",
      "       [0.23577179, 0.67082536, 0.0710095 , 0.02239332]], dtype=float32)]\n",
      "\n",
      " --- At epoch 29 : \n",
      "  [29, [37.36891, 32.775288, 2.9986658, 3.4916217], [34.031925, 13.670201, 27.188774, 6.4334292], 29] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4334292, 8.815454e-11, 0.0004512356, array([[0.1589776 , 0.78395677, 0.04090891, 0.01615674],\n",
      "       [0.19064789, 0.74314123, 0.04741392, 0.01879696],\n",
      "       [0.19617271, 0.7318446 , 0.05167406, 0.02030865],\n",
      "       [0.20208625, 0.706943  , 0.06794815, 0.02302266],\n",
      "       [0.24956317, 0.6475017 , 0.07747318, 0.02546192]], dtype=float32)]\n",
      "\n",
      " --- At epoch 30 : \n",
      "  [30, [37.313957, 32.72603, 2.994078, 3.4819436], [34.00993, 13.692364, 27.515007, 6.482276], 30] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.482276, 1.3685112e-13, 0.00080622756, array([[0.17413618, 0.76684874, 0.04183047, 0.01718467],\n",
      "       [0.20750642, 0.722028  , 0.05040241, 0.0200632 ],\n",
      "       [0.21329369, 0.70925033, 0.0558831 , 0.0215729 ],\n",
      "       [0.21904635, 0.6883755 , 0.06784575, 0.02473236],\n",
      "       [0.27023977, 0.62423426, 0.07837214, 0.02715385]], dtype=float32)]\n",
      "\n",
      " --- At epoch 31 : \n",
      "  [31, [37.309757, 32.70727, 2.9854476, 3.4745002], [34.009346, 13.70171, 27.478243, 6.522921], 31] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.522921, 8.4190777e-10, 0.0005088724, array([[0.17536142, 0.7624677 , 0.04479227, 0.01737862],\n",
      "       [0.21083878, 0.71514934, 0.05365027, 0.02036163],\n",
      "       [0.21657561, 0.7021214 , 0.05913316, 0.02216979],\n",
      "       [0.22351572, 0.67807686, 0.0735351 , 0.02487238],\n",
      "       [0.27628347, 0.61122143, 0.08501961, 0.02747555]], dtype=float32)]\n",
      "\n",
      " --- At epoch 32 : \n",
      "  [32, [37.35627, 32.774746, 3.0061295, 3.4656587], [33.981056, 13.715634, 27.748854, 6.4966664], 32] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4966664, 8.820578e-15, 0.0005191181, array([[0.18905216, 0.7468085 , 0.04561567, 0.01852369],\n",
      "       [0.22563292, 0.69791156, 0.05476034, 0.02169521],\n",
      "       [0.23435126, 0.68100196, 0.06086604, 0.0237807 ],\n",
      "       [0.24103   , 0.6580711 , 0.0743007 , 0.02659821],\n",
      "       [0.29726785, 0.58674324, 0.08640582, 0.02958309]], dtype=float32)]\n",
      "\n",
      " --- At epoch 33 : \n",
      "  [33, [37.372566, 32.832375, 3.03428, 3.4590695], [33.87514, 13.656192, 27.406681, 6.4529395], 33] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4529395, 8.041462e-25, 0.00046353607, array([[0.19480869, 0.74055487, 0.04532109, 0.01931533],\n",
      "       [0.23279472, 0.6894712 , 0.05469652, 0.0230375 ],\n",
      "       [0.24308234, 0.67150706, 0.06012827, 0.02528229],\n",
      "       [0.24757479, 0.6496815 , 0.07425765, 0.02848608],\n",
      "       [0.3091131 , 0.57436055, 0.08516233, 0.03136404]], dtype=float32)]\n",
      "\n",
      " --- At epoch 34 : \n",
      "  [34, [37.39527, 32.872147, 3.0505035, 3.455195], [33.82973, 13.687801, 27.833239, 6.4867725], 34] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4867725, 6.590357e-15, 0.000519282, array([[0.20759165, 0.7224954 , 0.04878643, 0.02112653],\n",
      "       [0.2466721 , 0.6691806 , 0.05890967, 0.02523767],\n",
      "       [0.2594503 , 0.6479903 , 0.06491856, 0.02764086],\n",
      "       [0.26010624, 0.6273239 , 0.08136161, 0.03120822],\n",
      "       [0.32777262, 0.5450781 , 0.09292081, 0.03422849]], dtype=float32)]\n",
      "\n",
      " --- At epoch 35 : \n",
      "  [35, [37.36484, 32.84072, 3.039454, 3.4485157], [33.813137, 13.66029, 27.671442, 6.3892884], 35] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3892884, 4.679482e-12, 0.00092592667, array([[0.21751112, 0.7123238 , 0.04923873, 0.02092634],\n",
      "       [0.25848204, 0.65737015, 0.05897392, 0.02517389],\n",
      "       [0.27216542, 0.63576573, 0.06439988, 0.02766899],\n",
      "       [0.27391797, 0.61304134, 0.0819958 , 0.03104483],\n",
      "       [0.3436636 , 0.5296182 , 0.0925946 , 0.03412359]], dtype=float32)]\n",
      "\n",
      " --- At epoch 36 : \n",
      "  [36, [37.43663, 32.933674, 3.0666442, 3.4455974], [33.799114, 13.640574, 27.456308, 6.3138075], 36] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3138075, 1.641632e-16, 0.00063768966, array([[0.21736035, 0.7110394 , 0.05131359, 0.02028659],\n",
      "       [0.25882584, 0.65338993, 0.06314199, 0.02464222],\n",
      "       [0.2750551 , 0.62792945, 0.06974738, 0.02726809],\n",
      "       [0.27667278, 0.6086656 , 0.0840954 , 0.03056629],\n",
      "       [0.35285833, 0.51564837, 0.09712546, 0.0343678 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 37 : \n",
      "  [37, [37.535614, 33.05191, 3.07352, 3.4407053], [33.75421, 13.821659, 29.3463, 6.2548475], 37] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.2548475, 1.0019774e-09, 0.0010052548, array([[0.25267982, 0.6660715 , 0.05560512, 0.02564356],\n",
      "       [0.29258054, 0.6109227 , 0.06609758, 0.03039913],\n",
      "       [0.30803335, 0.58620554, 0.07229082, 0.03347033],\n",
      "       [0.3063912 , 0.5695244 , 0.08734457, 0.03673983],\n",
      "       [0.37758726, 0.48656663, 0.09640008, 0.03944607]], dtype=float32)]\n",
      "\n",
      " --- At epoch 38 : \n",
      "  [38, [37.452618, 32.95733, 3.0724308, 3.4380062], [33.761024, 13.705026, 28.211266, 6.233567], 38] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.233567, 1.9107467e-10, 0.0004315573, array([[0.23593497, 0.6852877 , 0.05430072, 0.02447668],\n",
      "       [0.27895424, 0.6249758 , 0.06634717, 0.02972275],\n",
      "       [0.29526636, 0.59953123, 0.07262536, 0.03257703],\n",
      "       [0.29596362, 0.5807362 , 0.0870656 , 0.03623455],\n",
      "       [0.36969793, 0.49257612, 0.09793529, 0.03979063]], dtype=float32)]\n",
      "\n",
      " --- At epoch 39 : \n",
      "  [39, [37.439674, 32.94168, 3.0608416, 3.4347422], [33.74633, 13.64386, 27.626114, 6.217177], 39] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.217177, 3.2043335e-09, 0.00071799615, array([[0.2370894 , 0.6864649 , 0.05347458, 0.02297111],\n",
      "       [0.2812847 , 0.62615   , 0.06453706, 0.02802819],\n",
      "       [0.29982042, 0.5988744 , 0.07022975, 0.0310754 ],\n",
      "       [0.30163386, 0.5785175 , 0.08576532, 0.03408328],\n",
      "       [0.37610352, 0.48991615, 0.09608583, 0.03789447]], dtype=float32)]\n",
      "\n",
      " --- At epoch 40 : \n",
      "  [40, [37.478455, 33.002056, 3.0877657, 3.4317589], [33.715893, 13.650671, 27.783016, 6.199602], 40] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.199602, 5.4508695e-09, 0.00058026466, array([[0.24618976, 0.6741668 , 0.05574379, 0.02389971],\n",
      "       [0.28940484, 0.6139133 , 0.0675858 , 0.02909606],\n",
      "       [0.3114482 , 0.58213764, 0.07413543, 0.03227876],\n",
      "       [0.31216237, 0.561735  , 0.09037744, 0.03572527],\n",
      "       [0.38947603, 0.46887216, 0.10175771, 0.03989413]], dtype=float32)]\n",
      "\n",
      " --- At epoch 41 : \n",
      "  [41, [37.571457, 33.115227, 3.1109657, 3.4288971], [33.67275, 13.747452, 28.728495, 6.1065655], 41] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1065655, 4.009875e-16, 0.00063821755, array([[0.25459483, 0.6582806 , 0.06103093, 0.02609355],\n",
      "       [0.2972347 , 0.5978316 , 0.07327004, 0.03166362],\n",
      "       [0.31750765, 0.5680089 , 0.07949187, 0.03499157],\n",
      "       [0.31650892, 0.54783094, 0.09740632, 0.0382538 ],\n",
      "       [0.39199638, 0.4575369 , 0.108224  , 0.04224271]], dtype=float32)]\n",
      "\n",
      " --- At epoch 42 : \n",
      "  [42, [37.533318, 33.067142, 3.1079834, 3.4264998], [33.69258, 13.726437, 28.361353, 6.0846453], 42] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0846453, 1.4241404e-10, 0.00035798398, array([[0.24615023, 0.66971266, 0.0585885 , 0.02554852],\n",
      "       [0.28902557, 0.60700154, 0.07281544, 0.03115747],\n",
      "       [0.31107813, 0.57358056, 0.08066975, 0.03467146],\n",
      "       [0.31452507, 0.5542035 , 0.09322319, 0.03804818],\n",
      "       [0.39554566, 0.45420346, 0.10745467, 0.0427962 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 43 : \n",
      "  [43, [37.512756, 33.051216, 3.109205, 3.4241726], [33.66921, 13.702668, 28.224, 6.0868125], 43] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0868125, 1.42526884e-11, 0.00015575229, array([[0.2509637 , 0.6641779 , 0.0575559 , 0.02730249],\n",
      "       [0.29424304, 0.60211325, 0.07030214, 0.0333415 ],\n",
      "       [0.31820637, 0.5674884 , 0.07732911, 0.03697612],\n",
      "       [0.31786725, 0.5500394 , 0.09143566, 0.04065777],\n",
      "       [0.40069014, 0.44951248, 0.10412717, 0.04567017]], dtype=float32)]\n",
      "\n",
      " --- At epoch 44 : \n",
      "  [44, [37.51426, 33.05342, 3.0994942, 3.421317], [33.670815, 13.717056, 28.444113, 6.012814], 44] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.012814, 1.4706131e-07, 0.0001895407, array([[0.26221043, 0.6496973 , 0.06130924, 0.02678306],\n",
      "       [0.30553317, 0.5872038 , 0.07468686, 0.03257619],\n",
      "       [0.32782546, 0.5548266 , 0.08145133, 0.03589659],\n",
      "       [0.32604533, 0.5382635 , 0.09645899, 0.03923223],\n",
      "       [0.40674174, 0.4414594 , 0.10816812, 0.04363076]], dtype=float32)]\n",
      "\n",
      " --- At epoch 45 : \n",
      "  [45, [37.75856, 33.3454, 3.1663475, 3.4191973], [33.63564, 13.849277, 29.662374, 5.9450536], 45] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9450536, 8.200219e-08, 0.00037767302, array([[0.2751174 , 0.6254941 , 0.06776694, 0.03162157],\n",
      "       [0.31599417, 0.56329644, 0.08252583, 0.0381836 ],\n",
      "       [0.33801603, 0.53075016, 0.08989888, 0.04133498],\n",
      "       [0.33228058, 0.5180125 , 0.10375319, 0.04595375],\n",
      "       [0.4097769 , 0.42443323, 0.11538069, 0.05040922]], dtype=float32)]\n",
      "\n",
      " --- At epoch 46 : \n",
      "  [46, [37.564186, 33.1125, 3.1262455, 3.4160905], [33.661373, 13.705359, 28.184847, 5.98095], 46] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.98095, 3.6457326e-10, 0.000101516394, array([[0.2513497 , 0.65978336, 0.06081055, 0.02805642],\n",
      "       [0.29490694, 0.5951751 , 0.07540314, 0.03451475],\n",
      "       [0.32004428, 0.55941117, 0.08262579, 0.03791872],\n",
      "       [0.3187752 , 0.5426513 , 0.09662088, 0.04195256],\n",
      "       [0.40501374, 0.43660712, 0.11063538, 0.04774377]], dtype=float32)]\n",
      "\n",
      " --- At epoch 47 : \n",
      "  [47, [37.572834, 33.118626, 3.120516, 3.4131975], [33.6816, 13.6958, 28.133732, 5.9443665], 47] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9443665, 1.1804187e-11, 4.3050444e-05, array([[0.2551856 , 0.6533052 , 0.0625319 , 0.02897733],\n",
      "       [0.29966557, 0.58707684, 0.07765622, 0.03560138],\n",
      "       [0.3224077 , 0.55370516, 0.08492924, 0.03895788],\n",
      "       [0.32275698, 0.53641117, 0.09798904, 0.04284278],\n",
      "       [0.40527996, 0.43512723, 0.11137952, 0.04821333]], dtype=float32)]\n",
      "\n",
      " --- At epoch 48 : \n",
      "  [48, [37.627728, 33.192467, 3.144263, 3.4105582], [33.629196, 13.740294, 28.527508, 5.9284153], 48] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9284153, 2.3804243e-24, 9.785911e-05, array([[0.25788048, 0.64590806, 0.06508297, 0.03112849],\n",
      "       [0.3001983 , 0.5816386 , 0.07992026, 0.03824286],\n",
      "       [0.32515034, 0.54623735, 0.08692026, 0.04169207],\n",
      "       [0.32030192, 0.5310909 , 0.10230204, 0.04630512],\n",
      "       [0.4036016 , 0.42822504, 0.11582688, 0.05234646]], dtype=float32)]\n",
      "\n",
      " --- At epoch 49 : \n",
      "  [49, [37.630856, 33.205647, 3.1544702, 3.408071], [33.59672, 13.7497225, 28.752754, 5.929344], 49] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.929344, 1.1853417e-09, 3.9038256e-05, array([[0.27114376, 0.630572  , 0.06614286, 0.03214139],\n",
      "       [0.3126713 , 0.56661016, 0.08128041, 0.03943819],\n",
      "       [0.33869937, 0.53036284, 0.08825179, 0.04268602],\n",
      "       [0.32878503, 0.5193661 , 0.10388262, 0.04796628],\n",
      "       [0.41675243, 0.4145534 , 0.1156486 , 0.05304551]], dtype=float32)]\n",
      "\n",
      " --- At epoch 50 : \n",
      "  [50, [37.588264, 33.130344, 3.1234746, 3.406114], [33.70658, 13.65111, 27.666649, 5.901853], 50] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.901853, 2.3120312e-16, 0.00020066381, array([[0.24750622, 0.6560521 , 0.06624296, 0.03019872],\n",
      "       [0.29281446, 0.5872924 , 0.08256068, 0.03733254],\n",
      "       [0.3165385 , 0.552721  , 0.09014359, 0.04059687],\n",
      "       [0.31433535, 0.5366193 , 0.10419558, 0.04484981],\n",
      "       [0.3951277 , 0.43587282, 0.1181215 , 0.05087801]], dtype=float32)]\n",
      "\n",
      " --- At epoch 51 : \n",
      "  [51, [37.654823, 33.22247, 3.160865, 3.4031126], [33.597767, 13.731911, 28.290932, 5.914134], 51] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.914134, 6.503879e-10, 0.00014361834, array([[0.2493629 , 0.6544463 , 0.06388664, 0.03230414],\n",
      "       [0.29552135, 0.58542585, 0.07883474, 0.04021808],\n",
      "       [0.32174364, 0.5492346 , 0.08536536, 0.04365637],\n",
      "       [0.31690836, 0.5322141 , 0.10235667, 0.04852077],\n",
      "       [0.400517  , 0.429124  , 0.11577005, 0.05458896]], dtype=float32)]\n",
      "\n",
      " --- At epoch 52 : \n",
      "  [52, [37.698105, 33.271442, 3.1539726, 3.4003966], [33.64189, 13.761643, 28.738064, 5.8798084], 52] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8798084, 5.304367e-09, 4.2235777e-05, array([[0.26454702, 0.6312996 , 0.07040012, 0.03375323],\n",
      "       [0.30626217, 0.56545526, 0.08698329, 0.04129929],\n",
      "       [0.33281034, 0.528031  , 0.09467044, 0.04448818],\n",
      "       [0.32671767, 0.5144411 , 0.10908376, 0.04975753],\n",
      "       [0.41186345, 0.4095701 , 0.12298123, 0.05558526]], dtype=float32)]\n",
      "\n",
      " --- At epoch 53 : \n",
      "  [53, [37.70111, 33.26974, 3.161243, 3.3981447], [33.637344, 13.771616, 28.756855, 5.8930054], 53] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8930054, 2.9842018e-09, 3.75808e-05, array([[0.25399664, 0.6387374 , 0.07162049, 0.03564553],\n",
      "       [0.29612693, 0.57172096, 0.08812313, 0.04402893],\n",
      "       [0.3224391 , 0.53452337, 0.09561525, 0.04742223],\n",
      "       [0.31650797, 0.5176183 , 0.11265602, 0.05321772],\n",
      "       [0.39846075, 0.41544867, 0.12663761, 0.05945295]], dtype=float32)]\n",
      "\n",
      " --- At epoch 54 : \n",
      "  [54, [37.694965, 33.265896, 3.159536, 3.395475], [33.64043, 13.738807, 28.515081, 5.9157753], 54] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9157753, 4.694738e-06, 7.0410024e-05, array([[0.2607918 , 0.631007  , 0.07228343, 0.03591771],\n",
      "       [0.30357704, 0.5629526 , 0.08909031, 0.04438008],\n",
      "       [0.32941207, 0.52662945, 0.09628452, 0.04767388],\n",
      "       [0.322325  , 0.5124489 , 0.1117808 , 0.05344532],\n",
      "       [0.40563023, 0.40947908, 0.12526427, 0.05962646]], dtype=float32)]\n",
      "\n",
      " --- At epoch 55 : \n",
      "  [55, [37.74887, 33.3312, 3.1775727, 3.393214], [33.6102, 13.788132, 28.858376, 5.910964], 55] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.910964, 6.3483154e-13, 8.902014e-06, array([[0.26006398, 0.6289626 , 0.07439582, 0.03657769],\n",
      "       [0.30378765, 0.5582708 , 0.0927078 , 0.0452337 ],\n",
      "       [0.33135587, 0.5197003 , 0.10056716, 0.04837665],\n",
      "       [0.32243973, 0.5080349 , 0.114842  , 0.05468336],\n",
      "       [0.40625873, 0.40373847, 0.12901738, 0.06098543]], dtype=float32)]\n",
      "\n",
      " --- At epoch 56 : \n",
      "  [56, [37.6904, 33.258923, 3.1690166, 3.3915136], [33.611378, 13.767259, 28.58234, 5.935427], 56] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.935427, 6.2953796e-07, 9.7357595e-05, array([[0.2532466 , 0.6374812 , 0.07215993, 0.03711224],\n",
      "       [0.2952382 , 0.5682572 , 0.09024639, 0.04625826],\n",
      "       [0.32451186, 0.5273137 , 0.09836443, 0.04981006],\n",
      "       [0.31638253, 0.5155233 , 0.1118777 , 0.05621642],\n",
      "       [0.4029155 , 0.40815592, 0.1258719 , 0.06305669]], dtype=float32)]\n",
      "\n",
      " --- At epoch 57 : \n",
      "  [57, [37.788414, 33.37858, 3.1833827, 3.3891807], [33.60058, 13.815957, 29.153341, 5.950946], 57] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.950946, 1.8518568e-12, 0.00015542175, array([[0.27077106, 0.6107112 , 0.07961992, 0.03889773],\n",
      "       [0.3115141 , 0.54312974, 0.0974955 , 0.04786071],\n",
      "       [0.34018826, 0.50447744, 0.10442358, 0.05091077],\n",
      "       [0.3263681 , 0.49484253, 0.12166394, 0.05712551],\n",
      "       [0.40933338, 0.3944762 , 0.13372985, 0.06246062]], dtype=float32)]\n",
      "\n",
      " --- At epoch 58 : \n",
      "  [58, [37.729492, 33.30191, 3.154305, 3.3878217], [33.646713, 13.74822, 28.573586, 5.9676256], 58] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9676256, 2.110382e-08, 7.135036e-05, array([[0.2703605 , 0.6111153 , 0.0812256 , 0.03729866],\n",
      "       [0.31021976, 0.5437327 , 0.1003655 , 0.04568199],\n",
      "       [0.33952212, 0.50352144, 0.10835246, 0.04860397],\n",
      "       [0.3317962 , 0.49109605, 0.12215394, 0.05495379],\n",
      "       [0.41340306, 0.39056587, 0.13549928, 0.0605318 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 59 : \n",
      "  [59, [37.831944, 33.428284, 3.1960394, 3.3858519], [33.592625, 13.845175, 29.37535, 5.992317], 59] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.992317, 1.3993654e-05, 6.213379e-05, array([[0.27705127, 0.5988686 , 0.0838439 , 0.04023623],\n",
      "       [0.31660247, 0.53129345, 0.10297687, 0.04912718],\n",
      "       [0.3455659 , 0.49087837, 0.11109172, 0.05246399],\n",
      "       [0.3354995 , 0.47938454, 0.12665783, 0.05845822],\n",
      "       [0.41989544, 0.37512803, 0.14057098, 0.0644055 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 60 : \n",
      "  [60, [37.8073, 33.399055, 3.1963313, 3.3841991], [33.61889, 13.738693, 28.380018, 6.0116706], 60] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0116706, 1.1254645e-08, 3.6188507e-05, array([[0.26605868, 0.6110147 , 0.084217  , 0.03870957],\n",
      "       [0.30619672, 0.5406462 , 0.10512533, 0.04803178],\n",
      "       [0.33708754, 0.49865773, 0.11293092, 0.05132376],\n",
      "       [0.3243019 , 0.48908296, 0.12925117, 0.05736395],\n",
      "       [0.41253302, 0.37966865, 0.14393377, 0.06386451]], dtype=float32)]\n",
      "\n",
      " --- At epoch 61 : \n",
      "  [61, [37.856983, 33.451694, 3.2087052, 3.3835201], [33.55086, 13.876394, 29.321272, 6.0391054], 61] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0391054, 1.3645738e-23, 5.212102e-05, array([[0.2575749 , 0.61842644, 0.08404829, 0.03995037],\n",
      "       [0.3001342 , 0.5444724 , 0.10536768, 0.05002571],\n",
      "       [0.3303626 , 0.503551  , 0.11286241, 0.05322402],\n",
      "       [0.31769827, 0.49196514, 0.13110594, 0.05923066],\n",
      "       [0.40225172, 0.3851724 , 0.14711696, 0.06545892]], dtype=float32)]\n",
      "\n",
      " --- At epoch 62 : \n",
      "  [62, [37.85888, 33.455235, 3.201545, 3.381069], [33.62804, 13.738436, 28.343578, 6.077309], 62] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.077309, 8.999331e-06, 7.691359e-05, array([[0.26573032, 0.6047821 , 0.08886211, 0.04062546],\n",
      "       [0.3034316 , 0.5355006 , 0.11063327, 0.05043453],\n",
      "       [0.335196  , 0.49256578, 0.11851797, 0.05372028],\n",
      "       [0.3200606 , 0.48298806, 0.1359982 , 0.06095317],\n",
      "       [0.40968695, 0.37215042, 0.15075363, 0.06740902]], dtype=float32)]\n",
      "\n",
      " --- At epoch 63 : \n",
      "  [63, [37.91099, 33.51512, 3.2177813, 3.3796492], [33.5795, 13.88573, 29.578133, 6.079167], 63] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.079167, 4.630444e-08, 8.4085485e-05, array([[0.26963496, 0.5939115 , 0.0916609 , 0.04479256],\n",
      "       [0.30620536, 0.52423596, 0.11398192, 0.05557675],\n",
      "       [0.33626154, 0.48296034, 0.12170219, 0.05907597],\n",
      "       [0.32257584, 0.47177655, 0.13907953, 0.0665681 ],\n",
      "       [0.40868947, 0.3645897 , 0.15351884, 0.07320207]], dtype=float32)]\n",
      "\n",
      " --- At epoch 64 : \n",
      "  [64, [37.97023, 33.588284, 3.227696, 3.3782744], [33.60104, 13.8411255, 29.291456, 6.104418], 64] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.104418, 1.3446979e-08, 5.5339926e-05, array([[0.2851354 , 0.5698868 , 0.10039224, 0.04458557],\n",
      "       [0.3213261 , 0.4990137 , 0.12464446, 0.05501571],\n",
      "       [0.35104078, 0.45947418, 0.13165411, 0.05783097],\n",
      "       [0.3327168 , 0.45241928, 0.14943507, 0.06542884],\n",
      "       [0.41203004, 0.35527745, 0.1619228 , 0.07076967]], dtype=float32)]\n",
      "\n",
      " --- At epoch 65 : \n",
      "  [65, [37.92288, 33.528854, 3.218991, 3.3771338], [33.619785, 13.823561, 29.117073, 6.1757183], 65] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1757183, 8.060526e-08, 0.00016451416, array([[0.2807807 , 0.5741811 , 0.09974777, 0.04529049],\n",
      "       [0.31703204, 0.50269806, 0.12406883, 0.05620106],\n",
      "       [0.34900653, 0.46119848, 0.13069128, 0.05910376],\n",
      "       [0.32942557, 0.4549857 , 0.14904286, 0.06654587],\n",
      "       [0.4119812 , 0.35429496, 0.16180621, 0.07191768]], dtype=float32)]\n",
      "\n",
      " --- At epoch 66 : \n",
      "  [66, [37.99846, 33.601757, 3.2084298, 3.376591], [33.666855, 13.799143, 28.893166, 6.184343], 66] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.184343, 1.8562154e-08, 0.000104953004, array([[0.27613845, 0.57479405, 0.10531934, 0.04374813],\n",
      "       [0.31237328, 0.50259984, 0.13075493, 0.05427201],\n",
      "       [0.34291258, 0.46167672, 0.13806145, 0.05734926],\n",
      "       [0.326218  , 0.4538435 , 0.15657555, 0.06336303],\n",
      "       [0.40964088, 0.35105324, 0.17046364, 0.06884223]], dtype=float32)]\n",
      "\n",
      " --- At epoch 67 : \n",
      "  [67, [38.049206, 33.674675, 3.242509, 3.3745055], [33.560493, 13.965833, 30.176281, 6.190096], 67] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.190096, 1.6626618e-11, 8.020298e-05, array([[0.28387123, 0.56204253, 0.10588636, 0.04819991],\n",
      "       [0.31844985, 0.4894107 , 0.13239214, 0.05974735],\n",
      "       [0.3499499 , 0.4474308 , 0.13986588, 0.06275342],\n",
      "       [0.3293346 , 0.4432224 , 0.15714346, 0.07029954],\n",
      "       [0.4121278 , 0.3435317 , 0.16918048, 0.07516009]], dtype=float32)]\n",
      "\n",
      " --- At epoch 68 : \n",
      "  [68, [38.029266, 33.64829, 3.253015, 3.3737044], [33.54794, 13.955785, 29.883566, 6.2882032], 68] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.2882032, 2.376102e-10, 0.00047101162, array([[0.27764824, 0.56932145, 0.10507987, 0.04795045],\n",
      "       [0.3127744 , 0.49604002, 0.13136187, 0.05982367],\n",
      "       [0.34944466, 0.4486854 , 0.13870877, 0.06316122],\n",
      "       [0.32640833, 0.443441  , 0.15898953, 0.07116113],\n",
      "       [0.4141373 , 0.33463392, 0.17406866, 0.07716008]], dtype=float32)]\n",
      "\n",
      " --- At epoch 69 : \n",
      "  [69, [38.004597, 33.619312, 3.2418518, 3.3728552], [33.558804, 13.945159, 29.867523, 6.284648], 69] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.284648, 3.8694376e-18, 2.7161588e-05, array([[0.2764587 , 0.5662535 , 0.10894471, 0.04834308],\n",
      "       [0.31043094, 0.49044985, 0.1382763 , 0.06084293],\n",
      "       [0.34461072, 0.445603  , 0.14579615, 0.06399015],\n",
      "       [0.32130197, 0.4429771 , 0.16418277, 0.07153811],\n",
      "       [0.4076864 , 0.33736187, 0.1782987 , 0.07665303]], dtype=float32)]\n",
      "\n",
      " --- At epoch 70 : \n",
      "  [70, [37.987976, 33.596066, 3.2267668, 3.3722448], [33.60616, 13.837873, 28.983406, 6.347567], 70] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.347567, 1.0046117e-06, 0.0001582065, array([[0.2829015 , 0.5615594 , 0.10986798, 0.04567115],\n",
      "       [0.31714752, 0.4859439 , 0.13925731, 0.05765124],\n",
      "       [0.35176253, 0.44110766, 0.14659663, 0.06053315],\n",
      "       [0.33061162, 0.4370093 , 0.1649357 , 0.06744338],\n",
      "       [0.4181808 , 0.32888415, 0.1803033 , 0.07263173]], dtype=float32)]\n",
      "\n",
      " --- At epoch 71 : \n",
      "  [71, [37.977024, 33.579906, 3.2154307, 3.3713334], [33.604874, 13.903008, 29.522795, 6.3612456], 71] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3612456, 1.2381637e-12, 0.00012925462, array([[0.27363738, 0.564437  , 0.1140257 , 0.04789994],\n",
      "       [0.307731  , 0.48646408, 0.14524482, 0.06056011],\n",
      "       [0.34028423, 0.4430971 , 0.15312116, 0.06349751],\n",
      "       [0.31939703, 0.4375101 , 0.17147288, 0.07161998],\n",
      "       [0.40714845, 0.3290568 , 0.18729565, 0.07649912]], dtype=float32)]\n",
      "\n",
      " --- At epoch 72 : \n",
      "  [72, [38.021927, 33.626015, 3.2270372, 3.3709435], [33.637497, 13.8503065, 29.043247, 6.3638315], 72] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3638315, 2.2898223e-06, 4.9377428e-05, array([[0.27512708, 0.56192476, 0.11473087, 0.04821726],\n",
      "       [0.31013304, 0.48280987, 0.14577729, 0.06127983],\n",
      "       [0.34356615, 0.4389934 , 0.15311076, 0.06432972],\n",
      "       [0.3233532 , 0.43389326, 0.17131416, 0.07143936],\n",
      "       [0.40905374, 0.32692683, 0.18751785, 0.07650156]], dtype=float32)]\n",
      "\n",
      " --- At epoch 73 : \n",
      "  [73, [38.03447, 33.651344, 3.2401733, 3.3700285], [33.59323, 13.919904, 29.665174, 6.340944], 73] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.340944, 2.7794948e-27, 3.72516e-05, array([[0.2852624 , 0.5459953 , 0.11731533, 0.05142706],\n",
      "       [0.31774583, 0.4684573 , 0.14909263, 0.06470423],\n",
      "       [0.35304835, 0.42327213, 0.15616147, 0.067518  ],\n",
      "       [0.32767358, 0.42113042, 0.17449161, 0.07670436],\n",
      "       [0.4123847 , 0.31556234, 0.19103731, 0.08101571]], dtype=float32)]\n",
      "\n",
      " --- At epoch 74 : \n",
      "  [74, [38.147476, 33.78346, 3.273385, 3.3697062], [33.548965, 14.070723, 30.839725, 6.3940315], 74] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3940315, 4.417476e-10, 8.6749256e-05, array([[0.29285806, 0.52813834, 0.12357625, 0.05542734],\n",
      "       [0.3217825 , 0.45279926, 0.15565355, 0.06976461],\n",
      "       [0.35899276, 0.40737155, 0.16128534, 0.07235034],\n",
      "       [0.33003607, 0.40736791, 0.18091877, 0.0816772 ],\n",
      "       [0.4123928 , 0.3057166 , 0.19658941, 0.08530118]], dtype=float32)]\n",
      "\n",
      " --- At epoch 75 : \n",
      "  [75, [38.064114, 33.6834, 3.2438986, 3.3691125], [33.5814, 13.911284, 29.441479, 6.42221], 75] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.42221, 1.1265907e-12, 7.887295e-05, array([[0.27732682, 0.554708  , 0.11674588, 0.05121937],\n",
      "       [0.30913365, 0.47440302, 0.15061477, 0.06584855],\n",
      "       [0.34612224, 0.42748585, 0.15770431, 0.0686876 ],\n",
      "       [0.3197271 , 0.42733973, 0.17532738, 0.0776058 ],\n",
      "       [0.40874407, 0.31479153, 0.19406672, 0.08239774]], dtype=float32)]\n",
      "\n",
      " --- At epoch 76 : \n",
      "  [76, [38.015232, 33.625626, 3.2394671, 3.3683438], [33.556442, 13.945972, 29.60443, 6.438524], 76] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.438524, 1.662574e-35, 2.2914739e-05, array([[0.28193843, 0.5505024 , 0.11567503, 0.05188407],\n",
      "       [0.31914318, 0.46544272, 0.14870551, 0.06670862],\n",
      "       [0.35497746, 0.42055368, 0.15503989, 0.06942901],\n",
      "       [0.32508436, 0.4216926 , 0.17436188, 0.0788612 ],\n",
      "       [0.41378593, 0.3116283 , 0.19177242, 0.08281332]], dtype=float32)]\n",
      "\n",
      " --- At epoch 77 : \n",
      "  [77, [37.96485, 33.566208, 3.225577, 3.3683162], [33.570057, 13.932024, 29.540243, 6.4914646], 77] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4914646, 4.9675002e-08, 5.9340608e-05, array([[0.2815731 , 0.54731995, 0.11870311, 0.05240387],\n",
      "       [0.3156902 , 0.46418127, 0.1529993 , 0.06712922],\n",
      "       [0.3523516 , 0.41854718, 0.15931824, 0.06978292],\n",
      "       [0.3222897 , 0.41870406, 0.17838688, 0.08061934],\n",
      "       [0.41142595, 0.30821377, 0.19591512, 0.08444511]], dtype=float32)]\n",
      "\n",
      " --- At epoch 78 : \n",
      "  [78, [38.05927, 33.674545, 3.2533243, 3.3675914], [33.570198, 13.946086, 29.668972, 6.4527655], 78] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4527655, 1.1273143e-07, 5.0026814e-05, array([[0.287017  , 0.5378508 , 0.12022776, 0.05490444],\n",
      "       [0.3207837 , 0.45448157, 0.15451708, 0.07021765],\n",
      "       [0.35714582, 0.40859035, 0.16128688, 0.07297691],\n",
      "       [0.32895315, 0.40953618, 0.17849134, 0.08301933],\n",
      "       [0.41589966, 0.29986498, 0.19698833, 0.08724703]], dtype=float32)]\n",
      "\n",
      " --- At epoch 79 : \n",
      "  [79, [37.95928, 33.553078, 3.2137725, 3.3672569], [33.612507, 13.878493, 29.15157, 6.459946], 79] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.459946, 2.6553704e-07, 0.00035644285, array([[0.2841906 , 0.5418669 , 0.1213237 , 0.05261877],\n",
      "       [0.32009053, 0.45720235, 0.15513822, 0.06756896],\n",
      "       [0.35634196, 0.41204506, 0.161319  , 0.07029403],\n",
      "       [0.3286162 , 0.41079265, 0.18036562, 0.08022546],\n",
      "       [0.4148837 , 0.30121836, 0.19932754, 0.08457038]], dtype=float32)]\n",
      "\n",
      " --- At epoch 80 : \n",
      "  [80, [37.93794, 33.52917, 3.2149608, 3.3671236], [33.62045, 13.824096, 28.695639, 6.535994], 80] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.535994, 4.9174927e-16, 7.811744e-05, array([[0.28175202, 0.54574627, 0.1204151 , 0.05208663],\n",
      "       [0.31656232, 0.4597135 , 0.1557959 , 0.06792828],\n",
      "       [0.35297027, 0.4148912 , 0.16170967, 0.07042889],\n",
      "       [0.3235622 , 0.4165056 , 0.18025152, 0.07968063],\n",
      "       [0.41107783, 0.30652726, 0.19868226, 0.08371264]], dtype=float32)]\n",
      "\n",
      " --- At epoch 81 : \n",
      "  [81, [38.100166, 33.719154, 3.246859, 3.3667383], [33.58018, 14.022519, 30.41626, 6.44927], 81] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.44927, 2.8462203e-11, 0.00018032074, array([[0.29611218, 0.5167292 , 0.12878227, 0.05837645],\n",
      "       [0.3269572 , 0.43532407, 0.16369802, 0.07402074],\n",
      "       [0.36394456, 0.3895835 , 0.17009068, 0.07638124],\n",
      "       [0.33373266, 0.3923465 , 0.1867716 , 0.08714933],\n",
      "       [0.41813198, 0.28951603, 0.20268364, 0.08966835]], dtype=float32)]\n",
      "\n",
      " --- At epoch 82 : \n",
      "  [82, [38.069027, 33.682602, 3.247941, 3.3667006], [33.540527, 14.074976, 30.742466, 6.488103], 82] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.488103, 6.1713317e-15, 0.00014954529, array([[0.3024635 , 0.51100993, 0.12737644, 0.05915014],\n",
      "       [0.33118108, 0.43013376, 0.16300452, 0.07568073],\n",
      "       [0.36905882, 0.38357392, 0.16929442, 0.07807288],\n",
      "       [0.33815613, 0.3880563 , 0.18503234, 0.08875521],\n",
      "       [0.42247382, 0.28554896, 0.20069015, 0.09128714]], dtype=float32)]\n",
      "\n",
      " --- At epoch 83 : \n",
      "  [83, [37.996796, 33.60159, 3.2249715, 3.366964], [33.566807, 13.958454, 29.777006, 6.5349073], 83] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5349073, 1.2042369e-15, 6.411043e-05, array([[0.30388695, 0.515722  , 0.12540916, 0.05498194],\n",
      "       [0.3335026 , 0.4338676 , 0.16096838, 0.0716614 ],\n",
      "       [0.37285736, 0.38662958, 0.1667429 , 0.07377005],\n",
      "       [0.34017915, 0.39261526, 0.18432203, 0.08288354],\n",
      "       [0.42756388, 0.288227  , 0.19912912, 0.08508005]], dtype=float32)]\n",
      "\n",
      " --- At epoch 84 : \n",
      "  [84, [38.004616, 33.59924, 3.2133121, 3.3669765], [33.659462, 13.832943, 28.80232, 6.583322], 84] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.583322, 6.66419e-06, 0.00011143581, array([[0.2892654 , 0.52931637, 0.12716365, 0.05425462],\n",
      "       [0.32254374, 0.44395098, 0.16293254, 0.07057273],\n",
      "       [0.36006397, 0.397945  , 0.16891067, 0.07308035],\n",
      "       [0.3305355 , 0.39988577, 0.18710124, 0.08247743],\n",
      "       [0.41667038, 0.2933781 , 0.20373368, 0.08621785]], dtype=float32)]\n",
      "\n",
      " --- At epoch 85 : \n",
      "  [85, [38.00226, 33.599224, 3.222778, 3.3661783], [33.588497, 13.985073, 29.948738, 6.513725], 85] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.513725, 3.471737e-20, 1.12210155e-05, array([[0.2776099 , 0.5406957 , 0.1243622 , 0.05733221],\n",
      "       [0.30894643, 0.45522967, 0.16088657, 0.07493735],\n",
      "       [0.3471092 , 0.40638536, 0.16823487, 0.07827051],\n",
      "       [0.31864932, 0.40814376, 0.1848609 , 0.08834607],\n",
      "       [0.40860268, 0.29500678, 0.20408064, 0.09230984]], dtype=float32)]\n",
      "\n",
      " --- At epoch 86 : \n",
      "  [86, [37.980198, 33.57269, 3.217592, 3.3668199], [33.555553, 14.043089, 30.38082, 6.5573955], 86] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5573955, 5.1323292e-09, 0.00021086883, array([[0.29328498, 0.5221334 , 0.12598677, 0.05859481],\n",
      "       [0.32273608, 0.4387027 , 0.16237326, 0.07618798],\n",
      "       [0.3622486 , 0.39016214, 0.16857693, 0.07901227],\n",
      "       [0.33068666, 0.394535  , 0.18470702, 0.09007131],\n",
      "       [0.41885653, 0.2855268 , 0.20284298, 0.09277372]], dtype=float32)]\n",
      "\n",
      " --- At epoch 87 : \n",
      "  [87, [38.050686, 33.66288, 3.2286084, 3.3664587], [33.57101, 14.010094, 30.170088, 6.521208], 87] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.521208, 6.39758e-08, 4.450992e-05, array([[0.31498134, 0.4942156 , 0.13236104, 0.05844208],\n",
      "       [0.33858502, 0.41765806, 0.16763951, 0.07611737],\n",
      "       [0.38166556, 0.3686643 , 0.17176045, 0.07790969],\n",
      "       [0.34434935, 0.37525696, 0.19237785, 0.08801582],\n",
      "       [0.43155834, 0.27262798, 0.2057646 , 0.09004905]], dtype=float32)]\n",
      "\n",
      " --- At epoch 88 : \n",
      "  [88, [37.92822, 33.5089, 3.2106674, 3.3661854], [33.57959, 13.993873, 29.955988, 6.488479], 88] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.488479, 6.368387e-18, 4.9101504e-06, array([[0.28594857, 0.5319523 , 0.12430173, 0.05779738],\n",
      "       [0.31657174, 0.44575253, 0.16113953, 0.07653611],\n",
      "       [0.35552287, 0.397582  , 0.16744888, 0.07944629],\n",
      "       [0.32631084, 0.39850393, 0.18604554, 0.08913967],\n",
      "       [0.4144691 , 0.28993505, 0.2028829 , 0.09271297]], dtype=float32)]\n",
      "\n",
      " --- At epoch 89 : \n",
      "  [89, [37.969864, 33.555595, 3.2099085, 3.3660617], [33.577335, 14.036154, 30.248877, 6.5120587], 89] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5120587, 2.0840748e-06, 5.8959802e-05, array([[0.27955437, 0.5389161 , 0.123845  , 0.0576845 ],\n",
      "       [0.3127467 , 0.44961613, 0.16090949, 0.07672771],\n",
      "       [0.34922013, 0.40326196, 0.16775937, 0.0797585 ],\n",
      "       [0.32229823, 0.40234023, 0.18600161, 0.08935994],\n",
      "       [0.40866837, 0.2938013 , 0.20437042, 0.09315994]], dtype=float32)]\n",
      "\n",
      " Validation performance under the hyper-parameters: \n",
      " {'lr': 0.001, 'batch_size': 91.24126472063516, 'l2_mean': 0.04302724148416418, 'l2_var': 0.08463283709967047, 'burn_in_steps': 80} [82, [38.069027, 33.682602, 3.247941, 3.3667006], [33.540527, 14.074976, 30.742466, 6.488103], 82]\n",
      "\n",
      " Training time: \n",
      " 6.308356671945014 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\tig\\tian-work-2020\\bayesian_predictive_mixture\\utils_training.py:162: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  if np.isnan(i[1][0]) == True:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- At epoch 0 : \n",
      "  [0, [50.66728, 47.2558, 5.4636183, 5.996099], [37.12494, 25.044733, 97.34544, 4.4766917], 0] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.4766917, 0.27867538, 0.108365834, array([[0.21119232, 0.42802   , 0.17815258, 0.18263502],\n",
      "       [0.21431677, 0.41872025, 0.19584568, 0.17111729],\n",
      "       [0.2228099 , 0.41092   , 0.18608692, 0.18018323],\n",
      "       [0.23161833, 0.39988068, 0.17353064, 0.19497037],\n",
      "       [0.23676893, 0.41759723, 0.13599311, 0.2096407 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 1 : \n",
      "  [1, [50.597847, 47.18343, 5.4497147, 5.402434], [37.118282, 25.034157, 97.31244, 4.479327], 1] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.479327, 0.12214952, 0.09318195, array([[0.12484787, 0.6626984 , 0.09050504, 0.12194868],\n",
      "       [0.1384407 , 0.6200026 , 0.10819953, 0.13335715],\n",
      "       [0.14917721, 0.59634393, 0.10857668, 0.14590219],\n",
      "       [0.16143149, 0.56568235, 0.11197581, 0.16091032],\n",
      "       [0.16965656, 0.5581194 , 0.09717718, 0.17504685]], dtype=float32)]\n",
      "\n",
      " --- At epoch 2 : \n",
      "  [2, [50.521095, 47.10337, 5.434409, 5.066345], [37.09121, 24.98403, 97.06149, 4.5326834], 2] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.5326834, 0.026883751, 0.08250632, array([[0.07093929, 0.8463206 , 0.04305283, 0.03968725],\n",
      "       [0.0916125 , 0.80016387, 0.06068315, 0.0475405 ],\n",
      "       [0.0999062 , 0.78648835, 0.06276502, 0.0508404 ],\n",
      "       [0.11482865, 0.7534043 , 0.07110807, 0.060659  ],\n",
      "       [0.12831764, 0.73260164, 0.069962  , 0.06911877]], dtype=float32)]\n",
      "\n",
      " --- At epoch 3 : \n",
      "  [3, [50.36645, 46.94049, 5.4067397, 4.8446856], [37.023567, 24.850801, 96.38452, 4.6092334], 3] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6092334, 0.0022941225, 0.07459281, array([[4.2680488e-03, 9.9261570e-01, 2.2976084e-03, 8.1871502e-04],\n",
      "       [9.3286391e-03, 9.8376232e-01, 5.4098801e-03, 1.4992187e-03],\n",
      "       [1.0540234e-02, 9.8197132e-01, 5.8566467e-03, 1.6318107e-03],\n",
      "       [1.4871116e-02, 9.7452229e-01, 8.2902741e-03, 2.3164134e-03],\n",
      "       [2.2204619e-02, 9.6292180e-01, 1.1315432e-02, 3.5581554e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 4 : \n",
      "  [4, [50.156353, 46.720253, 5.3693876, 4.790249], [36.92125, 24.645937, 95.34441, 4.6166434], 4] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6166434, 4.650577e-05, 0.06579822, array([[5.7688798e-04, 9.9901056e-01, 2.6909309e-04, 1.4346732e-04],\n",
      "       [1.6518011e-03, 9.9720299e-01, 8.2707062e-04, 3.1815894e-04],\n",
      "       [1.9312399e-03, 9.9678385e-01, 9.2947192e-04, 3.5538030e-04],\n",
      "       [3.1895794e-03, 9.9469638e-01, 1.5327262e-03, 5.8130478e-04],\n",
      "       [5.8460897e-03, 9.9048853e-01, 2.6261618e-03, 1.0392963e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 5 : \n",
      "  [5, [49.886223, 46.43683, 5.320723, 4.741975], [36.794918, 24.38959, 94.03488, 4.598557], 5] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.598557, 9.4973075e-08, 0.056026157, array([[2.0109690e-04, 9.9967957e-01, 8.0069127e-05, 3.9322862e-05],\n",
      "       [6.3740660e-04, 9.9900913e-01, 2.6472987e-04, 8.8743524e-05],\n",
      "       [7.6074852e-04, 9.9882859e-01, 3.0831376e-04, 1.0235501e-04],\n",
      "       [1.3929335e-03, 9.9786013e-01, 5.6648493e-04, 1.8045558e-04],\n",
      "       [2.9382501e-03, 9.9558455e-01, 1.1181473e-03, 3.5915629e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 6 : \n",
      "  [6, [49.576378, 46.111275, 5.2633734, 4.7009], [36.651436, 24.09646, 92.52185, 4.6049376], 6] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6049376, 6.2694047e-12, 0.047519736, array([[1.2235070e-04, 9.9981719e-01, 4.4305896e-05, 1.6092783e-05],\n",
      "       [4.0428920e-04, 9.9941576e-01, 1.4303658e-04, 3.6980742e-05],\n",
      "       [4.7615342e-04, 9.9931061e-01, 1.6943492e-04, 4.3830019e-05],\n",
      "       [9.3026721e-04, 9.9864858e-01, 3.3809754e-04, 8.3111961e-05],\n",
      "       [2.2016368e-03, 9.9686205e-01, 7.4646022e-04, 1.8983241e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 7 : \n",
      "  [7, [49.202263, 45.717663, 5.1937847, 4.6652117], [36.49143, 23.760397, 90.78084, 4.6012607], 7] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6012607, 1.2220261e-18, 0.039855015, array([[7.7872508e-05, 9.9988294e-01, 2.5233881e-05, 1.4007797e-05],\n",
      "       [2.5978492e-04, 9.9962509e-01, 8.1455226e-05, 3.3662862e-05],\n",
      "       [3.0695499e-04, 9.9955517e-01, 9.7230812e-05, 4.0588035e-05],\n",
      "       [6.4875558e-04, 9.9905735e-01, 2.0904254e-04, 8.4858533e-05],\n",
      "       [1.7016287e-03, 9.9756753e-01, 5.1438989e-04, 2.1653669e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 8 : \n",
      "  [8, [48.761536, 45.251648, 5.1060734, 4.6435175], [36.31597, 23.371635, 88.76664, 4.591612], 8] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.591612, 1.4602157e-29, 0.032033004, array([[1.2714839e-04, 9.9981302e-01, 3.1394240e-05, 2.8483661e-05],\n",
      "       [3.5781937e-04, 9.9949205e-01, 8.8207962e-05, 6.1916326e-05],\n",
      "       [4.3746870e-04, 9.9938011e-01, 1.0676937e-04, 7.5620766e-05],\n",
      "       [9.8524615e-04, 9.9860257e-01, 2.4083274e-04, 1.7146613e-04],\n",
      "       [2.6313092e-03, 9.9628049e-01, 6.2351098e-04, 4.6469690e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 9 : \n",
      "  [9, [48.29352, 44.75503, 5.0102415, 4.6264486], [36.13925, 22.966455, 86.641426, 4.6032405], 9] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6032405, 0.0, 0.024464956, array([[3.0133850e-04, 9.9954861e-01, 7.2138828e-05, 7.7864890e-05],\n",
      "       [6.7517685e-04, 9.9902129e-01, 1.6045575e-04, 1.4307602e-04],\n",
      "       [8.3619240e-04, 9.9878675e-01, 1.9846827e-04, 1.7856872e-04],\n",
      "       [1.8861152e-03, 9.9725455e-01, 4.4650023e-04, 4.1293088e-04],\n",
      "       [5.1437002e-03, 9.9252629e-01, 1.1755910e-03, 1.1544318e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 10 : \n",
      "  [10, [47.833065, 44.263485, 4.915765, 4.6058125], [35.97781, 22.57552, 84.58873, 4.594404], 10] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.594404, 0.0, 0.019748555, array([[5.0853292e-04, 9.9926299e-01, 1.0637900e-04, 1.2209633e-04],\n",
      "       [9.2667091e-04, 9.9869907e-01, 1.8970421e-04, 1.8445175e-04],\n",
      "       [1.2270493e-03, 9.9827170e-01, 2.5341983e-04, 2.4776880e-04],\n",
      "       [2.8281598e-03, 9.9598855e-01, 5.9490796e-04, 5.8831868e-04],\n",
      "       [8.9206295e-03, 9.8733240e-01, 1.8443016e-03, 1.9026846e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 11 : \n",
      "  [11, [47.367054, 43.76414, 4.820743, 4.5806537], [35.81976, 22.170467, 82.51472, 4.615058], 11] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.615058, 0.0, 0.0148215, array([[1.2811586e-03, 9.9831247e-01, 1.9841282e-04, 2.0805205e-04],\n",
      "       [1.7981438e-03, 9.9764794e-01, 2.8639639e-04, 2.6758571e-04],\n",
      "       [2.8020011e-03, 9.9636072e-01, 4.3121562e-04, 4.0600114e-04],\n",
      "       [6.4002504e-03, 9.9161363e-01, 1.0217788e-03, 9.6442353e-04],\n",
      "       [2.2156749e-02, 9.7059959e-01, 3.7081216e-03, 3.5355045e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 12 : \n",
      "  [12, [46.8876, 43.246914, 4.724971, 4.552259], [35.67183, 21.761806, 80.43922, 4.6098013], 12] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6098013, 0.0, 0.0120464675, array([[5.4147444e-03, 9.9296218e-01, 6.7878969e-04, 9.4432646e-04],\n",
      "       [6.1580427e-03, 9.9210733e-01, 7.3670573e-04, 9.9792844e-04],\n",
      "       [1.0187892e-02, 9.8702592e-01, 1.1594209e-03, 1.6267695e-03],\n",
      "       [2.0402782e-02, 9.7353214e-01, 2.6262503e-03, 3.4388886e-03],\n",
      "       [6.5033242e-02, 9.1541052e-01, 8.3748018e-03, 1.1181411e-02]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 13 : \n",
      "  [13, [46.383442, 42.701218, 4.6267323, 4.5242014], [35.5245, 21.34065, 78.367004, 4.6199174], 13] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6199174, 0.0, 0.009164416, array([[0.01683785, 0.97748125, 0.00229996, 0.00338098],\n",
      "       [0.01833203, 0.9756353 , 0.00241591, 0.0036167 ],\n",
      "       [0.02700823, 0.96437997, 0.00339946, 0.00521232],\n",
      "       [0.04255687, 0.9420371 , 0.00657699, 0.0088291 ],\n",
      "       [0.09549396, 0.87001926, 0.01442571, 0.02006112]], dtype=float32)]\n",
      "\n",
      " --- At epoch 14 : \n",
      "  [14, [45.856464, 42.127953, 4.52303, 4.497837], [35.382267, 20.905113, 76.20424, 4.645834], 14] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.645834, 0.0, 0.00713175, array([[0.022382  , 0.9676116 , 0.0044683 , 0.00553813],\n",
      "       [0.02480805, 0.9643662 , 0.00467731, 0.0061484 ],\n",
      "       [0.03167376, 0.95488507, 0.00573982, 0.0077014 ],\n",
      "       [0.04090865, 0.9384558 , 0.00999762, 0.01063781],\n",
      "       [0.06709729, 0.8998871 , 0.0155204 , 0.01749515]], dtype=float32)]\n",
      "\n",
      " --- At epoch 15 : \n",
      "  [15, [45.341003, 41.563465, 4.4177275, 4.473201], [35.25563, 20.487946, 74.01157, 4.6726975], 15] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6726975, 0.0, 0.005485429, array([[0.01867173, 0.9682532 , 0.00684397, 0.00623116],\n",
      "       [0.02118864, 0.9650989 , 0.00677791, 0.00693452],\n",
      "       [0.02486396, 0.9595012 , 0.00754178, 0.00809303],\n",
      "       [0.0291515 , 0.9474237 , 0.01357374, 0.0098511 ],\n",
      "       [0.04011527, 0.9294188 , 0.01687808, 0.01358783]], dtype=float32)]\n",
      "\n",
      " --- At epoch 16 : \n",
      "  [16, [44.832607, 40.998947, 4.3106093, 4.457443], [35.160675, 20.093945, 71.8499, 4.71007], 16] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.71007, 0.0, 0.0045660855, array([[0.01313149, 0.97407484, 0.00703161, 0.00576203],\n",
      "       [0.01511552, 0.970491  , 0.00804674, 0.00634665],\n",
      "       [0.01744872, 0.9656664 , 0.00957941, 0.00730541],\n",
      "       [0.01986058, 0.9591679 , 0.01246468, 0.00850682],\n",
      "       [0.02573951, 0.94706464, 0.01608765, 0.01110823]], dtype=float32)]\n",
      "\n",
      " --- At epoch 17 : \n",
      "  [17, [44.32486, 40.436714, 4.2026134, 4.4268756], [35.02447, 19.705235, 69.70309, 4.70464], 17] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.70464, 0.0, 0.0036211591, array([[0.00957981, 0.9744921 , 0.0069337 , 0.00899444],\n",
      "       [0.0116622 , 0.9716545 , 0.00728941, 0.00939384],\n",
      "       [0.01240607, 0.96915096, 0.00812991, 0.01031314],\n",
      "       [0.01527563, 0.9630599 , 0.0102709 , 0.01139367],\n",
      "       [0.01719742, 0.9580896 , 0.01160227, 0.0131107 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 18 : \n",
      "  [18, [43.909935, 39.99606, 4.1280675, 4.4060187], [34.951298, 19.3404, 67.64141, 4.7635107], 18] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.7635107, 0.0, 0.0028338695, array([[0.00733509, 0.98019654, 0.00484257, 0.00762593],\n",
      "       [0.00878549, 0.9771831 , 0.0053578 , 0.00867361],\n",
      "       [0.01003179, 0.9737835 , 0.00626646, 0.00991833],\n",
      "       [0.01192934, 0.9682262 , 0.00839964, 0.01144475],\n",
      "       [0.01466578, 0.96023214, 0.01048832, 0.01461367]], dtype=float32)]\n",
      "\n",
      " --- At epoch 19 : \n",
      "  [19, [43.466854, 39.511715, 4.041072, 4.378331], [34.798775, 18.998926, 65.74562, 4.7638426], 19] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.7638426, 0.0, 0.002193991, array([[0.00683835, 0.97658426, 0.0075488 , 0.00902848],\n",
      "       [0.00843066, 0.9734471 , 0.00856521, 0.00955708],\n",
      "       [0.00835725, 0.97109175, 0.01010582, 0.01044516],\n",
      "       [0.01142856, 0.9656392 , 0.01133761, 0.0115947 ],\n",
      "       [0.01223246, 0.96046144, 0.01376869, 0.01353736]], dtype=float32)]\n",
      "\n",
      " --- At epoch 20 : \n",
      "  [20, [43.051994, 39.071907, 3.9694443, 4.3530607], [34.6486, 18.65109, 63.83205, 4.802155], 20] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.802155, 0.0, 0.0017461278, array([[0.00672483, 0.97632265, 0.00774527, 0.00920726],\n",
      "       [0.00836555, 0.97385526, 0.00832855, 0.00945062],\n",
      "       [0.00782017, 0.97243744, 0.00954189, 0.0102005 ],\n",
      "       [0.01142348, 0.966349  , 0.01116929, 0.01105825],\n",
      "       [0.01145094, 0.963085  , 0.01291772, 0.01254638]], dtype=float32)]\n",
      "\n",
      " --- At epoch 21 : \n",
      "  [21, [42.656776, 38.65385, 3.9035165, 4.3304615], [34.52275, 18.316448, 61.946884, 4.8476706], 21] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.8476706, 0.0, 0.0014293554, array([[0.006891  , 0.9771902 , 0.00748976, 0.00842906],\n",
      "       [0.00855076, 0.9749016 , 0.00803282, 0.00851477],\n",
      "       [0.0080179 , 0.9734433 , 0.00928167, 0.00925704],\n",
      "       [0.01197288, 0.9672798 , 0.01080663, 0.0099408 ],\n",
      "       [0.01201576, 0.96387833, 0.01272567, 0.01138024]], dtype=float32)]\n",
      "\n",
      " --- At epoch 22 : \n",
      "  [22, [42.28359, 38.259014, 3.841225, 4.306692], [34.403984, 17.996027, 60.10928, 4.903897], 22] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.903897, 0.0, 0.0010997293, array([[0.00748814, 0.97662205, 0.00774466, 0.00814509],\n",
      "       [0.00930373, 0.9745181 , 0.008083  , 0.00809513],\n",
      "       [0.00871794, 0.97326577, 0.0092408 , 0.00877545],\n",
      "       [0.01304888, 0.9664446 , 0.01122327, 0.00928324],\n",
      "       [0.01300018, 0.9635182 , 0.01294752, 0.01053406]], dtype=float32)]\n",
      "\n",
      " --- At epoch 23 : \n",
      "  [23, [41.916885, 37.870842, 3.7798264, 4.2820067], [34.285408, 17.674526, 58.24925, 4.9453974], 23] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.9453974, 0.0, 0.0008533433, array([[0.00839632, 0.9765553 , 0.0080845 , 0.0069639 ],\n",
      "       [0.01041112, 0.97455263, 0.00820302, 0.00683329],\n",
      "       [0.00980319, 0.97361934, 0.00923877, 0.00733866],\n",
      "       [0.01474573, 0.9659353 , 0.01169876, 0.00762025],\n",
      "       [0.01431156, 0.96418166, 0.01300793, 0.00849882]], dtype=float32)]\n",
      "\n",
      " --- At epoch 24 : \n",
      "  [24, [41.571953, 37.513435, 3.7329783, 4.257977], [34.162445, 17.375223, 56.51127, 4.99852], 24] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.99852, 0.0, 0.00071807945, array([[0.00870685, 0.97543156, 0.00902036, 0.00684127],\n",
      "       [0.01091543, 0.97268665, 0.00976314, 0.00663487],\n",
      "       [0.01014369, 0.9714534 , 0.01134165, 0.00706123],\n",
      "       [0.01562153, 0.96449196, 0.01269228, 0.00719427],\n",
      "       [0.01514341, 0.9621049 , 0.01475939, 0.00799225]], dtype=float32)]\n",
      "\n",
      " --- At epoch 25 : \n",
      "  [25, [41.20909, 37.113937, 3.6617222, 4.2330546], [34.10087, 17.087076, 54.728073, 5.060298], 25] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.060298, 0.0, 0.0006183788, array([[0.01020191, 0.97435296, 0.00928243, 0.00616274],\n",
      "       [0.01265885, 0.9711358 , 0.0102447 , 0.00596063],\n",
      "       [0.01191232, 0.9697751 , 0.0120422 , 0.00627044],\n",
      "       [0.01776042, 0.96303004, 0.012909  , 0.00630054],\n",
      "       [0.01713456, 0.96075505, 0.01513334, 0.00697704]], dtype=float32)]\n",
      "\n",
      " --- At epoch 26 : \n",
      "  [26, [40.905018, 36.80415, 3.6253097, 4.2164984], [33.97455, 16.785938, 52.916157, 5.176121], 26] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.176121, 0.0, 0.00085355825, array([[0.01037949, 0.97493774, 0.00921596, 0.00546679],\n",
      "       [0.01301096, 0.971907  , 0.0098445 , 0.00523751],\n",
      "       [0.01215829, 0.9708509 , 0.01149916, 0.00549167],\n",
      "       [0.01832341, 0.9632374 , 0.01299185, 0.00544744],\n",
      "       [0.0180486 , 0.9606432 , 0.01513774, 0.00617057]], dtype=float32)]\n",
      "\n",
      " --- At epoch 27 : \n",
      "  [27, [40.555454, 36.420498, 3.5586493, 4.178734], [33.909523, 16.516672, 51.209347, 5.259253], 27] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.259253, 0.0, 0.00049783965, array([[0.01265919, 0.97164357, 0.01023005, 0.00546715],\n",
      "       [0.01588142, 0.9680321 , 0.01087333, 0.00521323],\n",
      "       [0.01462725, 0.9675309 , 0.01251421, 0.00532767],\n",
      "       [0.02187019, 0.9591304 , 0.01381437, 0.00518506],\n",
      "       [0.02060597, 0.9583099 , 0.01541867, 0.00566543]], dtype=float32)]\n",
      "\n",
      " --- At epoch 28 : \n",
      "  [28, [40.255463, 36.111774, 3.5250556, 4.1508746], [33.79005, 16.24448, 49.51335, 5.311854], 28] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.311854, 0.0, 0.0005143806, array([[0.01316498, 0.9697576 , 0.01169783, 0.00537953],\n",
      "       [0.01653341, 0.96603817, 0.01233592, 0.00509246],\n",
      "       [0.01523975, 0.96531326, 0.01426558, 0.00518137],\n",
      "       [0.02320476, 0.95556444, 0.0162493 , 0.00498155],\n",
      "       [0.0220045 , 0.9542572 , 0.01824185, 0.00549649]], dtype=float32)]\n",
      "\n",
      " --- At epoch 29 : \n",
      "  [29, [39.96333, 35.801056, 3.4809704, 4.125416], [33.710026, 15.983943, 47.818623, 5.416118], 29] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.416118, 0.0, 0.0005553455, array([[0.01441401, 0.96829796, 0.0123705 , 0.00491758],\n",
      "       [0.01796325, 0.96453756, 0.01284583, 0.00465333],\n",
      "       [0.01649754, 0.9641337 , 0.01469097, 0.00467775],\n",
      "       [0.02504351, 0.95320284, 0.01733856, 0.00441511],\n",
      "       [0.02364709, 0.9525579 , 0.01896516, 0.00482981]], dtype=float32)]\n",
      "\n",
      " --- At epoch 30 : \n",
      "  [30, [39.66596, 35.485027, 3.439519, 4.0950203], [33.622265, 15.726178, 46.135548, 5.5909634], 30] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.5909634, 0.0, 0.00047822524, array([[0.01487791, 0.968329  , 0.01257986, 0.00421326],\n",
      "       [0.01871412, 0.9638302 , 0.01344689, 0.00400884],\n",
      "       [0.01718096, 0.96326584, 0.01557234, 0.00398082],\n",
      "       [0.02627044, 0.9528096 , 0.01720073, 0.00371925],\n",
      "       [0.02469471, 0.95215863, 0.01908077, 0.00406583]], dtype=float32)]\n",
      "\n",
      " --- At epoch 31 : \n",
      "  [31, [39.50531, 35.233467, 3.3506527, 4.0911865], [34.037277, 15.60523, 44.62038, 5.831761], 31] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.831761, 0.0, 0.0008409905, array([[0.01350961, 0.96723217, 0.01256979, 0.00668849],\n",
      "       [0.01664377, 0.96216094, 0.01381888, 0.00737643],\n",
      "       [0.01744645, 0.95872766, 0.01591039, 0.00791549],\n",
      "       [0.02150685, 0.94559973, 0.02468647, 0.00820691],\n",
      "       [0.02381832, 0.93930197, 0.02732496, 0.00955475]], dtype=float32)]\n",
      "\n",
      " --- At epoch 32 : \n",
      "  [32, [39.392735, 35.119667, 3.3461833, 4.0525193], [34.019947, 15.455551, 43.488106, 5.9122853], 32] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9122853, 0.0, 0.00074003584, array([[0.0127584 , 0.96289074, 0.01766299, 0.00668781],\n",
      "       [0.01559597, 0.9575114 , 0.01940845, 0.00748412],\n",
      "       [0.01638869, 0.95328397, 0.02201645, 0.00831099],\n",
      "       [0.01997193, 0.9356748 , 0.03519382, 0.00915946],\n",
      "       [0.02289437, 0.92620915, 0.03975005, 0.0111464 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 33 : \n",
      "  [33, [39.17744, 34.91819, 3.3418114, 4.018319], [33.78594, 15.174934, 41.7855, 6.0219283], 33] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0219283, 0.0, 0.00049744704, array([[0.01176084, 0.96449083, 0.0179362 , 0.00581218],\n",
      "       [0.0152476 , 0.95816433, 0.02008412, 0.0065039 ],\n",
      "       [0.01471028, 0.9552404 , 0.02291372, 0.00713553],\n",
      "       [0.01938298, 0.935086  , 0.03767773, 0.00785324],\n",
      "       [0.02175444, 0.9266242 , 0.04205851, 0.00956289]], dtype=float32)]\n",
      "\n",
      " --- At epoch 34 : \n",
      "  [34, [38.86972, 34.604366, 3.3045273, 3.9859447], [33.52871, 14.919306, 40.42028, 6.1958656], 34] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1958656, 0.0, 0.00041115363, array([[0.0142299 , 0.95769393, 0.0215312 , 0.006545  ],\n",
      "       [0.01861887, 0.9529634 , 0.02153985, 0.00687793],\n",
      "       [0.01630209, 0.9529759 , 0.02339417, 0.00732779],\n",
      "       [0.02276386, 0.9263168 , 0.04326622, 0.00765309],\n",
      "       [0.0241308 , 0.9233221 , 0.04353746, 0.00900966]], dtype=float32)]\n",
      "\n",
      " --- At epoch 35 : \n",
      "  [35, [38.37634, 34.079254, 3.2527947, 3.9540758], [33.351627, 14.64286, 38.629642, 6.261075], 35] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.261075, 0.0, 0.0015809545, array([[0.01549964, 0.95743   , 0.01925228, 0.00781804],\n",
      "       [0.02033316, 0.9496985 , 0.02219699, 0.00777135],\n",
      "       [0.01690243, 0.94952124, 0.02559974, 0.00797652],\n",
      "       [0.02698732, 0.9368666 , 0.02815013, 0.00799586],\n",
      "       [0.02529466, 0.9330983 , 0.03267317, 0.00893393]], dtype=float32)]\n",
      "\n",
      " --- At epoch 36 : \n",
      "  [36, [38.21797, 33.90834, 3.2417283, 3.9269485], [33.330597, 14.455892, 37.115974, 6.393193], 36] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.393193, 0.0, 0.0019769848, array([[0.01787924, 0.9563035 , 0.01770682, 0.00811049],\n",
      "       [0.02393951, 0.94713694, 0.0205861 , 0.00833745],\n",
      "       [0.01941151, 0.94820637, 0.02368787, 0.00869426],\n",
      "       [0.03081092, 0.9343191 , 0.02604132, 0.00882866],\n",
      "       [0.02878354, 0.9307749 , 0.03038897, 0.01005254]], dtype=float32)]\n",
      "\n",
      " --- At epoch 37 : \n",
      "  [37, [37.925922, 33.59155, 3.2062051, 3.8954153], [33.223988, 14.270642, 35.69111, 6.5100913], 37] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5100913, 0.0, 0.0020556017, array([[0.02257742, 0.9520955 , 0.01817545, 0.0071516 ],\n",
      "       [0.02954945, 0.94273406, 0.0205929 , 0.00712356],\n",
      "       [0.02390209, 0.9455025 , 0.0233839 , 0.00721149],\n",
      "       [0.03837327, 0.93012196, 0.02443962, 0.00706515],\n",
      "       [0.0342047 , 0.93038213, 0.02765848, 0.00775473]], dtype=float32)]\n",
      "\n",
      " --- At epoch 38 : \n",
      "  [38, [37.792515, 33.454716, 3.2075918, 3.8602886], [33.15198, 14.122922, 34.407913, 6.586816], 38] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.586816, 0.0, 0.0019530572, array([[0.02720343, 0.94890225, 0.01619413, 0.0077002 ],\n",
      "       [0.03526512, 0.9389322 , 0.01817536, 0.00762734],\n",
      "       [0.02922637, 0.94246006, 0.02061689, 0.00769669],\n",
      "       [0.04612952, 0.92485434, 0.02164396, 0.00737215],\n",
      "       [0.04205424, 0.92558926, 0.02432852, 0.00802803]], dtype=float32)]\n",
      "\n",
      " --- At epoch 39 : \n",
      "  [39, [37.567947, 33.188198, 3.1385236, 3.8354275], [33.241364, 13.964423, 33.159042, 6.584901], 39] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.584901, 0.0, 0.001525829, array([[0.0329717 , 0.9439059 , 0.01398532, 0.00913699],\n",
      "       [0.04155812, 0.9336498 , 0.01554234, 0.00924977],\n",
      "       [0.03595941, 0.93722636, 0.01739745, 0.00941685],\n",
      "       [0.05375437, 0.918522  , 0.01877028, 0.0089533 ],\n",
      "       [0.05013062, 0.9194587 , 0.02068265, 0.00972794]], dtype=float32)]\n",
      "\n",
      " --- At epoch 40 : \n",
      "  [40, [37.54168, 33.17568, 3.170594, 3.7986703], [33.117897, 13.879497, 32.24468, 6.4972806], 40] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4972806, 0.0, 0.0011873132, array([[0.03743932, 0.9381293 , 0.01417426, 0.01025699],\n",
      "       [0.04736732, 0.9263644 , 0.01584932, 0.01041896],\n",
      "       [0.04057534, 0.93068403, 0.01796777, 0.01077284],\n",
      "       [0.06088356, 0.9094279 , 0.01933265, 0.0103559 ],\n",
      "       [0.05728744, 0.9100549 , 0.02141383, 0.01124374]], dtype=float32)]\n",
      "\n",
      " --- At epoch 41 : \n",
      "  [41, [37.39886, 33.00751, 3.146596, 3.7916026], [33.138657, 13.733095, 30.97456, 6.5188117], 41] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.5188117, 0.0, 0.0010897212, array([[0.03966084, 0.9360938 , 0.012628  , 0.01161737],\n",
      "       [0.04980097, 0.92456734, 0.01361064, 0.01202099],\n",
      "       [0.04240244, 0.9299625 , 0.01500868, 0.01262631],\n",
      "       [0.06216729, 0.90833664, 0.01737581, 0.01212028],\n",
      "       [0.05965824, 0.9088168 , 0.01844386, 0.01308101]], dtype=float32)]\n",
      "\n",
      " --- At epoch 42 : \n",
      "  [42, [37.31552, 32.91879, 3.1451764, 3.7474916], [33.08118, 13.682346, 30.371054, 6.3888893], 42] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3888893, 0.0, 0.0006297547, array([[0.04434654, 0.9282164 , 0.01388129, 0.0135558 ],\n",
      "       [0.05606079, 0.91397023, 0.01608315, 0.01388573],\n",
      "       [0.04724093, 0.91954285, 0.01842328, 0.01479301],\n",
      "       [0.06983028, 0.89862376, 0.01771133, 0.01383464],\n",
      "       [0.06566975, 0.89921963, 0.02044617, 0.01466441]], dtype=float32)]\n",
      "\n",
      " --- At epoch 43 : \n",
      "  [43, [37.21561, 32.809177, 3.1519663, 3.7166753], [32.991325, 13.552119, 28.925234, 6.322939], 43] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.322939, 0.0, 0.0004488367, array([[0.0446222 , 0.9284965 , 0.01420144, 0.01267998],\n",
      "       [0.05685059, 0.91454196, 0.01556812, 0.0130393 ],\n",
      "       [0.04765091, 0.92068565, 0.01744692, 0.01421654],\n",
      "       [0.07196402, 0.8972964 , 0.01757361, 0.01316598],\n",
      "       [0.06772012, 0.89895916, 0.01946124, 0.01385947]], dtype=float32)]\n",
      "\n",
      " --- At epoch 44 : \n",
      "  [44, [37.15166, 32.7347, 3.1462274, 3.6899688], [32.97694, 13.4979105, 28.27867, 6.247376], 44] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.247376, 0.0, 0.00027135923, array([[0.05080971, 0.9201835 , 0.01636631, 0.01264055],\n",
      "       [0.06429909, 0.9047556 , 0.01792392, 0.01302134],\n",
      "       [0.05370834, 0.91172636, 0.02004369, 0.01452165],\n",
      "       [0.08031121, 0.8862207 , 0.02030714, 0.01316095],\n",
      "       [0.07477314, 0.8894394 , 0.02222909, 0.01355837]], dtype=float32)]\n",
      "\n",
      " --- At epoch 45 : \n",
      "  [45, [37.316784, 32.92408, 3.2125936, 3.668517], [32.900936, 13.52195, 27.812849, 6.144498], 45] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.144498, 0.0, 0.0002137493, array([[0.05609509, 0.91365325, 0.0179076 , 0.012344  ],\n",
      "       [0.07214354, 0.895076  , 0.01998376, 0.01279672],\n",
      "       [0.05893245, 0.90357554, 0.02268001, 0.01481204],\n",
      "       [0.08993427, 0.87518   , 0.02164264, 0.01324311],\n",
      "       [0.08382547, 0.8781633 , 0.02443603, 0.0135753 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 46 : \n",
      "  [46, [37.248413, 32.83933, 3.2018611, 3.650276], [32.907288, 13.449637, 26.945295, 6.0759497], 46] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0759497, 0.0, 0.00021594045, array([[0.05948083, 0.91065395, 0.01829969, 0.01156557],\n",
      "       [0.07593061, 0.89216477, 0.01983357, 0.01207105],\n",
      "       [0.06255827, 0.90050757, 0.02241886, 0.01451527],\n",
      "       [0.09421346, 0.87023383, 0.02289546, 0.01265721],\n",
      "       [0.08978678, 0.8725442 , 0.02491971, 0.01274926]], dtype=float32)]\n",
      "\n",
      " --- At epoch 47 : \n",
      "  [47, [37.17807, 32.75476, 3.175503, 3.6376283], [32.953476, 13.409673, 26.60995, 6.02904], 47] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.02904, 0.0, 0.0003698644, array([[0.06626956, 0.9017516 , 0.02040658, 0.01157237],\n",
      "       [0.08378005, 0.8813457 , 0.02271079, 0.01216343],\n",
      "       [0.06938402, 0.8895427 , 0.02593502, 0.01513831],\n",
      "       [0.10314835, 0.85894763, 0.02491816, 0.01298587],\n",
      "       [0.09860542, 0.86048555, 0.02796297, 0.01294599]], dtype=float32)]\n",
      "\n",
      " --- At epoch 48 : \n",
      "  [48, [37.210964, 32.786232, 3.1762607, 3.6348808], [32.977688, 13.396445, 26.287899, 5.9575605], 48] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9575605, 0.0, 0.00041949315, array([[0.07292674, 0.89479566, 0.02091515, 0.0113625 ],\n",
      "       [0.09237388, 0.8720699 , 0.02340838, 0.01214779],\n",
      "       [0.07606244, 0.88123757, 0.02689034, 0.01580964],\n",
      "       [0.11292308, 0.8475408 , 0.02634138, 0.01319473],\n",
      "       [0.10889258, 0.84827125, 0.02968379, 0.01315237]], dtype=float32)]\n",
      "\n",
      " --- At epoch 49 : \n",
      "  [49, [37.329243, 32.914265, 3.219112, 3.6186714], [32.92379, 13.482433, 26.254168, 5.90744], 49] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.90744, 0.0, 0.0005059635, array([[0.07615921, 0.8871326 , 0.02447806, 0.01223014],\n",
      "       [0.09790923, 0.8618166 , 0.02720971, 0.01306445],\n",
      "       [0.07846516, 0.87263346, 0.03125041, 0.01765098],\n",
      "       [0.1192579 , 0.83590597, 0.03065576, 0.01418036],\n",
      "       [0.11220645, 0.8397911 , 0.0341283 , 0.01387402]], dtype=float32)]\n",
      "\n",
      " --- At epoch 50 : \n",
      "  [50, [37.382103, 32.97635, 3.2244453, 3.614884], [32.95851, 13.499385, 26.43282, 5.8717275], 50] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8717275, 0.0, 0.00054956164, array([[0.08635386, 0.87671316, 0.02555156, 0.01138144],\n",
      "       [0.10944051, 0.85008234, 0.02820463, 0.01227264],\n",
      "       [0.08759686, 0.86255336, 0.03258745, 0.01726233],\n",
      "       [0.13075316, 0.82360953, 0.03202591, 0.01361136],\n",
      "       [0.12500376, 0.8261185 , 0.03558762, 0.01329016]], dtype=float32)]\n",
      "\n",
      " --- At epoch 51 : \n",
      "  [51, [37.20897, 32.76183, 3.1521115, 3.6305249], [33.114456, 13.347491, 25.817793, 5.9399905], 51] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9399905, 0.0, 0.0010053671, array([[0.0857285 , 0.87903464, 0.02416627, 0.01107069],\n",
      "       [0.1089039 , 0.8529127 , 0.02591957, 0.01226384],\n",
      "       [0.09077616, 0.86200637, 0.02944029, 0.01777716],\n",
      "       [0.12914309, 0.8208977 , 0.03604456, 0.0139147 ],\n",
      "       [0.12742959, 0.82067555, 0.03831889, 0.01357597]], dtype=float32)]\n",
      "\n",
      " --- At epoch 52 : \n",
      "  [52, [37.534184, 33.13912, 3.2535636, 3.612474], [32.97608, 13.5893755, 26.633797, 5.808968], 52] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.808968, 0.0, 0.0006367479, array([[0.08920057, 0.866446  , 0.03268045, 0.01167294],\n",
      "       [0.11496831, 0.8355785 , 0.03696265, 0.01249064],\n",
      "       [0.08967359, 0.8481899 , 0.04337041, 0.01876607],\n",
      "       [0.13643092, 0.80777806, 0.04145831, 0.01433273],\n",
      "       [0.13045679, 0.8084353 , 0.04748629, 0.01362165]], dtype=float32)]\n",
      "\n",
      " --- At epoch 53 : \n",
      "  [53, [37.472897, 33.063335, 3.2412179, 3.6042643], [32.996902, 13.54949, 26.28905, 5.7421675], 53] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7421675, 0.0, 0.0007446156, array([[0.08855109, 0.8650665 , 0.03580959, 0.01057283],\n",
      "       [0.11482912, 0.83341146, 0.0402927 , 0.01146676],\n",
      "       [0.08912692, 0.84594345, 0.04700186, 0.01792777],\n",
      "       [0.13607563, 0.80444545, 0.04608556, 0.01339336],\n",
      "       [0.12972517, 0.80583024, 0.05188823, 0.01255638]], dtype=float32)]\n",
      "\n",
      " --- At epoch 54 : \n",
      "  [54, [37.458607, 33.044765, 3.2286937, 3.601714], [33.009674, 13.578675, 26.479153, 5.7479134], 54] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7479134, 0.0, 0.0006933639, array([[0.08834451, 0.8592128 , 0.04175101, 0.01069174],\n",
      "       [0.11392365, 0.82862854, 0.04582426, 0.01162357],\n",
      "       [0.08723224, 0.841297  , 0.05281902, 0.01865182],\n",
      "       [0.13383473, 0.7995115 , 0.05292243, 0.01373143],\n",
      "       [0.12678953, 0.8024089 , 0.05816085, 0.01264079]], dtype=float32)]\n",
      "\n",
      " --- At epoch 55 : \n",
      "  [55, [37.40854, 32.976875, 3.2219112, 3.5997903], [33.03382, 13.51084, 25.837666, 5.7377663], 55] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7377663, 0.0, 0.000669257, array([[0.08180324, 0.86459434, 0.04344115, 0.01016125],\n",
      "       [0.10588461, 0.83383363, 0.04902202, 0.01125976],\n",
      "       [0.08136693, 0.8427422 , 0.05708998, 0.01880089],\n",
      "       [0.12828544, 0.8017453 , 0.05624321, 0.01372606],\n",
      "       [0.12168806, 0.80226207, 0.06336285, 0.01268699]], dtype=float32)]\n",
      "\n",
      " --- At epoch 56 : \n",
      "  [56, [37.346264, 32.905315, 3.194818, 3.602512], [33.074463, 13.498649, 25.96031, 5.730253], 56] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.730253, 0.0, 0.0008107807, array([[0.08306029, 0.8599696 , 0.04711668, 0.00985345],\n",
      "       [0.10923667, 0.8269297 , 0.05279009, 0.0110435 ],\n",
      "       [0.08321121, 0.83652055, 0.06104648, 0.01922171],\n",
      "       [0.12953335, 0.79666525, 0.06005895, 0.01374248],\n",
      "       [0.12176162, 0.799224  , 0.06657534, 0.01243901]], dtype=float32)]\n",
      "\n",
      " --- At epoch 57 : \n",
      "  [57, [37.35553, 32.912518, 3.185937, 3.5953782], [33.102013, 13.535157, 26.342632, 5.697141], 57] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.697141, 0.0, 0.00069954473, array([[0.08189475, 0.8557083 , 0.05165121, 0.01074571],\n",
      "       [0.1070665 , 0.82450515, 0.0563335 , 0.01209482],\n",
      "       [0.08120424, 0.8327309 , 0.06430287, 0.02176195],\n",
      "       [0.12611215, 0.7914279 , 0.06721009, 0.01524983],\n",
      "       [0.11979677, 0.79352415, 0.07304186, 0.01363714]], dtype=float32)]\n",
      "\n",
      " --- At epoch 58 : \n",
      "  [58, [37.262627, 32.796726, 3.1655989, 3.596559], [33.13385, 13.444246, 25.605331, 5.7321124], 58] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7321124, 0.0, 0.00058521825, array([[0.07259987, 0.85937274, 0.05818882, 0.00983855],\n",
      "       [0.09633126, 0.8266511 , 0.06567839, 0.01133922],\n",
      "       [0.0725894 , 0.83123964, 0.07500845, 0.02116252],\n",
      "       [0.11412398, 0.79819053, 0.07284047, 0.01484503],\n",
      "       [0.10948215, 0.7959292 , 0.0813156 , 0.01327309]], dtype=float32)]\n",
      "\n",
      " --- At epoch 59 : \n",
      "  [59, [37.2721, 32.804775, 3.1626978, 3.5885556], [33.143185, 13.491571, 25.997925, 5.666], 59] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.666, 0.0, 0.00048542698, array([[0.0685911 , 0.85377175, 0.06715935, 0.01047781],\n",
      "       [0.0919283 , 0.82148224, 0.0745146 , 0.01207482],\n",
      "       [0.06768382, 0.8245997 , 0.084448  , 0.02326853],\n",
      "       [0.10877659, 0.793824  , 0.08156033, 0.01583916],\n",
      "       [0.10283679, 0.7925696 , 0.09062197, 0.01397172]], dtype=float32)]\n",
      "\n",
      " --- At epoch 60 : \n",
      "  [60, [37.204224, 32.71863, 3.138108, 3.5862699], [33.186043, 13.407049, 25.409641, 5.6833363], 60] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.6833363, 0.0, 0.00053534535, array([[0.06073721, 0.85762423, 0.07131381, 0.01032467],\n",
      "       [0.08373502, 0.82464963, 0.0795397 , 0.01207566],\n",
      "       [0.06089522, 0.8254587 , 0.0897804 , 0.02386563],\n",
      "       [0.09894355, 0.79555756, 0.08918855, 0.01631033],\n",
      "       [0.09463405, 0.7908649 , 0.09998151, 0.01451954]], dtype=float32)]\n",
      "\n",
      " --- At epoch 61 : \n",
      "  [61, [37.174763, 32.679886, 3.1324456, 3.584082], [33.201145, 13.393392, 25.354477, 5.6947374], 61] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.6947374, 0.0, 0.00063478114, array([[0.05406157, 0.8575393 , 0.0779582 , 0.01044095],\n",
      "       [0.07612799, 0.82576954, 0.08575386, 0.0123486 ],\n",
      "       [0.05417825, 0.82498616, 0.09597003, 0.02486559],\n",
      "       [0.08977045, 0.79392284, 0.09959049, 0.01671621],\n",
      "       [0.08547386, 0.7904261 , 0.1095066 , 0.01459345]], dtype=float32)]\n",
      "\n",
      " --- At epoch 62 : \n",
      "  [62, [37.142056, 32.63798, 3.113775, 3.5815806], [33.234283, 13.380198, 25.389923, 5.683168], 62] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.683168, 0.0, 0.00064601563, array([[0.04949827, 0.8547488 , 0.08521223, 0.01054073],\n",
      "       [0.06988534, 0.8207901 , 0.09676599, 0.01255855],\n",
      "       [0.04951323, 0.8167744 , 0.10828379, 0.0254286 ],\n",
      "       [0.08406437, 0.7955238 , 0.1030282 , 0.01738352],\n",
      "       [0.0790773 , 0.78841484, 0.11739068, 0.01511712]], dtype=float32)]\n",
      "\n",
      " --- At epoch 63 : \n",
      "  [63, [36.912533, 32.30413, 2.927993, 3.6152747], [33.7788, 13.344862, 25.800858, 5.739371], 63] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.739371, 0.0, 0.0008357249, array([[0.06695294, 0.8437511 , 0.08096706, 0.00832889],\n",
      "       [0.08513071, 0.8164608 , 0.08795471, 0.01045377],\n",
      "       [0.07150876, 0.8104759 , 0.09649914, 0.02151614],\n",
      "       [0.09849264, 0.772143  , 0.11491866, 0.01444566],\n",
      "       [0.09845307, 0.7618881 , 0.12669176, 0.01296704]], dtype=float32)]\n",
      "\n",
      " --- At epoch 64 : \n",
      "  [64, [37.036057, 32.496647, 3.0254838, 3.5787504], [33.46914, 13.353334, 26.200008, 5.642149], 64] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.642149, 0.0, 0.00064430974, array([[0.04827974, 0.8325267 , 0.10777886, 0.01141468],\n",
      "       [0.06557825, 0.8018362 , 0.11856612, 0.01401948],\n",
      "       [0.04781726, 0.7962545 , 0.1287457 , 0.02718247],\n",
      "       [0.07626014, 0.7665056 , 0.13828346, 0.01895085],\n",
      "       [0.070462  , 0.76093864, 0.15172543, 0.01687391]], dtype=float32)]\n",
      "\n",
      " --- At epoch 65 : \n",
      "  [65, [37.065823, 32.545826, 3.0611455, 3.5698502], [33.34113, 13.360759, 26.05981, 5.64771], 65] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.64771, 0.0, 0.00048832333, array([[0.03521609, 0.833024  , 0.11905101, 0.0127089 ],\n",
      "       [0.0507658 , 0.8046837 , 0.12901202, 0.01553841],\n",
      "       [0.0341157 , 0.79753613, 0.13894004, 0.02940813],\n",
      "       [0.05931867, 0.7697456 , 0.15020189, 0.02073382],\n",
      "       [0.05404206, 0.76550114, 0.16218114, 0.01827569]], dtype=float32)]\n",
      "\n",
      " --- At epoch 66 : \n",
      "  [66, [36.91427, 32.248623, 2.8892934, 3.590867], [34.05457, 13.404391, 25.587942, 5.7787967], 66] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7787967, 0.0, 0.001075087, array([[0.0420097 , 0.84186447, 0.10661647, 0.00950932],\n",
      "       [0.05435344, 0.81075954, 0.12264222, 0.01224477],\n",
      "       [0.04578588, 0.7990744 , 0.13221575, 0.022924  ],\n",
      "       [0.06261345, 0.7734265 , 0.14701717, 0.01694284],\n",
      "       [0.06307364, 0.75429964, 0.16722584, 0.01540087]], dtype=float32)]\n",
      "\n",
      " --- At epoch 67 : \n",
      "  [67, [37.050816, 32.489376, 3.0116835, 3.5644503], [33.568672, 13.327919, 25.877861, 5.698919], 67] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.698919, 0.0, 0.0004904441, array([[0.02585391, 0.8400727 , 0.1211887 , 0.01288469],\n",
      "       [0.03781987, 0.8071942 , 0.13881625, 0.01616963],\n",
      "       [0.02749631, 0.79575884, 0.14845061, 0.02829428],\n",
      "       [0.04611569, 0.7718003 , 0.16025977, 0.0218242 ],\n",
      "       [0.04244796, 0.75525343, 0.18232492, 0.01997372]], dtype=float32)]\n",
      "\n",
      " --- At epoch 68 : \n",
      "  [68, [36.958736, 32.38358, 3.000911, 3.5662334], [33.567627, 13.259648, 25.320889, 5.7299485], 68] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7299485, 0.0, 0.0008141643, array([[0.02250043, 0.8389451 , 0.12605767, 0.01249672],\n",
      "       [0.03319945, 0.80779946, 0.1434403 , 0.01556085],\n",
      "       [0.02310938, 0.7959603 , 0.15434623, 0.02658411],\n",
      "       [0.03984804, 0.7712585 , 0.16802369, 0.02086986],\n",
      "       [0.0370287 , 0.75030994, 0.19301642, 0.01964496]], dtype=float32)]\n",
      "\n",
      " --- At epoch 69 : \n",
      "  [69, [36.896286, 32.284065, 2.958629, 3.5639496], [33.72773, 13.303973, 25.474072, 5.756943], 69] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.756943, 0.0, 0.0009300484, array([[0.02273621, 0.83800447, 0.12653492, 0.01272447],\n",
      "       [0.03316876, 0.80373126, 0.14707032, 0.01602966],\n",
      "       [0.02340576, 0.79065305, 0.15859613, 0.02734504],\n",
      "       [0.03824263, 0.769257  , 0.17099757, 0.02150275],\n",
      "       [0.03651294, 0.7462664 , 0.19748206, 0.01973862]], dtype=float32)]\n",
      "\n",
      " --- At epoch 70 : \n",
      "  [70, [36.803886, 32.16364, 2.9056656, 3.5840752], [33.82083, 13.301562, 25.380499, 5.8470254], 70] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8470254, 0.0, 0.0007387064, array([[0.02364582, 0.8309791 , 0.13255475, 0.01282034],\n",
      "       [0.03448154, 0.7997896 , 0.1496215 , 0.01610736],\n",
      "       [0.02485499, 0.7889635 , 0.15907708, 0.02710446],\n",
      "       [0.0393332 , 0.7610571 , 0.1783369 , 0.02127278],\n",
      "       [0.03648016, 0.74124753, 0.20262218, 0.0196501 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 71 : \n",
      "  [71, [36.888416, 32.301197, 2.976378, 3.5542438], [33.58854, 13.267622, 25.4577, 5.7954307], 71] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7954307, 0.0, 0.0005146156, array([[0.01753805, 0.8265385 , 0.14130905, 0.01461437],\n",
      "       [0.02716754, 0.7946548 , 0.16006175, 0.01811598],\n",
      "       [0.0184704 , 0.7817167 , 0.17066628, 0.02914666],\n",
      "       [0.03165393, 0.75444925, 0.19003764, 0.02385927],\n",
      "       [0.02878142, 0.73156744, 0.21747425, 0.02217689]], dtype=float32)]\n",
      "\n",
      " --- At epoch 72 : \n",
      "  [72, [36.951157, 32.393814, 3.011852, 3.542151], [33.473557, 13.245192, 25.446596, 5.8072653], 72] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8072653, 0.0, 0.00031212275, array([[0.01643464, 0.82366025, 0.1438064 , 0.01609873],\n",
      "       [0.02580353, 0.7926524 , 0.16175139, 0.01979261],\n",
      "       [0.01713057, 0.7808242 , 0.1711459 , 0.0308994 ],\n",
      "       [0.02972185, 0.755511  , 0.18909305, 0.02567409],\n",
      "       [0.02672953, 0.73558146, 0.21382062, 0.02386832]], dtype=float32)]\n",
      "\n",
      " --- At epoch 73 : \n",
      "  [73, [36.831852, 32.27215, 3.0048203, 3.5322144], [33.402145, 13.184709, 25.020815, 5.800811], 73] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.800811, 0.0, 0.00029511144, array([[0.01447734, 0.81732595, 0.15389776, 0.0142989 ],\n",
      "       [0.02302027, 0.7890697 , 0.17044413, 0.01746591],\n",
      "       [0.01517965, 0.77660793, 0.1808138 , 0.02739854],\n",
      "       [0.02735671, 0.74878895, 0.20117465, 0.02267972],\n",
      "       [0.02419211, 0.72532207, 0.22920966, 0.02127618]], dtype=float32)]\n",
      "\n",
      " --- At epoch 74 : \n",
      "  [74, [36.85707, 32.306877, 3.0253613, 3.5329356], [33.3673, 13.190472, 25.111307, 5.8696556], 74] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.8696556, 0.0, 0.00022286394, array([[0.01513238, 0.81892127, 0.15078656, 0.01515977],\n",
      "       [0.02349371, 0.78700155, 0.17084356, 0.01866116],\n",
      "       [0.01586159, 0.77350175, 0.18193856, 0.02869804],\n",
      "       [0.02817948, 0.75369024, 0.19430026, 0.02383   ],\n",
      "       [0.02506098, 0.7300544 , 0.2226585 , 0.02222616]], dtype=float32)]\n",
      "\n",
      " --- At epoch 75 : \n",
      "  [75, [36.778484, 32.223038, 3.006029, 3.5245254], [33.360035, 13.132097, 24.513474, 5.896305], 75] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.896305, 0.0, 0.00016103423, array([[0.01608915, 0.82093537, 0.14973517, 0.01324034],\n",
      "       [0.0241532 , 0.7896325 , 0.16959575, 0.01661849],\n",
      "       [0.01708342, 0.77669734, 0.18029882, 0.02592042],\n",
      "       [0.0304096 , 0.7555809 , 0.19287655, 0.02113295],\n",
      "       [0.02654055, 0.7308823 , 0.22267707, 0.01990004]], dtype=float32)]\n",
      "\n",
      " --- At epoch 76 : \n",
      "  [76, [36.714977, 32.15781, 3.0032675, 3.5222297], [33.31434, 13.099736, 24.346512, 5.9507837], 76] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9507837, 0.0, 0.00010052578, array([[0.01584947, 0.8170548 , 0.15448308, 0.01261261],\n",
      "       [0.02331875, 0.78612643, 0.17453688, 0.01601798],\n",
      "       [0.01688235, 0.7734957 , 0.18448858, 0.0251334 ],\n",
      "       [0.02980223, 0.7526588 , 0.19739875, 0.02014022],\n",
      "       [0.02595555, 0.729947  , 0.22541237, 0.01868514]], dtype=float32)]\n",
      "\n",
      " --- At epoch 77 : \n",
      "  [77, [36.58185, 32.00073, 2.9692316, 3.5158472], [33.337303, 13.0366125, 23.72654, 5.9946427], 77] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.9946427, 0.0, 8.66374e-05, array([[0.01508305, 0.8167764 , 0.156657  , 0.01148351],\n",
      "       [0.02213181, 0.7855719 , 0.1775771 , 0.01471926],\n",
      "       [0.01661287, 0.7729946 , 0.1878337 , 0.02255891],\n",
      "       [0.02905894, 0.7492618 , 0.20342296, 0.01825627],\n",
      "       [0.02491934, 0.72267467, 0.23507333, 0.01733272]], dtype=float32)]\n",
      "\n",
      " --- At epoch 78 : \n",
      "  [78, [36.561836, 31.980501, 2.9671006, 3.5103805], [33.31992, 13.015565, 23.535465, 6.0337496], 78] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0337496, 0.0, 8.985009e-05, array([[0.01421473, 0.8145904 , 0.15976134, 0.01143353],\n",
      "       [0.02037611, 0.78328276, 0.18165372, 0.01468744],\n",
      "       [0.01586306, 0.76917374, 0.19321738, 0.02174585],\n",
      "       [0.02736601, 0.747038  , 0.2078201 , 0.01777587],\n",
      "       [0.02395194, 0.716167  , 0.24254534, 0.0173357 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 79 : \n",
      "  [79, [36.510006, 31.923721, 2.9480944, 3.5039525], [33.319153, 13.0112915, 23.60713, 6.0700884], 79] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0700884, 0.0, 0.00025129248, array([[0.01508739, 0.80623883, 0.16620658, 0.01246711],\n",
      "       [0.02114853, 0.7763049 , 0.18664347, 0.01590312],\n",
      "       [0.01672285, 0.76296383, 0.19755158, 0.02276171],\n",
      "       [0.02839829, 0.7401703 , 0.21276553, 0.01866587],\n",
      "       [0.02477555, 0.71025324, 0.24668966, 0.01828157]], dtype=float32)]\n",
      "\n",
      " --- At epoch 80 : \n",
      "  [80, [36.594017, 32.031063, 2.9878922, 3.5069885], [33.250935, 13.026449, 23.745392, 6.1420636], 80] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1420636, 0.0, 6.9129754e-05, array([[0.0166283 , 0.80480677, 0.16508159, 0.01348334],\n",
      "       [0.023695  , 0.7740428 , 0.18495443, 0.01730781],\n",
      "       [0.01826537, 0.7614913 , 0.1952571 , 0.0249862 ],\n",
      "       [0.03082429, 0.7383186 , 0.210689  , 0.02016802],\n",
      "       [0.02727515, 0.7092403 , 0.24413885, 0.01934559]], dtype=float32)]\n",
      "\n",
      " --- At epoch 81 : \n",
      "  [81, [36.688087, 32.14597, 3.011856, 3.4945283], [33.223648, 13.087721, 24.331066, 6.127628], 81] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.127628, 0.0, 0.00018802065, array([[0.01951598, 0.7957244 , 0.17127982, 0.01347986],\n",
      "       [0.02709677, 0.7640225 , 0.19148946, 0.0173912 ],\n",
      "       [0.02077354, 0.7502404 , 0.20322691, 0.02575913],\n",
      "       [0.03467574, 0.72848505, 0.21634965, 0.02048956],\n",
      "       [0.03097253, 0.698852  , 0.25071093, 0.01946453]], dtype=float32)]\n",
      "\n",
      " --- At epoch 82 : \n",
      "  [82, [36.74128, 32.218967, 3.038569, 3.4858258], [33.1443, 13.10612, 24.474108, 6.1742578], 82] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.1742578, 0.0, 0.0002187763, array([[0.02111481, 0.7892481 , 0.17576411, 0.01387295],\n",
      "       [0.02945114, 0.7577372 , 0.19493107, 0.01788057],\n",
      "       [0.02240864, 0.7451593 , 0.20590898, 0.026523  ],\n",
      "       [0.03782729, 0.724123  , 0.2172884 , 0.02076138],\n",
      "       [0.03335161, 0.69790554, 0.24933623, 0.01940661]], dtype=float32)]\n",
      "\n",
      " --- At epoch 83 : \n",
      "  [83, [36.676826, 32.125214, 2.9811597, 3.486388], [33.279472, 13.09395, 24.35925, 6.278543], 83] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.278543, 0.0, 0.00029068813, array([[0.02465528, 0.7961305 , 0.1650839 , 0.01413033],\n",
      "       [0.03390136, 0.76124656, 0.18621294, 0.01863924],\n",
      "       [0.02712868, 0.74742234, 0.19739138, 0.02805752],\n",
      "       [0.04300676, 0.7255482 , 0.20957854, 0.02186638],\n",
      "       [0.03881977, 0.69666195, 0.24388297, 0.02063533]], dtype=float32)]\n",
      "\n",
      " --- At epoch 84 : \n",
      "  [84, [36.723694, 32.195316, 3.0247364, 3.4761317], [33.173393, 13.081757, 24.277676, 6.282651], 84] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.282651, 0.0, 0.00026295186, array([[0.02396226, 0.79016304, 0.17164145, 0.01423322],\n",
      "       [0.03313234, 0.7566766 , 0.19147767, 0.01871334],\n",
      "       [0.02585824, 0.7441938 , 0.20187843, 0.02806956],\n",
      "       [0.04132696, 0.72262913, 0.21426369, 0.0217802 ],\n",
      "       [0.03789596, 0.69449204, 0.24717964, 0.02043245]], dtype=float32)]\n",
      "\n",
      " --- At epoch 85 : \n",
      "  [85, [36.712162, 32.190884, 3.0406709, 3.4706004], [33.115665, 13.066033, 24.103441, 6.3279676], 85] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3279676, 0.0, 0.00019796932, array([[0.02481651, 0.78855973, 0.17299506, 0.01362871],\n",
      "       [0.034357  , 0.7546448 , 0.19309822, 0.01790007],\n",
      "       [0.02691   , 0.74042344, 0.20568149, 0.02698505],\n",
      "       [0.04413678, 0.7186499 , 0.21624638, 0.02096694],\n",
      "       [0.03997079, 0.68804556, 0.25209925, 0.01988443]], dtype=float32)]\n",
      "\n",
      " --- At epoch 86 : \n",
      "  [86, [36.669415, 32.062305, 2.9198315, 3.4953249], [33.54861, 13.15509, 24.43043, 6.383098], 86] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.383098, 0.0, 0.00055595994, array([[0.02568353, 0.78992754, 0.16807474, 0.01631421],\n",
      "       [0.03401198, 0.75120425, 0.19298108, 0.02180263],\n",
      "       [0.02890058, 0.73467416, 0.2047408 , 0.03168439],\n",
      "       [0.04135082, 0.71494883, 0.21869773, 0.0250026 ],\n",
      "       [0.0405418 , 0.6795137 , 0.2559929 , 0.02395161]], dtype=float32)]\n",
      "\n",
      " --- At epoch 87 : \n",
      "  [87, [36.747597, 32.21241, 3.0025227, 3.4670029], [33.247604, 13.114592, 24.637854, 6.3762774], 87] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3762774, 0.0, 0.00034164777, array([[0.02416356, 0.7774148 , 0.18023762, 0.01818402],\n",
      "       [0.03282833, 0.740608  , 0.20290558, 0.02365809],\n",
      "       [0.02645496, 0.7248218 , 0.21488369, 0.03383959],\n",
      "       [0.04020759, 0.7044207 , 0.22803754, 0.02733419],\n",
      "       [0.03794687, 0.6709903 , 0.26482543, 0.02623739]], dtype=float32)]\n",
      "\n",
      " --- At epoch 88 : \n",
      "  [88, [36.807594, 32.285336, 3.0206313, 3.4625752], [33.198494, 13.159787, 25.103872, 6.406782], 88] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.406782, 0.0, 0.0002706239, array([[0.02432864, 0.775055  , 0.1804515 , 0.02016481],\n",
      "       [0.03327941, 0.7374808 , 0.20324089, 0.02599887],\n",
      "       [0.02666936, 0.7208981 , 0.21504717, 0.03738535],\n",
      "       [0.0407738 , 0.70120245, 0.22784775, 0.030176  ],\n",
      "       [0.038102  , 0.6694805 , 0.26402202, 0.02839545]], dtype=float32)]\n",
      "\n",
      " --- At epoch 89 : \n",
      "  [89, [36.87296, 32.382553, 3.0715811, 3.4528708], [33.075043, 13.167362, 25.152117, 6.465182], 89] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.465182, 0.0, 0.000350177, array([[0.02515261, 0.7618421 , 0.19260858, 0.02039677],\n",
      "       [0.03454274, 0.7264385 , 0.21326283, 0.02575592],\n",
      "       [0.02701157, 0.71121585, 0.22538672, 0.03638593],\n",
      "       [0.04234971, 0.6902007 , 0.23755513, 0.02989447],\n",
      "       [0.03964994, 0.65708524, 0.27496752, 0.02829725]], dtype=float32)]\n",
      "\n",
      " Validation performance under the hyper-parameters: \n",
      " {'lr': 0.001, 'batch_size': 203.71763540614378, 'l2_mean': 0.09869818657745369, 'l2_var': 0.02776556266605989, 'burn_in_steps': 80} [45, [37.316784, 32.92408, 3.2125936, 3.668517], [32.900936, 13.52195, 27.812849, 6.144498], 45]\n",
      "\n",
      " Training time: \n",
      " 3.4044793461300995 \n",
      "\n",
      "\n",
      " --- At epoch 0 : \n",
      "  [0, [50.658165, 47.246014, 5.461492, 5.950299], [37.118637, 25.031507, 97.2809, 4.4867277], 0] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.4867277, 0.08425828, 0.22627969, array([[0.2029535 , 0.459246  , 0.16753624, 0.17026417],\n",
      "       [0.20713595, 0.4465719 , 0.1848128 , 0.1614794 ],\n",
      "       [0.21648026, 0.43592995, 0.17674623, 0.17084353],\n",
      "       [0.22568904, 0.4216523 , 0.16738288, 0.18527573],\n",
      "       [0.23092578, 0.43701336, 0.132985  , 0.19907585]], dtype=float32)]\n",
      "\n",
      " --- At epoch 1 : \n",
      "  [1, [50.567173, 47.150875, 5.4433327, 5.2460747], [37.099907, 24.994982, 97.12447, 4.5179505], 1] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.5179505, 0.029057514, 0.18489972, array([[0.10121754, 0.74915135, 0.06739492, 0.08223615],\n",
      "       [0.11916554, 0.70075405, 0.08542231, 0.09465815],\n",
      "       [0.12945467, 0.679233  , 0.08740591, 0.10390644],\n",
      "       [0.1431391 , 0.64571095, 0.09320754, 0.11794247],\n",
      "       [0.15342845, 0.63164485, 0.08438446, 0.1305423 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 2 : \n",
      "  [2, [50.43352, 47.011826, 5.4194417, 4.866233], [37.047344, 24.899956, 96.62579, 4.591713], 2] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.591713, 0.0035684118, 0.15422629, array([[0.00993294, 0.98238313, 0.00550289, 0.00218102],\n",
      "       [0.01907862, 0.9657907 , 0.01141218, 0.00371843],\n",
      "       [0.02108375, 0.96282035, 0.0120888 , 0.00400707],\n",
      "       [0.02801845, 0.95061284, 0.01594376, 0.00542486],\n",
      "       [0.03778909, 0.9351546 , 0.01936179, 0.00769458]], dtype=float32)]\n",
      "\n",
      " --- At epoch 3 : \n",
      "  [3, [50.19493, 46.76119, 5.3766074, 4.798607], [36.936504, 24.677942, 95.50516, 4.6177745], 3] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6177745, 0.00011872398, 0.12523629, array([[7.3752739e-04, 9.9873286e-01, 3.5347708e-04, 1.7610188e-04],\n",
      "       [2.0820620e-03, 9.9645519e-01, 1.0578918e-03, 4.0484834e-04],\n",
      "       [2.3758155e-03, 9.9600226e-01, 1.1725761e-03, 4.4935397e-04],\n",
      "       [3.7924205e-03, 9.9360621e-01, 1.8750064e-03, 7.2633935e-04],\n",
      "       [6.6005681e-03, 9.8911464e-01, 3.0195778e-03, 1.2652222e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 4 : \n",
      "  [4, [49.866337, 46.415886, 5.316547, 4.7364306], [36.785927, 24.370268, 93.9401, 4.609174], 4] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.609174, 4.9717045e-07, 0.093298666, array([[2.3586949e-04, 9.9961299e-01, 9.4659859e-05, 5.6576937e-05],\n",
      "       [7.0937898e-04, 9.9885285e-01, 3.0589502e-04, 1.3184617e-04],\n",
      "       [8.3166495e-04, 9.9867308e-01, 3.4720323e-04, 1.4799500e-04],\n",
      "       [1.5260010e-03, 9.9757093e-01, 6.3351495e-04, 2.6957746e-04],\n",
      "       [3.0618464e-03, 9.9522936e-01, 1.1895656e-03, 5.1916414e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 5 : \n",
      "  [5, [49.45972, 45.987225, 5.239859, 4.679367], [36.609653, 23.99836, 92.041466, 4.598606], 5] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.598606, 5.705394e-11, 0.06386334, array([[1.6346219e-04, 9.9974400e-01, 5.4201031e-05, 3.8334645e-05],\n",
      "       [4.6723531e-04, 9.9928576e-01, 1.6698918e-04, 8.0104641e-05],\n",
      "       [5.6960556e-04, 9.9913812e-01, 1.9781668e-04, 9.4492076e-05],\n",
      "       [1.1548543e-03, 9.9826247e-01, 3.9806275e-04, 1.8468610e-04],\n",
      "       [2.5687935e-03, 9.9620759e-01, 8.4539573e-04, 3.7816638e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 6 : \n",
      "  [6, [48.9642, 45.462425, 5.1430745, 4.6515503], [36.41009, 23.557241, 89.786354, 4.6064596], 6] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6064596, 2.1394294e-18, 0.04025253, array([[1.8943999e-04, 9.9969161e-01, 5.2014828e-05, 6.6964589e-05],\n",
      "       [5.0062418e-04, 9.9924004e-01, 1.4180463e-04, 1.1751645e-04],\n",
      "       [6.1563298e-04, 9.9906772e-01, 1.7327060e-04, 1.4337497e-04],\n",
      "       [1.3086731e-03, 9.9802160e-01, 3.7550309e-04, 2.9420527e-04],\n",
      "       [3.1207644e-03, 9.9539232e-01, 8.6175109e-04, 6.2518968e-04]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 7 : \n",
      "  [7, [48.364506, 44.8177, 5.0163026, 4.6251497], [36.201157, 23.046507, 87.17607, 4.600468], 7] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.600468, 3.4189114e-33, 0.024560366, array([[4.9456890e-04, 9.9907970e-01, 9.9153156e-05, 3.2646285e-04],\n",
      "       [9.2269439e-04, 9.9838543e-01, 2.0673356e-04, 4.8506769e-04],\n",
      "       [1.1918376e-03, 9.9790728e-01, 2.6341496e-04, 6.3742953e-04],\n",
      "       [2.5041583e-03, 9.9557650e-01, 5.7392142e-04, 1.3454073e-03],\n",
      "       [6.0384553e-03, 9.8981756e-01, 1.2999396e-03, 2.8440282e-03]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 8 : \n",
      "  [8, [47.687153, 44.092354, 4.8801017, 4.5835094], [35.9654, 22.470158, 84.20089, 4.599038], 8] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.599038, 0.0, 0.01390848, array([[8.82023654e-04, 9.97675955e-01, 2.24911637e-04, 1.21710263e-03],\n",
      "       [1.35123916e-03, 9.96637464e-01, 3.63035680e-04, 1.64822617e-03],\n",
      "       [1.88831915e-03, 9.95132267e-01, 5.24931937e-04, 2.45438679e-03],\n",
      "       [4.03726054e-03, 9.89537477e-01, 1.14229601e-03, 5.28300134e-03],\n",
      "       [1.14732888e-02, 9.71996546e-01, 2.99036573e-03, 1.35397855e-02]],\n",
      "      dtype=float32)]\n",
      "\n",
      " --- At epoch 9 : \n",
      "  [9, [46.976723, 43.32536, 4.735938, 4.552628], [35.73819, 21.86641, 81.09647, 4.6033635], 9] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6033635, 0.0, 0.009101553, array([[0.00404681, 0.98608506, 0.00141216, 0.00845602],\n",
      "       [0.00483081, 0.98375076, 0.00160419, 0.00981422],\n",
      "       [0.00697943, 0.9761105 , 0.00223905, 0.0146709 ],\n",
      "       [0.01272234, 0.95728314, 0.00460498, 0.02538959],\n",
      "       [0.03205002, 0.8969156 , 0.01156647, 0.05946791]], dtype=float32)]\n",
      "\n",
      " --- At epoch 10 : \n",
      "  [10, [46.28705, 42.58325, 4.599204, 4.5186296], [35.516113, 21.281958, 78.09312, 4.6184936], 10] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6184936, 0.0, 0.006412414, array([[0.00680282, 0.9712922 , 0.00388494, 0.01802005],\n",
      "       [0.00774964, 0.96782625, 0.00382307, 0.02060103],\n",
      "       [0.01020211, 0.95686275, 0.00480874, 0.02812642],\n",
      "       [0.01617655, 0.9328331 , 0.01070674, 0.04028364],\n",
      "       [0.03226325, 0.8661066 , 0.02071447, 0.08091573]], dtype=float32)]\n",
      "\n",
      " --- At epoch 11 : \n",
      "  [11, [45.580997, 41.830215, 4.466297, 4.4910603], [35.28219, 20.6794, 74.99211, 4.6660075], 11] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.6660075, 0.0, 0.0047849594, array([[0.00702919, 0.9640084 , 0.00601745, 0.02294492],\n",
      "       [0.00830676, 0.95902586, 0.00549621, 0.02717119],\n",
      "       [0.00943016, 0.95034415, 0.00617523, 0.0340505 ],\n",
      "       [0.01374435, 0.93024725, 0.01537016, 0.04063822],\n",
      "       [0.02118675, 0.89149344, 0.0209672 , 0.06635261]], dtype=float32)]\n",
      "\n",
      " --- At epoch 12 : \n",
      "  [12, [44.841644, 41.031742, 4.3254013, 4.4445944], [35.04262, 20.091461, 71.96104, 4.673005], 12] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.673005, 0.0, 0.0037004908, array([[0.0069043 , 0.9553752 , 0.00900976, 0.02871074],\n",
      "       [0.00830895, 0.95059085, 0.00836413, 0.03273612],\n",
      "       [0.00773864, 0.9462809 , 0.00898728, 0.03699311],\n",
      "       [0.01090194, 0.93476945, 0.01685805, 0.03747055],\n",
      "       [0.0126113 , 0.9187836 , 0.01913816, 0.04946695]], dtype=float32)]\n",
      "\n",
      " --- At epoch 13 : \n",
      "  [13, [44.153717, 40.30955, 4.209258, 4.4104877], [34.787884, 19.504072, 68.8405, 4.705191], 13] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.705191, 0.0, 0.002590247, array([[0.0052093 , 0.9675982 , 0.00735905, 0.01983348],\n",
      "       [0.00648698, 0.96355283, 0.00682907, 0.02313109],\n",
      "       [0.00600627, 0.96066505, 0.00727077, 0.02605788],\n",
      "       [0.00898494, 0.9516566 , 0.0135711 , 0.02578738],\n",
      "       [0.00947211, 0.9429862 , 0.01476677, 0.03277493]], dtype=float32)]\n",
      "\n",
      " --- At epoch 14 : \n",
      "  [14, [43.51382, 39.63056, 4.09921, 4.376203], [34.58032, 18.967302, 65.8789, 4.7512264], 14] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.7512264, 0.0, 0.0017293075, array([[0.00549642, 0.9734867 , 0.00703268, 0.01398416],\n",
      "       [0.0068441 , 0.970138  , 0.00676061, 0.0162572 ],\n",
      "       [0.00637495, 0.9676913 , 0.00748285, 0.01845097],\n",
      "       [0.00943711, 0.95972854, 0.0127771 , 0.01805722],\n",
      "       [0.01007969, 0.9517465 , 0.01472035, 0.02345348]], dtype=float32)]\n",
      "\n",
      " --- At epoch 15 : \n",
      "  [15, [42.902176, 38.98178, 3.9942663, 4.3399663], [34.378517, 18.454794, 63.011543, 4.81933], 15] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.81933, 0.0, 0.00089361035, array([[0.00656715, 0.974872  , 0.00810564, 0.01045526],\n",
      "       [0.00814356, 0.9719153 , 0.00781091, 0.01213017],\n",
      "       [0.00751085, 0.97025573, 0.00864472, 0.01358873],\n",
      "       [0.01117914, 0.961304  , 0.0143724 , 0.01314452],\n",
      "       [0.01142195, 0.95587325, 0.01615811, 0.01654675]], dtype=float32)]\n",
      "\n",
      " --- At epoch 16 : \n",
      "  [16, [42.31546, 38.36001, 3.8963454, 4.3038664], [34.197765, 17.956259, 60.158237, 4.8931794], 16] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.8931794, 0.0, 0.0008566133, array([[0.00779829, 0.9767203 , 0.0083023 , 0.00717916],\n",
      "       [0.00973461, 0.9735771 , 0.00824654, 0.00844176],\n",
      "       [0.00907323, 0.9721265 , 0.00930195, 0.00949827],\n",
      "       [0.01351147, 0.96268654, 0.01476152, 0.00904044],\n",
      "       [0.01336654, 0.9588058 , 0.01660907, 0.01121861]], dtype=float32)]\n",
      "\n",
      " --- At epoch 17 : \n",
      "  [17, [41.77147, 37.78366, 3.8093195, 4.2654285], [34.022465, 17.497564, 57.460903, 4.9852633], 17] \n",
      "\n",
      "   loss and regualization : \n",
      " [4.9852633, 0.0, 0.00051888457, array([[0.00983195, 0.9754782 , 0.00899802, 0.00569183],\n",
      "       [0.01223466, 0.97174567, 0.00928133, 0.00673836],\n",
      "       [0.01134592, 0.97046083, 0.01068713, 0.00750604],\n",
      "       [0.01683875, 0.96165216, 0.01457458, 0.00693454],\n",
      "       [0.01643593, 0.9584653 , 0.01659461, 0.00850417]], dtype=float32)]\n",
      "\n",
      " --- At epoch 18 : \n",
      "  [18, [41.24397, 37.222847, 3.7243414, 4.2272596], [33.857605, 17.049133, 54.758, 5.1004057], 18] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.1004057, 0.0, 0.00032055733, array([[0.01210699, 0.9732957 , 0.01019656, 0.00440074],\n",
      "       [0.01484956, 0.96991247, 0.00992564, 0.00531242],\n",
      "       [0.01366531, 0.9694793 , 0.01106357, 0.00579181],\n",
      "       [0.02031688, 0.9573701 , 0.0170996 , 0.00521341],\n",
      "       [0.01935384, 0.9558793 , 0.01840218, 0.00636475]], dtype=float32)]\n",
      "\n",
      " --- At epoch 19 : \n",
      "  [19, [40.737164, 36.682514, 3.6451495, 4.18849], [33.71327, 16.628862, 52.159008, 5.204024], 19] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.204024, 1.964034e-06, 0.00038826186, array([[0.01489651, 0.97176874, 0.01006147, 0.00327327],\n",
      "       [0.01847325, 0.9669902 , 0.01043581, 0.00410077],\n",
      "       [0.01676583, 0.9668519 , 0.01200179, 0.0043805 ],\n",
      "       [0.02514485, 0.9548815 , 0.01611482, 0.00385879],\n",
      "       [0.02302809, 0.9545341 , 0.01775822, 0.00467954]], dtype=float32)]\n",
      "\n",
      " --- At epoch 20 : \n",
      "  [20, [40.35895, 36.283638, 3.592676, 4.1468396], [33.641006, 16.204674, 49.450043, 5.3738937], 20] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.3738937, 8.391699e-26, 0.00049514254, array([[0.01425049, 0.9741761 , 0.00910869, 0.00246473],\n",
      "       [0.01794699, 0.96975505, 0.00915422, 0.00314372],\n",
      "       [0.01708395, 0.9690477 , 0.01037274, 0.00349565],\n",
      "       [0.02412931, 0.95531005, 0.01737043, 0.00319023],\n",
      "       [0.02509116, 0.95166737, 0.0192268 , 0.00401462]], dtype=float32)]\n",
      "\n",
      " --- At epoch 21 : \n",
      "  [21, [39.910915, 35.816544, 3.5416512, 4.104309], [33.436348, 15.867927, 47.232136, 5.545419], 21] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.545419, 1.2636105e-33, 0.0003126814, array([[0.01783442, 0.968627  , 0.01128364, 0.00225485],\n",
      "       [0.02230199, 0.9619352 , 0.01289242, 0.0028703 ],\n",
      "       [0.02004562, 0.96134514, 0.01554935, 0.00305991],\n",
      "       [0.03003437, 0.94947857, 0.01779628, 0.00269068],\n",
      "       [0.02846034, 0.94728625, 0.02100049, 0.00325288]], dtype=float32)]\n",
      "\n",
      " --- At epoch 22 : \n",
      "  [22, [39.503597, 35.38206, 3.4864857, 4.059652], [33.308876, 15.479765, 44.62512, 5.7493334], 22] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.7493334, 8.131373e-21, 0.00046217046, array([[0.01989871, 0.9675015 , 0.01078008, 0.00181969],\n",
      "       [0.02507572, 0.9618524 , 0.01064699, 0.00242486],\n",
      "       [0.02238158, 0.9632355 , 0.01182823, 0.00255467],\n",
      "       [0.03366574, 0.94700646, 0.01717684, 0.00215099],\n",
      "       [0.03180107, 0.9479145 , 0.01764267, 0.00264179]], dtype=float32)]\n",
      "\n",
      " --- At epoch 23 : \n",
      "  [23, [38.823505, 34.643692, 3.4110096, 3.979698], [33.116745, 14.625134, 37.91986, 6.244074], 23] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.244074, 0.029369667, 0.00041055324, array([[0.0261174 , 0.9615934 , 0.01065286, 0.0016364 ],\n",
      "       [0.03216179, 0.95530796, 0.0102409 , 0.00228936],\n",
      "       [0.02887389, 0.9574299 , 0.01135264, 0.00234358],\n",
      "       [0.04373157, 0.93668675, 0.0177509 , 0.00183082],\n",
      "       [0.03952122, 0.9409142 , 0.01731943, 0.00224504]], dtype=float32)]\n",
      "\n",
      " --- At epoch 24 : \n",
      "  [24, [38.156696, 33.87825, 3.3768177, 3.8776724], [32.94979, 13.65055, 28.72128, 6.8040614], 24] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.8040614, 0.08178651, 0.002676704, array([[0.03766209, 0.9467454 , 0.01254501, 0.00304752],\n",
      "       [0.04589972, 0.93560416, 0.01443921, 0.00405688],\n",
      "       [0.03979848, 0.9387305 , 0.01734056, 0.00413049],\n",
      "       [0.06032995, 0.9188921 , 0.01764258, 0.00313543],\n",
      "       [0.0529605 , 0.9231038 , 0.02026165, 0.00367402]], dtype=float32)]\n",
      "\n",
      " --- At epoch 25 : \n",
      "  [25, [37.93279, 33.64185, 3.2910547, 3.8504083], [32.971447, 13.792845, 30.60804, 6.540495], 25] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.540495, 0.05545166, 0.0012726422, array([[0.04342818, 0.9394049 , 0.01258573, 0.00458108],\n",
      "       [0.05217531, 0.9272675 , 0.01503841, 0.00551873],\n",
      "       [0.04591078, 0.9303005 , 0.01804409, 0.00574459],\n",
      "       [0.06742132, 0.91037196, 0.01745228, 0.00475436],\n",
      "       [0.05674531, 0.9186256 , 0.01957751, 0.00505152]], dtype=float32)]\n",
      "\n",
      " --- At epoch 26 : \n",
      "  [26, [37.538406, 33.189243, 3.2564273, 3.7869616], [32.88647, 13.399364, 26.800253, 6.510536], 26] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.510536, 0.067715466, 0.0013743583, array([[0.04494542, 0.93273807, 0.01597546, 0.00634105],\n",
      "       [0.0535685 , 0.9218356 , 0.01750667, 0.00708924],\n",
      "       [0.0463149 , 0.9259478 , 0.02020362, 0.00753371],\n",
      "       [0.06859324, 0.90406543, 0.0209298 , 0.00641152],\n",
      "       [0.05863034, 0.912418  , 0.02226285, 0.00668874]], dtype=float32)]\n",
      "\n",
      " --- At epoch 27 : \n",
      "  [27, [37.3699, 33.00632, 3.2194924, 3.7406359], [32.876442, 13.332004, 26.423487, 6.353221], 27] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.353221, 0.060089994, 0.0012966123, array([[0.04879441, 0.9196431 , 0.01770531, 0.01385712],\n",
      "       [0.058718  , 0.91030383, 0.01827991, 0.01269825],\n",
      "       [0.05154815, 0.91338795, 0.02064636, 0.01441751],\n",
      "       [0.07525396, 0.88699156, 0.02287895, 0.01487548],\n",
      "       [0.0639077 , 0.89880323, 0.02305028, 0.01423876]], dtype=float32)]\n",
      "\n",
      " --- At epoch 28 : \n",
      "  [28, [37.140396, 32.738235, 3.2042403, 3.7047966], [32.808975, 13.156196, 24.484522, 6.3040733], 28] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3040733, 0.05959131, 0.0022499436, array([[0.04645528, 0.91169584, 0.0208732 , 0.02097573],\n",
      "       [0.05625679, 0.90340745, 0.02204204, 0.01829367],\n",
      "       [0.04766706, 0.9066197 , 0.02480011, 0.02091306],\n",
      "       [0.07203335, 0.8810187 , 0.02464416, 0.02230375],\n",
      "       [0.06077703, 0.89294213, 0.02554081, 0.02073997]], dtype=float32)]\n",
      "\n",
      " --- At epoch 29 : \n",
      "  [29, [37.099937, 32.70123, 3.191364, 3.66393], [32.787563, 13.147253, 24.605827, 6.2380304], 29] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.2380304, 0.049564525, 0.0020300285, array([[0.04591938, 0.90097976, 0.02537149, 0.02772942],\n",
      "       [0.05532457, 0.89532214, 0.02490859, 0.02444469],\n",
      "       [0.04782445, 0.89658827, 0.027517  , 0.02807036],\n",
      "       [0.07203718, 0.8670968 , 0.03106671, 0.02979934],\n",
      "       [0.06160235, 0.8796209 , 0.03037666, 0.02840009]], dtype=float32)]\n",
      "\n",
      " --- At epoch 30 : \n",
      "  [30, [37.03249, 32.623302, 3.1848412, 3.6340942], [32.75149, 13.155825, 24.71829, 6.169735], 30] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.169735, 0.03788042, 0.0017161048, array([[0.04270795, 0.89086837, 0.03168589, 0.03473787],\n",
      "       [0.05168847, 0.8847927 , 0.03225947, 0.0312594 ],\n",
      "       [0.04440342, 0.88388467, 0.03617585, 0.03553606],\n",
      "       [0.06809476, 0.8564842 , 0.03815424, 0.03726687],\n",
      "       [0.05856254, 0.8660568 , 0.03893487, 0.03644576]], dtype=float32)]\n",
      "\n",
      " --- At epoch 31 : \n",
      "  [31, [36.733685, 32.216824, 3.0031796, 3.6517792], [33.324142, 13.064598, 24.325676, 6.2445073], 31] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.2445073, 0.028118867, 0.002282112, array([[0.03462114, 0.89458   , 0.03989013, 0.03090871],\n",
      "       [0.04179044, 0.8844507 , 0.04336333, 0.03039558],\n",
      "       [0.03936021, 0.875945  , 0.04948127, 0.03521361],\n",
      "       [0.05198678, 0.85415506, 0.05628391, 0.03757426],\n",
      "       [0.05205593, 0.8479395 , 0.06059636, 0.0394082 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 32 : \n",
      "  [32, [36.882015, 32.44796, 3.1292465, 3.59265], [32.847168, 13.071501, 24.629597, 6.0168786], 32] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0168786, 0.02317592, 0.0017383414, array([[0.03294999, 0.8680228 , 0.05091497, 0.04811223],\n",
      "       [0.04236932, 0.8590969 , 0.05206484, 0.04646892],\n",
      "       [0.0353637 , 0.854817  , 0.05766059, 0.05215866],\n",
      "       [0.05200623, 0.82768685, 0.06647873, 0.05382819],\n",
      "       [0.04746835, 0.8307394 , 0.06691109, 0.05488113]], dtype=float32)]\n",
      "\n",
      " --- At epoch 33 : \n",
      "  [33, [37.037373, 32.622013, 3.2113867, 3.5733824], [32.723824, 13.066701, 24.037615, 5.96619], 33] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.96619, 0.018825429, 0.0016567779, array([[0.02963047, 0.8602622 , 0.05275074, 0.05735662],\n",
      "       [0.03997446, 0.8475605 , 0.05449668, 0.05796835],\n",
      "       [0.03229507, 0.84301424, 0.06003333, 0.0646573 ],\n",
      "       [0.05057979, 0.81809396, 0.06557065, 0.06575557],\n",
      "       [0.04479001, 0.82001716, 0.0670667 , 0.06812607]], dtype=float32)]\n",
      "\n",
      " --- At epoch 34 : \n",
      "  [34, [36.998783, 32.58031, 3.2093585, 3.5505393], [32.714718, 13.10751, 24.447378, 5.98683], 34] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.98683, 0.015017483, 0.0019483039, array([[0.02937563, 0.8430524 , 0.05811239, 0.06945955],\n",
      "       [0.03946146, 0.8267746 , 0.06082019, 0.0729438 ],\n",
      "       [0.03161856, 0.8205475 , 0.06750798, 0.08032603],\n",
      "       [0.05030808, 0.79812694, 0.07145574, 0.08010931],\n",
      "       [0.04434944, 0.7929204 , 0.07572708, 0.08700304]], dtype=float32)]\n",
      "\n",
      " --- At epoch 35 : \n",
      "  [35, [36.840897, 32.395954, 3.1445246, 3.5148623], [32.80601, 13.028162, 24.06355, 5.987742], 35] \n",
      "\n",
      "   loss and regualization : \n",
      " [5.987742, 0.011004571, 0.0016999136, array([[0.02523046, 0.82937586, 0.04233209, 0.10306156],\n",
      "       [0.03326704, 0.8044712 , 0.0466239 , 0.11563789],\n",
      "       [0.02745463, 0.7953349 , 0.05203259, 0.12517786],\n",
      "       [0.04402883, 0.7761774 , 0.05352448, 0.12626927],\n",
      "       [0.03913932, 0.7588639 , 0.05906767, 0.14292908]], dtype=float32)]\n",
      "\n",
      " --- At epoch 36 : \n",
      "  [36, [36.816334, 32.36238, 3.145988, 3.4967957], [32.799473, 13.002739, 23.723438, 6.0112286], 36] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.0112286, 0.0072916285, 0.00078683073, array([[0.02070311, 0.809024  , 0.02935764, 0.14091524],\n",
      "       [0.02749235, 0.7779641 , 0.03287659, 0.16166689],\n",
      "       [0.02270391, 0.76706886, 0.03657375, 0.17365351],\n",
      "       [0.03680973, 0.74875176, 0.03857763, 0.17586093],\n",
      "       [0.03313015, 0.7228197 , 0.0424266 , 0.2016236 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 37 : \n",
      "  [37, [36.75358, 32.295177, 3.1208797, 3.4876084], [32.816307, 13.013861, 23.962431, 6.134487], 37] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.134487, 0.0042945943, 0.00059127674, array([[0.02129299, 0.7870117 , 0.02429589, 0.16739942],\n",
      "       [0.02867817, 0.7514841 , 0.02745005, 0.19238773],\n",
      "       [0.02348417, 0.7415432 , 0.03042456, 0.20454806],\n",
      "       [0.03763195, 0.7237836 , 0.03190401, 0.2066804 ],\n",
      "       [0.03331878, 0.69879407, 0.03455063, 0.23333655]], dtype=float32)]\n",
      "\n",
      " --- At epoch 38 : \n",
      "  [38, [36.76138, 32.30148, 3.1399043, 3.4773116], [32.75068, 12.977079, 23.4203, 6.230713], 38] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.230713, 0.0034827879, 0.00024779825, array([[0.02110648, 0.78368485, 0.02137798, 0.17383069],\n",
      "       [0.02834991, 0.7474389 , 0.02363927, 0.2005719 ],\n",
      "       [0.02335864, 0.73688626, 0.02599467, 0.21376044],\n",
      "       [0.03762987, 0.71739286, 0.02920207, 0.21577524],\n",
      "       [0.03400782, 0.68811107, 0.03107608, 0.24680497]], dtype=float32)]\n",
      "\n",
      " --- At epoch 39 : \n",
      "  [39, [36.738907, 32.278194, 3.1304557, 3.4675014], [32.750847, 12.961832, 23.255116, 6.266008], 39] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.266008, 0.0026452374, 0.00014133228, array([[0.02282105, 0.77581125, 0.01821133, 0.18315633],\n",
      "       [0.0301357 , 0.73624796, 0.02086705, 0.2127493 ],\n",
      "       [0.02532226, 0.7257216 , 0.02308563, 0.22587049],\n",
      "       [0.03977106, 0.7086355 , 0.02363576, 0.22795768],\n",
      "       [0.03663815, 0.67801505, 0.02590777, 0.25943905]], dtype=float32)]\n",
      "\n",
      " --- At epoch 40 : \n",
      "  [40, [36.771072, 32.31289, 3.1566572, 3.4642043], [32.7186, 12.936363, 22.82966, 6.4166555], 40] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4166555, 0.002092354, 0.0002565892, array([[0.02350983, 0.77311504, 0.01746027, 0.18591489],\n",
      "       [0.03147494, 0.7317292 , 0.01989452, 0.21690124],\n",
      "       [0.02641048, 0.7210448 , 0.02194889, 0.23059583],\n",
      "       [0.04126884, 0.70224696, 0.02361799, 0.2328662 ],\n",
      "       [0.03848673, 0.6694894 , 0.02557664, 0.26644734]], dtype=float32)]\n",
      "\n",
      " --- At epoch 41 : \n",
      "  [41, [36.777973, 32.326756, 3.1558259, 3.4505436], [32.69126, 12.944857, 22.855324, 6.3909307], 41] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.3909307, 0.0023112493, 0.00013399089, array([[0.02518949, 0.75962555, 0.01837992, 0.196805  ],\n",
      "       [0.03339344, 0.7191475 , 0.02059475, 0.2268643 ],\n",
      "       [0.02835922, 0.7088565 , 0.02252274, 0.2402615 ],\n",
      "       [0.04386574, 0.68836945, 0.02472964, 0.2430351 ],\n",
      "       [0.04061522, 0.65576273, 0.02641183, 0.2772103 ]], dtype=float32)]\n",
      "\n",
      " --- At epoch 42 : \n",
      "  [42, [36.77194, 32.3148, 3.172074, 3.4422774], [32.667606, 12.933689, 22.695662, 6.4390416], 42] \n",
      "\n",
      "   loss and regualization : \n",
      " [6.4390416, 0.0020065587, 0.00013217545, array([[0.02476695, 0.7535697 , 0.01791112, 0.2037522 ],\n",
      "       [0.03300618, 0.7126408 , 0.02093333, 0.23341969],\n",
      "       [0.02820623, 0.7001348 , 0.02333398, 0.24832495],\n",
      "       [0.04342254, 0.6806788 , 0.02293959, 0.25295916],\n",
      "       [0.04115472, 0.64439493, 0.02587317, 0.28857723]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from random import shuffle\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# local packages \n",
    "from utils_libs import *\n",
    "from utils_training import *\n",
    "from utils_inference import *\n",
    "from mixture_models import *\n",
    "\n",
    "# ----- arguments from command line\n",
    "\n",
    "arg_gpu_id = \"0\"\n",
    "arg_dataset = \"../datasets/bitcoin/market1_tar1_len10/\"\n",
    "arg_py = \"market1_tar1_len10\"\n",
    "\n",
    "# ------ GPU set-up in multi-GPU environment\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = arg_gpu_id\n",
    "\n",
    "# ----- data and log paths\n",
    "path_data = arg_dataset\n",
    "path_log_error = \"../results/log_error_mix_\" + str(arg_gpu_id) + \".txt\"\n",
    "path_model = \"../results/m1_t1/\"\n",
    "path_py = \"../results/m1_t1/py_\" + arg_py\n",
    "\n",
    "# ----- set-up\n",
    "\n",
    "# -- model\n",
    "\n",
    "para_distr_type = \"gaussian\"\n",
    "# gaussian, student_t\n",
    "para_distr_para = []\n",
    "# gaussian: [] \n",
    "# student_t: [nu], nu >= 3\n",
    "para_var_type = \"square\" # square, exp\n",
    "# [Note] for one-dimensional feature, variance derivation should be re-defined? \n",
    "# always positive correlation of the feature to the variance\n",
    "para_share_type_gate = \"no_share\"\n",
    "# no_share, share, mix\n",
    "\n",
    "para_model_type = 'linear'\n",
    "\n",
    "# -- data\n",
    "\n",
    "if para_model_type == 'rnn':\n",
    "    para_x_src_padding = False\n",
    "    para_add_common_factor = False\n",
    "    para_common_factor_type = \"pool\" if para_add_common_factor == True else \"\"\n",
    "    \n",
    "elif para_model_type == 'linear':\n",
    "    para_x_src_padding = True\n",
    "    para_add_common_factor = False\n",
    "    para_common_factor_type = \"factor\" if para_add_common_factor == True else \"\"\n",
    "\n",
    "para_bool_target_seperate = False # [Note] if yes, the last source corresponds to the auto-regressive target variable\n",
    "para_x_shape_acronym = [\"src\", \"N\", \"T\", \"D\"]\n",
    "\n",
    "# -- training\n",
    "para_n_epoch = 90\n",
    "para_burn_in_epoch = 80\n",
    "para_vali_snapshot_num = max(1, int(0.05*para_n_epoch))\n",
    "para_test_snapshot_num = para_n_epoch - para_burn_in_epoch\n",
    "para_test_snapshot_sample_interval = 2\n",
    "\n",
    "para_hpara_search = \"random\" # random, grid \n",
    "para_hpara_train_trial_num = 30\n",
    "para_hpara_retrain_num = 10\n",
    "para_hpara_ensemble_num = 3\n",
    "\n",
    "# optimization\n",
    "para_loss_type = \"heter_lk_inv\"\n",
    "para_optimizer = \"adam\"\n",
    "\n",
    "# [Note] training heuristic: re-set the following for training on new data\n",
    "# [Note] if lr_decay is on, \"lr\" and \"para_n_epoch\" can be set to higher values\n",
    "para_optimizer_lr_decay = True \n",
    "para_optimizer_lr_decay_epoch = 10 # after the warm-up\n",
    "# [Note] when sg_mcmc is on, turn off the learning rate warm-up\n",
    "para_optimizer_lr_warmup_epoch = max(1, int(0.1*para_n_epoch))\n",
    "\n",
    "para_early_stop_bool = False\n",
    "para_early_stop_window = 0\n",
    "\n",
    "para_validation_metric = 'rmse'\n",
    "para_metric_map = {'rmse':0, 'mae':1, 'mape':2, 'nnllk':3} \n",
    "\n",
    "# regularization\n",
    "para_regu_mean = True\n",
    "para_regu_var = True\n",
    "para_regu_gate = False\n",
    "para_regu_mean_positive = False\n",
    "\n",
    "para_bool_bias_in_mean = True\n",
    "para_bool_bias_in_var = True\n",
    "para_bool_bias_in_gate = True\n",
    "\n",
    "# -- hpara: hyper parameter\n",
    "\n",
    "para_hpara_range = {}\n",
    "para_hpara_range['random'] = {}\n",
    "para_hpara_range['random']['linear'] = {}\n",
    "para_hpara_range['random']['rnn'] = {}\n",
    "\n",
    "# - linear\n",
    "if para_add_common_factor == True:\n",
    "    para_hpara_range['random']['linear']['factor_size'] = [10, 10]\n",
    "para_hpara_range['random']['linear']['lr'] = [1e-3, 1e-3]  \n",
    "para_hpara_range['random']['linear']['batch_size'] = [30, 250]\n",
    "# source-wise\n",
    "para_hpara_range['random']['linear']['l2_mean'] = [1e-3, 1e-1]\n",
    "para_hpara_range['random']['linear']['l2_var'] =  [1e-3, 1e-1]\n",
    "if para_regu_gate == True:\n",
    "    para_hpara_range['random']['linear']['l2_gate'] = [1e-7, 1e-3]\n",
    "\n",
    "# # - rnn\n",
    "# # source-wise\n",
    "# para_hpara_range['random']['rnn']['rnn_size'] =  [16, 16]\n",
    "# para_hpara_range['random']['rnn']['dense_num'] = [0, 3] # inproper value leads to non-convergence in training\n",
    "\n",
    "# para_hpara_range['random']['rnn']['lr'] = [0.001, 0.001]\n",
    "# para_hpara_range['random']['rnn']['batch_size'] = [100, 140]\n",
    "\n",
    "# # source-wise\n",
    "# para_hpara_range['random']['rnn']['l2_mean'] = [1e-7, 1e-3]\n",
    "# para_hpara_range['random']['rnn']['l2_var'] = [1e-7, 1e-3]\n",
    "# if para_regu_gate == True:\n",
    "#     para_hpara_range['random']['linear']['l2_gate'] = [1e-7, 1e-3]\n",
    "    \n",
    "# para_hpara_range['random']['rnn']['dropout_keep_prob'] = [0.7, 1.0]\n",
    "# para_hpara_range['random']['rnn']['max_norm_cons'] = [0.0, 0.0]\n",
    "\n",
    "# -- log\n",
    "def log_train(path):\n",
    "    with open(path, \"a\") as text_file:\n",
    "        text_file.write(\"\\n\\n ------ Bayesian mixture : \\n\")\n",
    "        \n",
    "        text_file.write(\"data source padding : %s \\n\"%(para_x_src_padding))\n",
    "        text_file.write(\"data path : %s \\n\"%(path_data))\n",
    "        text_file.write(\"data source timesteps : %s \\n\"%(para_steps_x))\n",
    "        text_file.write(\"data source feature dimensionality : %s \\n\"%(para_dim_x))\n",
    "        text_file.write(\"data source number : %d \\n\"%( len(src_ts_x) ))\n",
    "        text_file.write(\"data common factor : %s \\n\"%(para_add_common_factor))\n",
    "        text_file.write(\"data common factor type : %s \\n\"%(para_common_factor_type))\n",
    "        text_file.write(\"prediction path : %s \\n\"%(path_py))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"model type : %s \\n\"%(para_model_type))\n",
    "        text_file.write(\"target distribution type : %s \\n\"%(para_distr_type))\n",
    "        text_file.write(\"target distribution para. : %s \\n\"%(str(para_distr_para)))\n",
    "        text_file.write(\"target variable as a seperated data source : %s \\n\"%(para_bool_target_seperate))\n",
    "        text_file.write(\"variance calculation type : %s \\n\"%(para_var_type))\n",
    "        text_file.write(\"para. sharing in gate logit : %s \\n\"%(para_share_type_gate))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"regularization on mean : %s \\n\"%(para_regu_mean))\n",
    "        text_file.write(\"regularization on variance : %s \\n\"%(para_regu_var))\n",
    "        text_file.write(\"regularization on mixture gates : %s \\n\"%(para_regu_gate))\n",
    "        text_file.write(\"regularization on positive means : %s \\n\"%(para_regu_mean_positive))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"adding bias terms in mean : %s \\n\"%(para_bool_bias_in_mean))\n",
    "        text_file.write(\"adding bias terms in variance : %s \\n\"%(para_bool_bias_in_var))\n",
    "        text_file.write(\"adding bias terms in gates : %s \\n\"%(para_bool_bias_in_gate))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"optimizer : %s \\n\"%(para_optimizer))\n",
    "        text_file.write(\"loss type : %s \\n\"%(para_loss_type))\n",
    "        text_file.write(\"learning rate decay : %s \\n\"%(str(para_optimizer_lr_decay)))\n",
    "        text_file.write(\"learning rate decay epoch : %s \\n\"%(str(para_optimizer_lr_decay_epoch)))\n",
    "        text_file.write(\"learning rate warm-up epoch : %s \\n\"%(str(para_optimizer_lr_warmup_epoch)))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"hyper-para search : %s \\n\"%(para_hpara_search))\n",
    "        text_file.write(\"hyper-para range : %s \\n\"%(str(para_hpara_range[para_hpara_search][para_model_type])))\n",
    "        text_file.write(\"hyper-para training trial num : %s \\n\"%(str(para_hpara_train_trial_num)))\n",
    "        text_file.write(\"hyper-para retraining num.: %s \\n\"%(str(para_hpara_retrain_num)))\n",
    "        text_file.write(\"random seed ensemble num.: %s \\n\"%(str(para_hpara_ensemble_num)))\n",
    "        text_file.write(\"\\n\")\n",
    "        \n",
    "        text_file.write(\"epochs in total : %s \\n\"%(para_n_epoch))\n",
    "        text_file.write(\"burn_in_epoch : %s \\n\"%(para_burn_in_epoch))\n",
    "        text_file.write(\"num. snapshots in validating : %s \\n\"%(para_vali_snapshot_num))\n",
    "        text_file.write(\"num. snapshots in testing : %s \\n\"%(para_test_snapshot_num))\n",
    "        text_file.write(\"validation metric : %s \\n\"%(para_validation_metric))\n",
    "        text_file.write(\"early-stoping : %s \\n\"%(para_early_stop_bool))\n",
    "        text_file.write(\"early-stoping look-back window : %s \\n\"%(para_early_stop_window))\n",
    "        \n",
    "        text_file.write(\"\\n\\n\")\n",
    "\n",
    "# ----- training and evalution\n",
    "    \n",
    "def training_validating(xtr,\n",
    "                        ytr,\n",
    "                        xval,\n",
    "                        yval,\n",
    "                        dim_x,\n",
    "                        steps_x,\n",
    "                        hyper_para_dict,\n",
    "                        training_dict,\n",
    "                        retrain_top_steps, \n",
    "                        retrain_bayes_steps,\n",
    "                        retrain_bool,\n",
    "                        retrain_idx,\n",
    "                        random_seed):\n",
    "    '''\n",
    "    Argu.:\n",
    "      xtr: [num_src, N, T, D]\n",
    "         S: num_src\n",
    "         N: number of data samples\n",
    "         T: number of steps\n",
    "         D: dimension at each time step\n",
    "      ytr: [N 1]\n",
    "        \n",
    "      dim_x: integer, corresponding to D\n",
    "      steps_x: integer, corresponding to T\n",
    "      \n",
    "      hyper_para_dict: \n",
    "       \"lr\": float,\n",
    "       \"batch_size\": int\n",
    "       \"l2\": float,\n",
    "                           \n",
    "       \"lstm_size\": int,\n",
    "       \"dense_num\": int,\n",
    "       \"use_hidden_before_dense\": bool\n",
    "       \n",
    "      training_dict:\n",
    "       \"batch_per_epoch\": int\n",
    "       \"tr_idx\": list of integer\n",
    "    '''\n",
    "    # clear the graph in the current session \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "        # clear the graph in the current session \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # fix the random seed to stabilize the network\n",
    "        os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "        random.seed(random_seed)  # `python` built-in pseudo-random generator\n",
    "        np.random.seed(random_seed)\n",
    "        tf.set_random_seed(random_seed)\n",
    "        \n",
    "        # session set-up\n",
    "        config = tf.ConfigProto()\n",
    "        config.allow_soft_placement = True\n",
    "        config.gpu_options.allow_growth = True\n",
    "        sess = tf.Session(config = config)\n",
    "        \n",
    "        model = mixture_statistic(session = sess, \n",
    "                                  loss_type = para_loss_type,\n",
    "                                  num_src = len(xtr),\n",
    "                                  hyper_para_dict = hyper_para_dict, \n",
    "                                  model_type = para_model_type)\n",
    "        \n",
    "        # -- initialize the network\n",
    "        model.network_ini(hyper_para_dict,\n",
    "                          x_dim = dim_x,\n",
    "                          x_steps = steps_x, \n",
    "                          x_bool_common_factor = para_add_common_factor,\n",
    "                          model_type = para_model_type, \n",
    "                          model_distr_type = para_distr_type,\n",
    "                          model_distr_para = para_distr_para,\n",
    "                          model_var_type = para_var_type,\n",
    "                          model_para_share_type = para_share_type_gate,\n",
    "                          bool_regu_mean = para_regu_mean,\n",
    "                          bool_regu_var = para_regu_var,\n",
    "                          bool_regu_gate = para_regu_gate,\n",
    "                          bool_regu_positive_mean = para_regu_mean_positive,\n",
    "                          bool_bias_mean = para_bool_bias_in_mean,\n",
    "                          bool_bias_var = para_bool_bias_in_var,\n",
    "                          bool_bias_gate = para_bool_bias_in_gate,\n",
    "                          optimization_method = para_optimizer,\n",
    "                          optimization_lr_decay = para_optimizer_lr_decay,\n",
    "                          optimization_lr_decay_steps = para_optimizer_lr_decay_epoch*int(len(xtr[0])/int(hyper_para_dict[\"batch_size\"])),\n",
    "                          optimization_burn_in_step = para_burn_in_epoch,\n",
    "                          optimization_warmup_step = para_optimizer_lr_warmup_epoch*training_dict[\"batch_per_epoch\"] - 1)\n",
    "        \n",
    "        # !! the order of Saver\n",
    "        saver = tf.train.Saver(max_to_keep = None)\n",
    "        \n",
    "        model.train_ini()\n",
    "        model.inference_ini()\n",
    "        #tf.get_default_graph().finalize()\n",
    "        \n",
    "        # -- set up training batch parameters\n",
    "        batch_gen = data_loader(x = xtr,\n",
    "                                y = ytr,\n",
    "                                batch_size = int(hyper_para_dict[\"batch_size\"]), \n",
    "                                num_ins = training_dict[\"tr_num_ins\"],  \n",
    "                                num_src = len(xtr))\n",
    "        # -- begin training\n",
    "        \n",
    "        # training and validation error log\n",
    "        step_error = []\n",
    "        global_step = 0\n",
    "        \n",
    "        # training time counter\n",
    "        st_time = time.time()\n",
    "        \n",
    "        for epoch in range(para_n_epoch):\n",
    "            # shuffle traning instances each epoch\n",
    "            batch_gen.re_shuffle()\n",
    "            batch_x, batch_y, bool_last = batch_gen.one_batch()\n",
    "            \n",
    "            # loop over all batches\n",
    "            while batch_x != None:\n",
    "                    \n",
    "                # one-step training on a batch of training data\n",
    "                model.train_batch(batch_x, \n",
    "                                  batch_y,\n",
    "                                  global_step = epoch)\n",
    "                \n",
    "                # - batch-wise validation\n",
    "                # val_metric: [val_rmse, val_mae, val_mape, val_nnllk]\n",
    "                # nnllk: normalized negative log likelihood\n",
    "                val_metric, monitor_metric = model.validation(xval,\n",
    "                                                              yval,\n",
    "                                                              step = global_step,\n",
    "                                                              bool_end_of_epoch = bool_last)\n",
    "                if val_metric:\n",
    "                    # tr_metric [tr_rmse, tr_mae, tr_mape, tr_nnllk]\n",
    "                    tr_metric, _ = model.inference(xtr,\n",
    "                                                   ytr, \n",
    "                                                   bool_py_eval = False)\n",
    "                    #step_error.append([global_step, tr_metric, val_metric, epoch])\n",
    "                    step_error.append([epoch, tr_metric, val_metric, epoch])\n",
    "                    \n",
    "                # - next batch\n",
    "                batch_x, batch_y, bool_last = batch_gen.one_batch()\n",
    "                global_step += 1\n",
    "                    \n",
    "            # -- model saver \n",
    "            model_saver_flag = model.model_saver(path = path_model + para_model_type + '_' + str(retrain_idx) + '_' + str(epoch),\n",
    "                                                 epoch = epoch,\n",
    "                                                 step = global_step,\n",
    "                                                 top_snapshots = retrain_top_steps,\n",
    "                                                 bayes_snapshots = retrain_bayes_steps,\n",
    "                                                 early_stop_bool = para_early_stop_bool,\n",
    "                                                 early_stop_window = para_early_stop_window, \n",
    "                                                 tf_saver = saver)\n",
    "            # epoch-wise\n",
    "            print(\"\\n --- At epoch %d : \\n  %s \"%(epoch, str(step_error[-1])))\n",
    "            print(\"\\n   loss and regualization : \\n\", monitor_metric)\n",
    "            \n",
    "            # NAN value exception \n",
    "            if np.isnan(monitor_metric[0]) == True:\n",
    "                print(\"\\n --- NAN loss !! \\n\" )\n",
    "                break\n",
    "                \n",
    "            if retrain_bool == True and model_saver_flag != None:\n",
    "                print(\"\\n    [MODEL SAVED] \" + model_saver_flag + \" \\n \" + path_model + para_model_type + '_' + str(retrain_idx) + '_' + str(epoch))\n",
    "                \n",
    "        ed_time = time.time()\n",
    "        \n",
    "    # ? sorted training log ?\n",
    "    # step_error: [global_step, tr_metric, val_metric, epoch]\n",
    "    # sort step_error based on para_validation_metric\n",
    "    sort_step_error = sorted(step_error, key = lambda x:x[2][para_metric_map[para_validation_metric]])\n",
    "    \n",
    "    return sort_step_error,\\\n",
    "           1.0*(ed_time - st_time)/(epoch + 1e-5),\\\n",
    "\n",
    "def testing(retrain_snapshots,\n",
    "            retrain_ids,\n",
    "            xts,\n",
    "            yts,\n",
    "            file_path,\n",
    "            bool_instance_eval,\n",
    "            loss_type,\n",
    "            num_src,\n",
    "            snapshot_features, \n",
    "            hpara_dict):\n",
    "    \n",
    "    # ensemble of model snapshots\n",
    "    infer = ensemble_inference()\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.allow_soft_placement = True\n",
    "        config.gpu_options.allow_growth = True\n",
    "        \n",
    "        for tmp_idx, tmp_retrain_id in enumerate(retrain_ids):\n",
    "            \n",
    "            for tmp_model_id in retrain_snapshots[tmp_idx]:\n",
    "                \n",
    "                # path of the stored models \n",
    "                tmp_meta = file_path + para_model_type + '_' + str(tmp_retrain_id) + '_' + str(tmp_model_id) + '.meta'\n",
    "                tmp_data = file_path + para_model_type + '_' + str(tmp_retrain_id) + '_' + str(tmp_model_id)\n",
    "        \n",
    "                # clear graph\n",
    "                tf.reset_default_graph()\n",
    "                saver = tf.train.import_meta_graph(tmp_meta, \n",
    "                                                   clear_devices = True)\n",
    "                sess = tf.Session(config = config)\n",
    "                \n",
    "                model = mixture_statistic(session = sess, \n",
    "                                          loss_type = para_loss_type,\n",
    "                                          num_src = num_src,\n",
    "                                          hyper_para_dict = hpara_dict, \n",
    "                                          model_type = para_model_type)\n",
    "                # restore the model\n",
    "                model.model_restore(tmp_meta, \n",
    "                                    tmp_data, \n",
    "                                    saver)\n",
    "                \n",
    "                # one-shot inference sample\n",
    "                # error_tuple: [rmse, mae, mape, nnllk],  \n",
    "                # py_tuple: [py_mean, py_var, py_mean_src, py_var_src, py_gate_src]\n",
    "                error_tuple, py_tuple = model.inference(xts,\n",
    "                                                        yts, \n",
    "                                                        bool_py_eval = bool_instance_eval)\n",
    "                if bool_instance_eval == True:\n",
    "                    # store the samples\n",
    "                    infer.add_samples(py_mean = py_tuple[0],\n",
    "                                      py_var = py_tuple[1],\n",
    "                                      py_mean_src = py_tuple[2],\n",
    "                                      py_var_src = py_tuple[3],\n",
    "                                      py_gate_src = py_tuple[4])\n",
    "    \n",
    "    num_snapshots = sum([len(i) for i in retrain_snapshots])\n",
    "    \n",
    "    # return: error tuple, prediction tuple\n",
    "    if num_snapshots == 0:\n",
    "        return [\"None\"], [\"None\"]  \n",
    "    else:\n",
    "        # ensemble inference\n",
    "        if len(snapshot_features) == 0 or num_snapshots == 1:\n",
    "            return infer.bayesian_inference(yts)\n",
    "        else:\n",
    "            return infer.importance_inference(snapshot_features = snapshot_features, \n",
    "                                              y = yts)\n",
    "# ----- main process  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ------ data\n",
    "    \n",
    "    import pickle\n",
    "    tr_dta = pickle.load(open(path_data + 'train.p', \"rb\"), encoding = 'latin1')\n",
    "    val_dta = pickle.load(open(path_data + 'val.p', \"rb\"), encoding = 'latin1')\n",
    "    ts_dta = pickle.load(open(path_data + 'test.p', \"rb\"), encoding = 'latin1')\n",
    "    print(len(tr_dta), len(val_dta), len(ts_dta))\n",
    "    \n",
    "    # if para_bool_target_seperate = yes, the last source corresponds to the auto-regressive target variable\n",
    "    tr_x, tr_y = data_reshape(tr_dta, \n",
    "                              bool_target_seperate = para_bool_target_seperate)\n",
    "    val_x, val_y = data_reshape(val_dta,\n",
    "                                bool_target_seperate = para_bool_target_seperate)\n",
    "    ts_x, ts_y = data_reshape(ts_dta,\n",
    "                              bool_target_seperate = para_bool_target_seperate)\n",
    "    \n",
    "    # --- log transformation of y\n",
    "    \n",
    "#     tr_y = np.log(np.asarray(tr_y))\n",
    "#     val_y = np.log(np.asarray(val_y))\n",
    "#     ts_y = np.log(np.asarray(ts_y))\n",
    "    \n",
    "    tr_y = np.asarray(tr_y)-28.0\n",
    "    val_y = np.asarray(val_y)\n",
    "    ts_y = np.asarray(ts_y)\n",
    "        \n",
    "    # output from the reshape\n",
    "    # y [N 1], x [S [N T D]]\n",
    "    print(\"training: \", len(tr_x[0]), len(tr_y))\n",
    "    print(\"validation: \", len(val_x[0]), len(val_y))\n",
    "    print(\"testing: \", len(ts_x[0]), len(ts_y))\n",
    "    \n",
    "    # --- source-wise data preparation \n",
    "\n",
    "    if para_x_src_padding == True:\n",
    "        # T and D different across data sources\n",
    "        # padding to same T and D\n",
    "        # y: [N 1], x: [S [N T D]]\n",
    "        src_tr_x = data_padding_x(tr_x,\n",
    "                                  num_src = len(tr_x))\n",
    "        src_val_x = data_padding_x(val_x,\n",
    "                                   num_src = len(tr_x))\n",
    "        src_ts_x = data_padding_x(ts_x,\n",
    "                                  num_src = len(tr_x))\n",
    "        print(\"Shapes after padding: \", np.shape(src_tr_x), np.shape(src_val_x), np.shape(src_ts_x))\n",
    "        \n",
    "    else:\n",
    "        src_tr_x = tr_x\n",
    "        src_val_x = val_x\n",
    "        src_ts_x = ts_x\n",
    "        \n",
    "    if para_add_common_factor == True:\n",
    "        # x: [S [N T D]]\n",
    "        # assume T is same across data sources\n",
    "        \n",
    "        # [N T sum(D)]\n",
    "        tr_x_concat = np.concatenate(tr_x, -1)\n",
    "        val_x_concat = np.concatenate(val_x, -1)\n",
    "        ts_x_concat = np.concatenate(ts_x, -1)\n",
    "        \n",
    "        if para_common_factor_type == \"pool\":\n",
    "            tr_x_factor = tr_x_concat\n",
    "            val_x_factor = val_x_concat\n",
    "            ts_x_factor = ts_x_concat\n",
    "            \n",
    "        elif para_common_factor_type == \"factor\":\n",
    "            tmp_dim = np.shape(tr_x_concat)[-1]\n",
    "            tmp_step = np.shape(tr_x_concat)[1]\n",
    "            \n",
    "            from sklearn.decomposition import FactorAnalysis\n",
    "            transformer = FactorAnalysis(n_components = 10, \n",
    "                                         random_state = 0)\n",
    "            # [N T d]\n",
    "            tr_x_factor = []\n",
    "            for tmp_x in tr_x_concat:\n",
    "                # tmp_x: [T sum(D)] -> [T d]\n",
    "                tr_x_factor.append(transformer.fit_transform(tmp_x))\n",
    "                \n",
    "            val_x_factor = []\n",
    "            for tmp_x in val_x_concat:\n",
    "                # tmp_x: [T sum(D)] -> [T d]\n",
    "                val_x_factor.append(transformer.fit_transform(tmp_x))\n",
    "            \n",
    "            ts_x_factor = []\n",
    "            for tmp_x in ts_x_concat:\n",
    "                # tmp_x: [T sum(D)] -> [T d]\n",
    "                ts_x_factor.append(transformer.fit_transform(tmp_x))\n",
    "        \n",
    "        # [S+1 [N T d]]\n",
    "        src_tr_x.append(np.asarray(tr_x_factor))\n",
    "        src_val_x.append(np.asarray(val_x_factor))\n",
    "        src_ts_x.append(np.asarray(ts_x_factor))\n",
    "    \n",
    "    # steps and dimensionality of each source\n",
    "    para_steps_x = []\n",
    "    para_dim_x = []\n",
    "    for tmp_src in range(len(src_tr_x)):\n",
    "        tmp_shape = np.shape(src_tr_x[tmp_src][0])\n",
    "        para_steps_x.append(tmp_shape[0])\n",
    "        para_dim_x.append(tmp_shape[1])\n",
    "        print(\"src \" + str(tmp_src) + \" shape: \", tmp_shape)\n",
    "    \n",
    "    shape_tr_x_dict = dict({\"N\": len(tr_x[0])})\n",
    "    \n",
    "    # ------ training and validation\n",
    "    \n",
    "    log_train(path_log_error)\n",
    "    \n",
    "    # -- hyper-para generator \n",
    "    if para_hpara_search == \"random\":        \n",
    "        hpara_generator = hyper_para_random_search(para_hpara_range[para_hpara_search][para_model_type], \n",
    "                                                   para_hpara_train_trial_num)\n",
    "    elif para_hpara_search == \"grid\":\n",
    "        hpara_generator = hyper_para_grid_search(para_hpara_range[para_hpara_search][para_model_type])\n",
    "            \n",
    "    # -- begin hyper-para search\n",
    "    hpara_log = []\n",
    "    \n",
    "    # sample one set-up of hyper-para\n",
    "    hpara_dict = hpara_generator.one_trial()\n",
    "                                                 \n",
    "    while hpara_dict != None:\n",
    "        \n",
    "        tr_dict = training_para_gen(shape_x_dict = shape_tr_x_dict, \n",
    "                                    hpara_dict = hpara_dict)\n",
    "        # hp_: hyper-parameter\n",
    "        # hp_step_error: [[step, train_metric, val_metric, epoch]]\n",
    "        hp_step_error, hp_epoch_time = training_validating(src_tr_x,\n",
    "                                                           tr_y,\n",
    "                                                           src_val_x,\n",
    "                                                           val_y,\n",
    "                                                           dim_x = para_dim_x,\n",
    "                                                           steps_x = para_steps_x,\n",
    "                                                           hyper_para_dict = hpara_dict,\n",
    "                                                           training_dict = tr_dict,\n",
    "                                                           retrain_bool = False,\n",
    "                                                           retrain_top_steps = [],\n",
    "                                                           retrain_bayes_steps = [],\n",
    "                                                           retrain_idx = 0,\n",
    "                                                           random_seed = 1)\n",
    "        \n",
    "        #[ dict{lr, batch, l2, ..., burn_in_steps}, [[step, tr_metric, val_metric, epoch]] ]\n",
    "        hpara_dict[\"burn_in_steps\"] = para_burn_in_epoch # tr_dict[\"batch_per_epoch\"] - 1\n",
    "        hpara_log.append([hpara_dict, hp_step_error])\n",
    "        \n",
    "        # -- prepare for the next trial\n",
    "        \n",
    "        # sample the next hyper-para\n",
    "        hpara_dict = hpara_generator.one_trial()\n",
    "        \n",
    "        # -- logging\n",
    "        log_train_val_performance(path_log_error,\n",
    "                                  hpara = hpara_log[-1][0],\n",
    "                                  hpara_error = hpara_log[-1][1][0],\n",
    "                                  train_time = hp_epoch_time)\n",
    "        # NAN loss exception\n",
    "        log_null_loss_exception(hp_step_error, \n",
    "                                path_log_error)\n",
    "        \n",
    "        print('\\n Validation performance under the hyper-parameters: \\n', hpara_log[-1][0], hpara_log[-1][1][0])\n",
    "        print('\\n Training time: \\n', hp_epoch_time, '\\n')\n",
    "        \n",
    "    # ------ re-train\n",
    "    #save all epoches in re-training, then select snapshots\n",
    "    \n",
    "    # best hyper-para\n",
    "    best_hpara, _, _, _, _ = hyper_para_selection(hpara_log, \n",
    "                                                  val_snapshot_num = para_vali_snapshot_num, \n",
    "                                                  test_snapshot_num = para_test_snapshot_num,\n",
    "                                                  metric_idx = para_metric_map[para_validation_metric])\n",
    "    retrain_hpara_steps = []\n",
    "    retrain_hpara_step_error = []\n",
    "    retrain_random_seeds = [1] + [randint(0, 1000) for _ in range(para_hpara_retrain_num-1)]\n",
    "    \n",
    "    for tmp_retrain_id in range(para_hpara_retrain_num):\n",
    "        \n",
    "        tr_dict = training_para_gen(shape_x_dict = shape_tr_x_dict,\n",
    "                                    hpara_dict = best_hpara)\n",
    "        \n",
    "        step_error, _ = training_validating(src_tr_x,\n",
    "                                            tr_y,\n",
    "                                            src_val_x,\n",
    "                                            val_y,\n",
    "                                            dim_x = para_dim_x,\n",
    "                                            steps_x = para_steps_x,\n",
    "                                            hyper_para_dict = best_hpara,\n",
    "                                            training_dict = tr_dict,\n",
    "                                            retrain_bool = True,\n",
    "                                            retrain_top_steps = list(range(para_n_epoch)), #top_steps,\n",
    "                                            retrain_bayes_steps = list(range(para_n_epoch)), #bayes_steps,\n",
    "                                            retrain_idx = tmp_retrain_id,\n",
    "                                            random_seed = retrain_random_seeds[tmp_retrain_id])\n",
    "        \n",
    "        top_steps, bayes_steps, top_steps_features, bayes_steps_features, val_error, step_error_pairs = snapshot_selection(train_log = step_error,\n",
    "                                                                                                                           snapshot_num = para_test_snapshot_num,\n",
    "                                                                                                                           total_step_num = para_n_epoch,\n",
    "                                                                                                                           metric_idx = para_metric_map[para_validation_metric],\n",
    "                                                                                                                           val_snapshot_num = para_vali_snapshot_num)\n",
    "        if len(top_steps) != 0:\n",
    "            retrain_hpara_steps.append([top_steps, bayes_steps, top_steps_features, bayes_steps_features, tmp_retrain_id, val_error])\n",
    "            retrain_hpara_step_error.append([step_error_pairs, tmp_retrain_id])\n",
    "        \n",
    "        log_val_hyper_para(path = path_log_error,\n",
    "                           hpara_tuple = [best_hpara, top_steps],\n",
    "                           error_tuple = step_error[0], \n",
    "                           log_string = \"-- \" + str(tmp_retrain_id))\n",
    "    \n",
    "        print('\\n----- Retrain hyper-parameters: ', best_hpara, top_steps, '\\n')\n",
    "        print('\\n----- Retrain validation performance: ', step_error[0], '\\n')\n",
    "    \n",
    "    sort_retrain_hpara_steps = sorted(retrain_hpara_steps, \n",
    "                                      key = lambda x:x[-1])\n",
    "    \n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [i[-2:] for i in sort_retrain_hpara_steps], \n",
    "                         ensemble_str = \"Retrain Ids and Vali. Errors: \")\n",
    "    \n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [i[-2:] for i in sort_retrain_hpara_steps[:para_hpara_ensemble_num]], \n",
    "                         ensemble_str = \"Retrain Ids for ensemble: \")\n",
    "    \n",
    "    # ------ testing\n",
    "    # error tuple: [rmse, mae, mape, nnllk]\n",
    "    # py_tuple\n",
    "    \n",
    "    # -- one snapshot from one retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [sort_retrain_hpara_steps[0][0][:1]],\n",
    "                                    retrain_ids = [ sort_retrain_hpara_steps[0][-2] ],\n",
    "                                    xts = src_ts_x, \n",
    "                                    yts = ts_y, \n",
    "                                    file_path = path_model, \n",
    "                                    bool_instance_eval = True,\n",
    "                                    loss_type = para_loss_type,\n",
    "                                    num_src = len(src_val_x),\n",
    "                                    snapshot_features = [],\n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [error_tuple], \n",
    "                         ensemble_str = \"One-shot-one-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_one_one\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- one snapshot from multi retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [tmp_steps[0][:1] for tmp_steps in sort_retrain_hpara_steps], \n",
    "                                    retrain_ids = [i[-2] for i in sort_retrain_hpara_steps[:para_hpara_ensemble_num]],\n",
    "                                    xts = src_ts_x,\n",
    "                                    yts = ts_y, \n",
    "                                    file_path = path_model,\n",
    "                                    bool_instance_eval = True,\n",
    "                                    loss_type = para_loss_type,\n",
    "                                    num_src = len(src_ts_x), \n",
    "                                    snapshot_features = [], \n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [error_tuple], \n",
    "                         ensemble_str = \"One-shot-multi-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_one_multi\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- top snapshots from one retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [sort_retrain_hpara_steps[0][0]], \n",
    "                                    retrain_ids = [ sort_retrain_hpara_steps[0][-2] ], \n",
    "                                    xts = src_ts_x, \n",
    "                                    yts = ts_y, \n",
    "                                    file_path = path_model,\n",
    "                                    bool_instance_eval = True, \n",
    "                                    loss_type = para_loss_type, \n",
    "                                    num_src = len(src_ts_x), \n",
    "                                    snapshot_features = [], \n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error,\n",
    "                         error_tuple = [error_tuple],\n",
    "                         ensemble_str = \"Top-shots-one-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_top_one\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- top snapshots multi retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [tmp_steps[0] for tmp_steps in sort_retrain_hpara_steps], \n",
    "                                    retrain_ids = [i[-2] for i in sort_retrain_hpara_steps[:para_hpara_ensemble_num]], \n",
    "                                    xts = src_ts_x,\n",
    "                                    yts = ts_y,\n",
    "                                    file_path = path_model,\n",
    "                                    bool_instance_eval = True,\n",
    "                                    loss_type = para_loss_type,\n",
    "                                    num_src = len(src_ts_x), \n",
    "                                    snapshot_features = [], \n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [error_tuple], \n",
    "                         ensemble_str = \"Top-shots-multi-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_top_multi\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- bayesian snapshots one retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [sort_retrain_hpara_steps[0][1]], \n",
    "                                    retrain_ids = [ sort_retrain_hpara_steps[0][-2] ], \n",
    "                                    xts = src_ts_x, \n",
    "                                    yts = ts_y,\n",
    "                                    file_path = path_model, \n",
    "                                    bool_instance_eval = True, \n",
    "                                    loss_type = para_loss_type, \n",
    "                                    num_src = len(src_ts_x), \n",
    "                                    snapshot_features = [], \n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [error_tuple], \n",
    "                         ensemble_str = \"Bayesian-one-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_bayes_one\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- bayesian snapshots multi retrain\n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = [tmp_steps[1] for tmp_steps in sort_retrain_hpara_steps],\n",
    "                                    retrain_ids = [i[-2] for i in sort_retrain_hpara_steps[:para_hpara_ensemble_num]],\n",
    "                                    xts = src_ts_x,\n",
    "                                    yts = ts_y,\n",
    "                                    file_path = path_model,\n",
    "                                    bool_instance_eval = True,\n",
    "                                    loss_type = para_loss_type,\n",
    "                                    num_src = len(src_ts_x),\n",
    "                                    snapshot_features = [],\n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error,\n",
    "                         error_tuple = [error_tuple],\n",
    "                         ensemble_str = \"Bayesian-multi-retrain\")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_bayes_multi\" + \".p\", \"wb\"))\n",
    "    \n",
    "    # -- global top1 and topK steps\n",
    "    \n",
    "    retrain_ids, retrain_id_steps = global_top_steps_multi_retrain(retrain_step_error = retrain_hpara_step_error, \n",
    "                                                                   num_step = int(para_test_snapshot_num*para_hpara_ensemble_num))\n",
    "    \n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [retrain_ids, retrain_id_steps], \n",
    "                         ensemble_str = \"Global-top-steps: \")\n",
    "    \n",
    "    error_tuple, py_tuple = testing(retrain_snapshots = retrain_id_steps, \n",
    "                                    retrain_ids = retrain_ids,\n",
    "                                    xts = src_ts_x,\n",
    "                                    yts = ts_y, \n",
    "                                    file_path = path_model,\n",
    "                                    bool_instance_eval = True,\n",
    "                                    loss_type = para_loss_type,\n",
    "                                    num_src = len(src_ts_x), \n",
    "                                    snapshot_features = [], \n",
    "                                    hpara_dict = best_hpara)\n",
    "    log_test_performance(path = path_log_error, \n",
    "                         error_tuple = [error_tuple], \n",
    "                         ensemble_str = \"Global-top-steps-multi-retrain \")\n",
    "    # dump predictions\n",
    "    pickle.dump(py_tuple, open(path_py + \"_global\" + \".p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
